<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>TeXtidote analysis</title>
<style type="text/css">
body {
  font-family: sans-serif;
}
.highlight, .highlight-sh, .highlight-spelling {
  padding: 2pt;
  border-radius: 4pt;
  cursor: help;
  opacity: 0.7;
  border: dashed 1px;
}
.highlight {
  background-color: orange;
  color: black;
}
.highlight-sh {
  background-color: yellow;
  color: black;
}
.highlight-spelling {
  background-color: red;
  color: white;
}
div.original-file {
  font-family: monospace;
  font-size: 11pt;
  background-color: #f8f8ff;
  padding: 20pt;
  border-radius: 6pt;
}
.textidote {
  	background-image: url(data:image/svg+xml;base64,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);
}
h2.filename {
  font-family: monospace;
}
h1.textidote {
  width: 378px;
  height: 68px;
  display: block;
}
.keyword1 {
  font-weight: bold;
  color: green;
}
.keyword2 {
  font-weight: bold;
  color: darkblue;
}
.comment, .comment * {
  color: darkred;
  font-weight: normal;
}
.linenb {
  font-style: italic;
  color: lightgrey;
  width: 30pt;
  float: left;
  margin-top: 1pt;
  margin-bottom: 1pt;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.codeline {
  margin-left: -30pt;
  padding-left: 60pt;
  margin-top: 1pt;
  margin-bottom: 1pt;
}
.no-text {
  display: none;
}
.clear {
  clear: both;
}
</style>
</head>
<body>
<a href="https://sylvainhalle.github.io/textidote"><h1 class="textidote"><span class="no-text">Results of TeXtidote analysis</span></h1></a>
<p>Here is the result of analyzing your file(s) with TeXtidote. Hover the mouse over highlighted portions of the document to read a tooltip that gives you some writing advice.</p>
<h2 class="filename">thesis-20161105.tex</h2>

<p>Found 690 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;&nbsp;&nbsp;1</div><div class="codeline"><span class="highlight" title="Don't put a space before the closing parenthesis. Suggestions: [)] (44654) [lt:en:COMMA_PARENTHESIS_WHITESPACE]"></span><span class="highlight" title="Don't put a space before the full stop. Suggestions: [.] (79782) [lt:en:COMMA_PARENTHESIS_WHITESPACE]"></span><span class="comment">% IIIT nonsense:</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;&nbsp;2</div><div class="codeline"><span class="comment"><span class="comment">% https://drive.google.com/file/d/1gmWef1R1AxWSRTI94DTcXfRq5wjomLhI/view?usp=sharing</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;&nbsp;3</div><div class="codeline"><span class="comment"><span class="comment">%  $Description: Thesis</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;&nbsp;4</div><div class="codeline"><span class="comment"><span class="comment">%  $Author: xxx $</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;&nbsp;5</div><div class="codeline"><span class="comment"><span class="comment">%  $Date: xxx  $</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;&nbsp;6</div><div class="codeline"><span class="comment"><span class="comment">%  $Revision: 0.0 $</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;&nbsp;7</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;&nbsp;8</div><div class="codeline"><span class="keyword1">\documentclass</span>[11pt]{book}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;&nbsp;9</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\usepackage</span>{iiit_thesis}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;10</div><div class="codeline"><span class="keyword1">\usepackage</span>{iiit_thesis_new}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;11</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\usepackage</span>{times}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;12</div><div class="codeline"><span class="keyword1">\usepackage</span>{epsfig}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;13</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\usepackage</span>{amsmath}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;14</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\usepackage</span>{amssymb}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;15</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\usepackage</span>{latexsym}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;16</div><div class="codeline"><span class="keyword1">\usepackage</span>{graphicx}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;17</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\usepackage</span>{multirow}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;18</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\usepackage</span>{algorithm2e}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;19</div><div class="codeline"><span class="keyword1">\usepackage</span>{listing}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;20</div><div class="codeline"><span class="keyword1">\usepackage</span>{times}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;21</div><div class="codeline"><span class="keyword1">\usepackage</span>{latexsym}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;22</div><div class="codeline"><span class="keyword1">\usepackage</span>{physics}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;23</div><div class="codeline"><span class="keyword1">\usepackage</span>{amsmath}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;24</div><div class="codeline"><span class="keyword1">\usepackage</span>{amssymb}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;25</div><div class="codeline"><span class="keyword1">\usepackage</span>{stmaryrd}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;26</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\usepackage</span>{tikz}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;27</div><div class="codeline"><span class="keyword1">\usepackage</span>{multirow}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;28</div><div class="codeline"><span class="keyword1">\usepackage</span>{multicol}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;29</div><div class="codeline"><span class="keyword1">\usepackage</span>{array}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;30</div><div class="codeline"><span class="keyword1">\usepackage</span>{amsthm}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;31</div><div class="codeline"><span class="keyword1">\usepackage</span>{mathtools}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;32</div><div class="codeline"><span class="keyword1">\usepackage</span>{booktabs}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;33</div><div class="codeline"><span class="keyword1">\usepackage</span>{epigraph}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;34</div><div class="codeline"><span class="keyword1">\usepackage</span>{todonotes}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;35</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\usepackage</span>{natbib}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;36</div><div class="codeline"><span class="comment"><span class="comment">% \bibliographystyle{unsrtnat}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;37</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;38</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\usepackage</span>{float} % use for H with figures, which forces figure locations.</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;39</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;40</div><div class="codeline"><span class="keyword1">\usepackage</span>{tikz}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;41</div><div class="codeline">\usetikzlibrary{arrows}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;42</div><div class="codeline">\usetikzlibrary{shapes}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;43</div><div class="codeline">\newcommand*\circled[1]{\tikz[baseline=(char.base)]{</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;44</div><div class="codeline">            \node[shape=circle,fill=pairedOneLightBlue,inner sep=1pt] (char) {#1};}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;45</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;46</div><div class="codeline"><span class="keyword1">\usepackage</span>[sc,osf]{mathpazo}   <span class="comment">% With old-style figures and real smallcaps.</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;47</div><div class="codeline">\linespread{1.025}              <span class="comment">% Palatino leads a little more leading</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;48</div><div class="codeline"><span class="comment"><span class="comment">% Euler for math and numbers</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;49</div><div class="codeline"><span class="keyword1">\usepackage</span>[euler-digits,small]{eulervm}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;50</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;51</div><div class="codeline"><span class="keyword1">\usepackage</span>[T1]{fontenc}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;52</div><div class="codeline"><span class="keyword1">\usepackage</span>{inconsolata}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;53</div><div class="codeline"><span class="keyword1">\usepackage</span>{lettrine}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;54</div><div class="codeline"><span class="keyword1">\usepackage</span>{yfonts}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;55</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;56</div><div class="codeline"><span class="keyword1">\usepackage</span>{amsmath}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;57</div><div class="codeline"><span class="keyword1">\usepackage</span>{amssymb}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;58</div><div class="codeline"><span class="keyword1">\usepackage</span>{amsthm}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;59</div><div class="codeline"><span class="keyword1">\usepackage</span>{minted}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;60</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;61</div><div class="codeline"><span class="keyword1">\usepackage</span>{hyperref}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;62</div><div class="codeline"><span class="keyword1">\usepackage</span>{cancel}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;63</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\usepackage</span>{mathtools}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;64</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;65</div><div class="codeline"><span class="comment"><span class="comment">% hyperlink colors</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;66</div><div class="codeline"><span class="comment"><span class="comment">% https://tex.stackexchange.com/questions/823/remove-ugly-borders-around-clickable-cross-references-and-hyperlinks</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;67</div><div class="codeline"><span class="keyword1">\usepackage</span>{xcolor}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;68</div><div class="codeline">\hypersetup{</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;69</div><div class="codeline">    colorlinks,</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;70</div><div class="codeline">    linkcolor={red!50!black},</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;71</div><div class="codeline">    citecolor={red!50!black},</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;72</div><div class="codeline">    urlcolor={red!50!black}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;73</div><div class="codeline">}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;74</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;75</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;76</div><div class="codeline">\newcommand{\skewsym}{\mathrm{Skew}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;77</div><div class="codeline">\newcommand\ddfrac[2]{\frac{\displaystyle #1}{\displaystyle #2}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;78</div><div class="codeline">\newcommand{\N}{\ensuremath{\mathbb{N}}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;79</div><div class="codeline">\newcommand{\C}{\ensuremath{\mathbb{C}}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;80</div><div class="codeline">\newcommand{\coT}{\ensuremath{T^*}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;81</div><div class="codeline">\newcommand{\Lie}{\ensuremath{\mathfrak{L}}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;82</div><div class="codeline">\newcommand{\Vectorfield}{\ensuremath{\mathfrak{X}}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;83</div><div class="codeline">\newcommand{\pushforward}[1]{\ensuremath{{#1}_{\star}}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;84</div><div class="codeline">\newcommand{\pullback}[1]{\ensuremath{{#1}^{\star}}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;85</div><div class="codeline">\newcommand{\vectorfield}{\ensuremath{\mathfrak{X}}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;86</div><div class="codeline">\newcommand{\Z}{\ensuremath{\mathbb Z}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;87</div><div class="codeline">\newcommand{\pushfwd}[1]{\pushforward{#1}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;88</div><div class="codeline">\newcommand{\pf}[1]{\pushfwd{#1}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;89</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;90</div><div class="codeline">\newcommand{\boldX}{\ensuremath{\mathbf{X}}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;91</div><div class="codeline">\newcommand{\boldY}{\ensuremath{\mathbf{Y}}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;92</div><div class="codeline"><span class="comment"><span class="comment">%\renewcommand{\UrlFont}{\ttfamily\small}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;93</div><div class="codeline">\newcommand{\card}[1]{\left| #1 \right|}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;94</div><div class="codeline">\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{<span class="comment">%</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;95</div><div class="codeline"> #1\;\delimsize|\delimsize|\;#2<span class="comment">%</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;96</div><div class="codeline">}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;97</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;98</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;99</div><div class="codeline">\newcommand{\infdiv}{D\infdivx}</div><div class="clear"></div>
<div class="linenb">&nbsp;100</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;101</div><div class="codeline"><span class="comment"><span class="comment">%\newcommand{\card}[1]{\ensuremath{\left| #1 \right|}}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;102</div><div class="codeline">\newcommand{\wtov}{\texttt{word2vec }}</div><div class="clear"></div>
<div class="linenb">&nbsp;103</div><div class="codeline">\newcommand{<span class="highlight-sh" title="Do not mix \cite with \citep or \citet in the same document. [sh:c:itemix]">\citep}</span>[1]{\cite{#1}}</div><div class="clear"></div>
<div class="linenb">&nbsp;104</div><div class="codeline">\newcommand{\citet}[1]{\cite{#1}}</div><div class="clear"></div>
<div class="linenb">&nbsp;105</div><div class="codeline">\newcommand{\R}{\ensuremath{\mathbb R}}</div><div class="clear"></div>
<div class="linenb">&nbsp;106</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;107</div><div class="codeline">\def\qed{$\Box$}</div><div class="clear"></div>
<div class="linenb">&nbsp;108</div><div class="codeline">\newtheorem{theorem}{Theorem}</div><div class="clear"></div>
<div class="linenb">&nbsp;109</div><div class="codeline">\newtheorem{slogan}{Slogan}</div><div class="clear"></div>
<div class="linenb">&nbsp;110</div><div class="codeline">\newtheorem{corollary}[theorem]{Corollary}</div><div class="clear"></div>
<div class="linenb">&nbsp;111</div><div class="codeline">\newtheorem{definition}[theorem]{Definition}</div><div class="clear"></div>
<div class="linenb">&nbsp;112</div><div class="codeline">\newtheorem{lemma}[theorem]{Lemma}</div><div class="clear"></div>
<div class="linenb">&nbsp;113</div><div class="codeline">\newtheorem{observation}[theorem]{Observation}</div><div class="clear"></div>
<div class="linenb">&nbsp;114</div><div class="codeline"><span class="comment"><span class="comment">% \newtheorem{proof}[theorem]{Proof}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;115</div><div class="codeline">\newtheorem{remark}[theorem]{Remark}</div><div class="clear"></div>
<div class="linenb">&nbsp;116</div><div class="codeline">\newtheorem{example}[theorem]{Example}</div><div class="clear"></div>
<div class="linenb">&nbsp;117</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;118</div><div class="codeline">\definecolor{pairedNegOneLightGray}{HTML}{cacaca}</div><div class="clear"></div>
<div class="linenb">&nbsp;119</div><div class="codeline">\definecolor{pairedNegTwoDarkGray}{HTML}{827b7b}</div><div class="clear"></div>
<div class="linenb">&nbsp;120</div><div class="codeline">\definecolor{pairedOneLightBlue}{HTML}{a6cee3}</div><div class="clear"></div>
<div class="linenb">&nbsp;121</div><div class="codeline">\definecolor{pairedTwoDarkBlue}{HTML}{1f78b4}</div><div class="clear"></div>
<div class="linenb">&nbsp;122</div><div class="codeline">\definecolor{pairedThreeLightGreen}{HTML}{b2df8a}</div><div class="clear"></div>
<div class="linenb">&nbsp;123</div><div class="codeline">\definecolor{pairedFourDarkGreen}{HTML}{33a02c}</div><div class="clear"></div>
<div class="linenb">&nbsp;124</div><div class="codeline">\definecolor{pairedFiveLightRed}{HTML}{fb9a99}</div><div class="clear"></div>
<div class="linenb">&nbsp;125</div><div class="codeline">\definecolor{pairedSixDarkRed}{HTML}{e31a1c}</div><div class="clear"></div>
<div class="linenb">&nbsp;126</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;127</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;128</div><div class="codeline">\graphicspath{{figures/}{./}} <span class="comment">% To include images in other directories</span></div><div class="clear"></div>
<div class="linenb">&nbsp;129</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;130</div><div class="codeline"><span class="comment"><span class="comment">% https://tex.stackexchange.com/questions/132849/how-can-i-change-the-font-size-of-the-number-in-minted-environment</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;131</div><div class="codeline">\renewcommand{\theFancyVerbLine}{\sffamily \textcolor[rgb]{0.2,0.2,0.2}{\small \oldstylenums{\arabic{FancyVerbLine}}}}</div><div class="clear"></div>
<div class="linenb">&nbsp;132</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;133</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;134</div><div class="codeline">\long\def\symbolfootnote[#1]#2{\begingroup<span class="comment">%</span></div><div class="clear"></div>
<div class="linenb">&nbsp;135</div><div class="codeline">\def\thefootnote{\fnsymbol{footnote}}\footnote[#1]{#2}\endgroup}</div><div class="clear"></div>
<div class="linenb">&nbsp;136</div><div class="codeline">\renewcommand{\baselinestretch}{1.2}</div><div class="clear"></div>
<div class="linenb">&nbsp;137</div><div class="codeline">\onecolumn</div><div class="clear"></div>
<div class="linenb">&nbsp;138</div><div class="codeline"><span class="comment"><span class="comment">%--------------------------------------------------------</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;139</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;140</div><div class="codeline"><span class="keyword2">\begin{document}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;141</div><div class="codeline">\pagenumbering{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Roman, woman, Romans, Roma, Oman, Romano, Rowan, Ronan, roan, Romany, Rodman, Rogan, rowan, Rohan] (0) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>roman}</div><div class="clear"></div>
<div class="linenb">&nbsp;142</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;143</div><div class="codeline"><span class="comment"><span class="comment">%% TITLE PAGE</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;144</div><div class="codeline">\input{titlePage.tex}</div><div class="clear"></div>
<div class="linenb">&nbsp;145</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;146</div><div class="codeline"><span class="comment"><span class="comment">%% COPYRIGHT PAGE</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;147</div><div class="codeline"><span class="highlight-sh" title="If you are writing a research paper, do not force page breaks. [sh:nonp]"></span>\newpage</div><div class="clear"></div>
<div class="linenb">&nbsp;148</div><div class="codeline">\thispagestyle{empty}</div><div class="clear"></div>
<div class="linenb">&nbsp;149</div><div class="codeline">\renewcommand{\thesisdedication}{{\large Copyright \copyright~~Siddharth Bhat, 2021<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\\</span>}{\large All Rights Reserved\\}}</div><div class="clear"></div>
<div class="linenb">&nbsp;150</div><div class="codeline">\<span class="highlight-spelling" title="Possible spelling mistake found (13) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>thesisdedicationpage</div><div class="clear"></div>
<div class="linenb">&nbsp;151</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;152</div><div class="codeline"><span class="comment"><span class="comment">%% CERTIFICATE PAGE</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;153</div><div class="codeline">\input{certificate.tex}</div><div class="clear"></div>
<div class="linenb">&nbsp;154</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;155</div><div class="codeline"><span class="comment"><span class="comment">%%% DEDICATION PAGE</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;156</div><div class="codeline"><span class="highlight-sh" title="If you are writing a research paper, do not force page breaks. [sh:nonp]"></span>\newpage</div><div class="clear"></div>
<div class="linenb">&nbsp;157</div><div class="codeline">\thispagestyle{empty}</div><div class="clear"></div>
<div class="linenb">&nbsp;158</div><div class="codeline">\renewcommand{\thesisdedication}{\large To \texttt{\#math}, \texttt{\#haskell}, and \texttt{\#harmless}}</div><div class="clear"></div>
<div class="linenb">&nbsp;159</div><div class="codeline">\<span class="highlight-spelling" title="Possible spelling mistake found (41) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>thesisdedicationpage</div><div class="clear"></div>
<div class="linenb">&nbsp;160</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;161</div><div class="codeline">\<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [masters thesis] (64) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>mastersthesis</div><div class="clear"></div>
<div class="linenb">&nbsp;162</div><div class="codeline">\renewcommand{\baselinestretch}{1.5}</div><div class="clear"></div>
<div class="linenb">&nbsp;163</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;164</div><div class="codeline"><span class="comment"><span class="comment">% ACKNOWLEDGEMENTS PAGE</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;165</div><div class="codeline">\chapter*{Acknowledgments}</div><div class="clear"></div>
<div class="linenb">&nbsp;166</div><div class="codeline"><span class="keyword1">\label</span>{ch:ack}</div><div class="clear"></div>
<div class="linenb">&nbsp;167</div><div class="codeline">To \texttt{\#<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Haskell, Hassell, Haswell] (102) [lt:en:MORFOLOGIK_RULE_EN_GB]">haskell}</span>, \texttt{\#harmless} and \texttt{\#<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [match, path, mate, myth, oath, bath, maths, hath, mat, mats, moth, Mach, Meath, mash, lath, matt, Bath, Kath, Mata, Rath, Wath, ath, mah, maty, meth, m ath, mat h] (128) [lt:en:MORFOLOGIK_RULE_EN_GB]">math}</span>, for teaching me</div><div class="clear"></div>
<div class="linenb">&nbsp;168</div><div class="codeline">so much more than I <span class="highlight" title="Consider using 'could'.. Suggestions: [could] (170) [lt:en:MAY_COULD_POSSIBLY]">could possibly</span> have learnt on my own; To \texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Dave, dean, haven, tavern, avian, Damian, caveat, cavern, raven, Cavan, Dalian, caveman, divan, paean, demean, devein, Damjan, Darran, Dayman, Dean, Devan, Hadean, Haven, LaVeyan, Maven, dayan] (211) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>davean}</div><div class="clear"></div>
<div class="linenb">&nbsp;169</div><div class="codeline">for the uninvited talk. To \texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [tops, typos] (245) [lt:en:MORFOLOGIK_RULE_EN_GB]">topos}</span> for all the category theory. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (280) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]"></span>To</div><div class="clear"></div>
<div class="linenb">&nbsp;170</div><div class="codeline">\texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Emmett] (283) [lt:en:MORFOLOGIK_RULE_EN_GB]">ekmett}</span> for \texttt{\#harmless}. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (306) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> \texttt{Z-module} to showing me the</div><div class="clear"></div>
<div class="linenb">&nbsp;171</div><div class="codeline">beauty of groups, to \texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Razak] (357) [lt:en:MORFOLOGIK_RULE_EN_GB]">drazak}</span> for teaching me orbit-stabilizer, to</div><div class="clear"></div>
<div class="linenb">&nbsp;172</div><div class="codeline">\texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [dance, danced, Dade, halide, dale, dace, delude, Dacre, Dulce] (401) [lt:en:MORFOLOGIK_RULE_EN_GB]">dalcde}</span> for correcting my definition of compactness, to</div><div class="clear"></div>
<div class="linenb">&nbsp;173</div><div class="codeline">\texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Antonio, Antoine, Antonia, bonfire, Antoni, Antonius, António, cantonise, cantonize] (456) [lt:en:MORFOLOGIK_RULE_EN_GB]">antonfire}</span> for yelling at me when I didn't understand the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [patient, potent, quotient, orient, torment, torrent, toting] (513) [lt:en:MORFOLOGIK_RULE_EN_GB]">totient</span>, to</div><div class="clear"></div>
<div class="linenb">&nbsp;174</div><div class="codeline">\texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Bavaria, Atari, gamers, Lamar, gamer, safari, Bambi, Bayard, Samara, Tamar, Tamara, Bamako, Gagarin, Samaria, tamarin, beamer, calamari, beamers, blamer, Ahmari, Baars, Bahai, Barri, Beaumaris, Bharati, Bhavani, Bismark, Bodfari, Braemar, Brahmani, Bramah, Damaris, Gamage, Gamay, Gamrie, Kumari, Ngapara, Ngataki, Oamaru, Qatari, Ramati, Tamaki, Wakari, Zamani, basmati, blamers, gaiatri, gayatri, samara] (525) [lt:en:MORFOLOGIK_RULE_EN_GB]">bgamari}</span> for infinite patience with dropped projects, to</div><div class="clear"></div>
<div class="linenb">&nbsp;175</div><div class="codeline">\texttt{<span class="highlight-spelling" title="Possible spelling mistake found (581) [lt:en:MORFOLOGIK_RULE_EN_GB]">PlanckWalk}</span> for the patient explanation of an elliptic PDE, to</div><div class="clear"></div>
<div class="linenb">&nbsp;176</div><div class="codeline">\texttt{Millennial} for a description of the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Langland, Longlands, ganglands] (679) [lt:en:MORFOLOGIK_RULE_EN_GB]">langlands</span>, to \texttt{sure} for</div><div class="clear"></div>
<div class="linenb">&nbsp;177</div><div class="codeline">what a sheaf is, to all of you for making a corner of the internet feel like</div><div class="clear"></div>
<div class="linenb">&nbsp;178</div><div class="codeline">home. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (785) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Mona, monk, mono, mRNA, Mina, Mon, Monza, Mora, bona, Iona, monad, Nona, Rona, moan, dona, myna, Bona, Doña, Mana, Moana, Monea, Monk, Mono] (788) [lt:en:MORFOLOGIK_RULE_EN_GB]">mona</span>, for <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Span, Spa, Spam, Spar, Slag, Spas, Spat, Stag, Sag, Snag, Spay, Swag, Shag, Sprag, Spa G] (798) [lt:en:MORFOLOGIK_RULE_EN_GB]">SpaG</span>, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [critique, nitpick] (804) [lt:en:MORFOLOGIK_RULE_EN_GB]">britpick</span>, coffee, and tech support. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (840) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [adults, adduced, adduce, adduces, adducer] (843) [lt:en:MORFOLOGIK_RULE_EN_GB]">adlucem</span>, for</div><div class="clear"></div>
<div class="linenb">&nbsp;179</div><div class="codeline">dubious frog chasing. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (878) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Super, Superb, Rupert, Puberty, Sporty, Sperry, Superbly, Surety, Supercity, Supertax, Suety, Superspy] (881) [lt:en:MORFOLOGIK_RULE_EN_GB]">Superty</span>, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Niton, nitid, nit in] (890) [lt:en:MORFOLOGIK_RULE_EN_GB]">nitin</span>, and our goddess, for what is lost may</div><div class="clear"></div>
<div class="linenb">&nbsp;180</div><div class="codeline">be found again. <span class="highlight-spelling" title="Possible spelling mistake found (951) [lt:en:MORFOLOGIK_RULE_EN_GB]">ParticleMania</span> and <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Itches, Ixias] (969) [lt:en:MORFOLOGIK_RULE_EN_GB]">Itihas</span>, thanks for the many obtuse</div><div class="clear"></div>
<div class="linenb">&nbsp;181</div><div class="codeline">conversations that shaped what I thought. To <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Annan] (1049) [lt:en:MORFOLOGIK_RULE_EN_GB]">Kannan</span> and Manish, and <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Senates, Venerates, Penates] (1072) [lt:en:MORFOLOGIK_RULE_EN_GB]">Venkatesh</span>,</div><div class="clear"></div>
<div class="linenb">&nbsp;182</div><div class="codeline">for giving me the levity to pursue what I wanted. To <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Day, Eday, Udny, U day] (1136) [lt:en:MORFOLOGIK_RULE_EN_GB]">Uday</span>, for the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [match, path, mate, myth, oath, bath, maths, hath, mat, mats, moth, Mach, Meath, mash, lath, matt, Bath, Kath, Mata, Rath, Wath, ath, mah, maty, meth, m ath, mat h] (1150) [lt:en:MORFOLOGIK_RULE_EN_GB]">math</span>,</div><div class="clear"></div>
<div class="linenb">&nbsp;183</div><div class="codeline">warmth, and opportunities. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (1183) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> Arnaud, for the many conversations. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (1222) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> Tobias,</div><div class="clear"></div>
<div class="linenb">&nbsp;184</div><div class="codeline">for being a way better advisor than I  ever deserved.  <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (1288) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> \texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Van, Lyn, VPN, Ven, Von, Yn, V yn] (1291) [lt:en:MORFOLOGIK_RULE_EN_GB]">Vyn}</span> and</div><div class="clear"></div>
<div class="linenb">&nbsp;185</div><div class="codeline">\texttt{<span class="highlight-spelling" title="Possible spelling mistake found (1299) [lt:en:MORFOLOGIK_RULE_EN_GB]">GodotMisogi}</span>, for <span class="highlight-spelling" title="Possible spelling mistake found (1316) [lt:en:MORFOLOGIK_RULE_EN_GB]">Math-Utopia</span>. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (1329) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> \texttt{Luca}, \texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Sendai] (1338) [lt:en:MORFOLOGIK_RULE_EN_GB]">Senpai}</span>, and</div><div class="clear"></div>
<div class="linenb">&nbsp;186</div><div class="codeline">\texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [LLB, L LLB] (1350) [lt:en:MORFOLOGIK_RULE_EN_GB]">LLLB}</span> for bake and pancakes. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (1378) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> \texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [code legend] (1381) [lt:en:MORFOLOGIK_RULE_EN_GB]">codelegend}</span>, for going along</div><div class="clear"></div>
<div class="linenb">&nbsp;187</div><div class="codeline">with my incorrect explanations. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (1441) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> panda, for <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Marx, Mary, mark, Max, Marc, Mars, mare, Manx, Mara, mar, marl, mart, Mark, Marr, mara, max, mar x] (1455) [lt:en:MORFOLOGIK_RULE_EN_GB]">marx</span>, coffee, and the baked</div><div class="clear"></div>
<div class="linenb">&nbsp;188</div><div class="codeline">potato recipe. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (1498) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> Goose, for all the physics.  <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (1530) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Ameba] (1533) [lt:en:MORFOLOGIK_RULE_EN_GB]">Ameya</span>, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Anime sh] (1540) [lt:en:MORFOLOGIK_RULE_EN_GB]">Animesh</span>, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Man, Alan, Amman, Oman, Amen, Atman, Adman, AMA, Amon, Aran, Auman, Haman, Iman, A man, Am an] (1549) [lt:en:MORFOLOGIK_RULE_EN_GB]">Aman<span class="highlight-sh" title="There should be a space after a comma. [sh:d:001]"></span><span class="highlight" title="Put a space after the comma. Suggestions: [, Athreya] (1553) [lt:en:COMMA_PARENTHESIS_WHITESPACE]">,A</span>threya</span>,</div><div class="clear"></div>
<div class="linenb">&nbsp;189</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Auto, Euro, Aura, Aero, Mauro, Afro, Aro, Auroa] (1563) [lt:en:MORFOLOGIK_RULE_EN_GB]">Auro</span>, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Shawnee, Shawnees, Shalfleet, Sangeet] (1569) [lt:en:MORFOLOGIK_RULE_EN_GB]">Shaanjeet</span>, and all the rest of theory group for our shared love. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (1634) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span>  <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Time, Timor, IMO, Tito, Limo, Tims, Tim, Timm, Tim o, Vimo] (1638) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>Timo</div><div class="clear"></div>
<div class="linenb">&nbsp;190</div><div class="codeline">for mate, Tal for the coffee, Greg for the cherry vodka. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (1700) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> all the folks at</div><div class="clear"></div>
<div class="linenb">&nbsp;191</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Disc, RISC, Misc, CISC, IIRC, II Sc] (1720) [lt:en:MORFOLOGIK_RULE_EN_GB]">IISc</span>, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Tweak] (1726) [lt:en:MORFOLOGIK_RULE_EN_GB]">Tweag</span>,  <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Etc, Seth, ETA, Eh, Etch, Nth, 0th, 1th, 2th, 3th, 4th, 5th, 6th, 7th, 8th, 9th, Beth, ET, ETs, Erth, Esh, Eta, Th, Ath, Et, Meth, ET H] (1734) [lt:en:MORFOLOGIK_RULE_EN_GB]">ETH</span>, and theory group for the great times. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (1777) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Amok, Aloe] (1780) [lt:en:MORFOLOGIK_RULE_EN_GB]">Alok</span>, for beginning</div><div class="clear"></div>
<div class="linenb">&nbsp;192</div><div class="codeline">this project in the first place. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (1833) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> mum, for the cats and tea. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (1863) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">To</span> dad, for</div><div class="clear"></div>
<div class="linenb">&nbsp;193</div><div class="codeline">teaching me Squeak.</div><div class="clear"></div>
<div class="linenb">&nbsp;194</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;195</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;196</div><div class="codeline"><span class="comment"><span class="comment">%% ABSTRACT PAGE</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;197</div><div class="codeline">\chapter*{Abstract}</div><div class="clear"></div>
<div class="linenb">&nbsp;198</div><div class="codeline"><span class="keyword1">\label</span>{ch:abstract}</div><div class="clear"></div>
<div class="linenb">&nbsp;199</div><div class="codeline">\epigraph{It is only proper to realize that language is largely a historical<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> accident.}{<span class="highlight" title="Add a space between sentences. Suggestions: [ John] (1983) [lt:en:SENTENCE_WHITESPACE]">Jo</span>hn</span> Von <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Neumann., Neumann!, Neumann?, Neumann:, Neumann,, Neumann;] (1992) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>Neumann}</div><div class="clear"></div>
<div class="linenb">&nbsp;200</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;201</div><div class="codeline">With the growing use of natural language processing tools (<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Nap, Nip, Alp, LP, Np, PLP, N LP] (2060) [lt:en:MORFOLOGIK_RULE_EN_GB]">NLP</span>) in</div><div class="clear"></div>
<div class="linenb">&nbsp;202</div><div class="codeline">wide-ranging applications, it becomes imperative to understand why <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Nap, Nip, Alp, LP, Np, PLP, N LP] (2135) [lt:en:MORFOLOGIK_RULE_EN_GB]">NLP</span> models</div><div class="clear"></div>
<div class="linenb">&nbsp;203</div><div class="codeline">are as successful as they are. In particular, it is essential to understand</div><div class="clear"></div>
<div class="linenb">&nbsp;204</div><div class="codeline">what mathematical structures precisely underpin these models. To investigate</div><div class="clear"></div>
<div class="linenb">&nbsp;205</div><div class="codeline">the mathematical models of <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Nap, Nip, Alp, LP, Np, PLP, N LP] (2326) [lt:en:MORFOLOGIK_RULE_EN_GB]">NLP</span> knowledge representations, we focus on the</div><div class="clear"></div>
<div class="linenb">&nbsp;206</div><div class="codeline">setting of unsupervised word embeddings, due to the presence of robust models,</div><div class="clear"></div>
<div class="linenb">&nbsp;207</div><div class="codeline">and a seemingly simple mathematical structure. We find that even in this</div><div class="clear"></div>
<div class="linenb">&nbsp;208</div><div class="codeline">restricted setting, there are subtle, cross-cutting concerns as to how the</div><div class="clear"></div>
<div class="linenb">&nbsp;209</div><div class="codeline">model learns --- beginning from the high level description of learning a</div><div class="clear"></div>
<div class="linenb">&nbsp;210</div><div class="codeline">``vector'', to the low level details of implementations of these algorithms,</div><div class="clear"></div>
<div class="linenb">&nbsp;211</div><div class="codeline">including initialization and gradient calculation. We build a theory of</div><div class="clear"></div>
<div class="linenb">&nbsp;212</div><div class="codeline">knowledge representations for word embeddings, inspired by two seemingly</div><div class="clear"></div>
<div class="linenb">&nbsp;213</div><div class="codeline">unrelated ideas (a) Montague semantics \cite{sep-montague-semantics}, a linguistic theory of meaning which</div><div class="clear"></div>
<div class="linenb">&nbsp;214</div><div class="codeline">ascribes set-theoretic meaning to language, and (b) abstract interpretation, a</div><div class="clear"></div>
<div class="linenb">&nbsp;215</div><div class="codeline">mathematical theory of creating computable approximations to <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [incomputable] (3116) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>uncomputable</div><div class="clear"></div>
<div class="linenb">&nbsp;216</div><div class="codeline">semantics of programs. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (3152) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">We</span> find that <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [synthesizing] (3165) [lt:en:MORFOLOGIK_RULE_EN_GB]">syntheszing</span> these ideas provide a way to</div><div class="clear"></div>
<div class="linenb">&nbsp;217</div><div class="codeline">extract fuzzy-set embeddings from existing word-embeddings, which provides the</div><div class="clear"></div>
<div class="linenb">&nbsp;218</div><div class="codeline">full range of set-theoretic operations (union, intersection, and others), along</div><div class="clear"></div>
<div class="linenb">&nbsp;219</div><div class="codeline">with probabilistic operations (KL divergence, entropy) which are used to</div><div class="clear"></div>
<div class="linenb">&nbsp;220</div><div class="codeline">perform polysemy detection and word sense disambiguation, while retaining</div><div class="clear"></div>
<div class="linenb">&nbsp;221</div><div class="codeline">performance on regular word embeddings tasks such as similarity. Next, we turn</div><div class="clear"></div>
<div class="linenb">&nbsp;222</div><div class="codeline">our attention to generalizing the word embedding training regime by extracting</div><div class="clear"></div>
<div class="linenb">&nbsp;223</div><div class="codeline">the geometry which is currently held implicit. This leads us to formulate a</div><div class="clear"></div>
<div class="linenb">&nbsp;224</div><div class="codeline">general theory of learning word representations on Lie groups. In summary, we</div><div class="clear"></div>
<div class="linenb">&nbsp;225</div><div class="codeline">provide insight into the mathematical structure of word representations.</div><div class="clear"></div>
<div class="linenb">&nbsp;226</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;227</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;228</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;229</div><div class="codeline">\<span class="highlight-spelling" title="Possible spelling mistake found (3901) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>tableofcontents</div><div class="clear"></div>
<div class="linenb">&nbsp;230</div><div class="codeline">\<span class="highlight-spelling" title="Possible spelling mistake found (3918) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>listoffigures</div><div class="clear"></div>
<div class="linenb">&nbsp;231</div><div class="codeline">\<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [distortable] (3933) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>listoftables</div><div class="clear"></div>
<div class="linenb">&nbsp;232</div><div class="codeline"><span class="comment"><span class="comment">%--------------------------------------------------------</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;233</div><div class="codeline">\pagenumbering{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Arabic, Arabia, arabin, arabis] (3946) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>arabic}</div><div class="clear"></div>
<div class="linenb">&nbsp;234</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;235</div><div class="codeline">\chapter{Introduction}</div><div class="clear"></div>
<div class="linenb">&nbsp;236</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;237</div><div class="codeline">\epigraph{The sky is the limit, so <span class="highlight" title="Did you mean 'let's' (let's = let us; lets = 3rd person singular of 'let')?. Suggestions: [let's] (3993) [lt:en:LETS_LET]">lets</span> build rockets!}{<span class="highlight" title="Add a space between sentences. Suggestions: [ Anonymous] (4012) [lt:en:SENTENCE_WHITESPACE]"></span>Anonymous}</div><div class="clear"></div>
<div class="linenb">&nbsp;238</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;239</div><div class="codeline"><span class="comment"><span class="comment">% TODO: steal intro from glove, word2vec</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;240</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;241</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;242</div><div class="codeline"><span class="comment"><span class="comment">% \textinit{N}atural language processing has, since its inception, required</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;243</div><div class="codeline">Natural language processing has, since its inception, required</div><div class="clear"></div>
<div class="linenb">&nbsp;244</div><div class="codeline">techniques to extract semantic information from raw corpora with little to no</div><div class="clear"></div>
<div class="linenb">&nbsp;245</div><div class="codeline">supervision. To perform such unsupervised learning, many models</div><div class="clear"></div>
<div class="linenb">&nbsp;246</div><div class="codeline">have been built, based off of the ``Distributional Hypothesis'', which states</div><div class="clear"></div>
<div class="linenb">&nbsp;247</div><div class="codeline">that words that occur in the same contexts tend to have similar meaning<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">s\cite</span>{harris1954distributional}.</div><div class="clear"></div>
<div class="linenb">&nbsp;248</div><div class="codeline">The underlying idea that ``a word is characterized by the company it keeps'' was</div><div class="clear"></div>
<div class="linenb">&nbsp;249</div><div class="codeline">popularized by Firth \citep{firth1957synopsis}.</div><div class="clear"></div>
<div class="linenb">&nbsp;250</div><div class="codeline">However, distributional representations of words over vector spaces have an</div><div class="clear"></div>
<div class="linenb">&nbsp;251</div><div class="codeline">inherent lack of <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [interpretability] (4585) [lt:en:MORFOLOGIK_RULE_EN_GB]">interpretablity</span> \citep{goldberg2014word2vec}. Furthermore, due</div><div class="clear"></div>
<div class="linenb">&nbsp;252</div><div class="codeline">to the symmetric nature of the vector space operations for similarity and</div><div class="clear"></div>
<div class="linenb">&nbsp;253</div><div class="codeline">analogy, which are far from human similarity judgements</div><div class="clear"></div>
<div class="linenb">&nbsp;254</div><div class="codeline">\citep{tversky1977features}.</div><div class="clear"></div>
<div class="linenb">&nbsp;255</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;256</div><div class="codeline">An early technique which exploited distributional semantics was Latent Semantic</div><div class="clear"></div>
<div class="linenb">&nbsp;257</div><div class="codeline">Analysis (<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Lisa, USA, BSA, CSA, ESA, LSD, NSA, RSA, Elsa, FSA, LGA, SSA, DSA, Asa, GSA, Isa, La, Lea, SA, Sa, Ls, L SA, LS A] (4849) [lt:en:MORFOLOGIK_RULE_EN_GB]">LSA</span>) \cite{landauer1998introduction}. <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Lisa, USA, BSA, CSA, ESA, LSD, NSA, RSA, Elsa, FSA, LGA, SSA, DSA, Asa, GSA, Isa, La, Lea, SA, Sa, Ls, L SA, LS A] (4859) [lt:en:MORFOLOGIK_RULE_EN_GB]">LSA</span> <span class="highlight-spelling" title="Possible spelling mistake. 'analyzes' is American English.. Suggestions: [analyses] (4863) [lt:en:MORFOLOGIK_RULE_EN_GB]">analyzes</span> relationships by</div><div class="clear"></div>
<div class="linenb">&nbsp;258</div><div class="codeline">assuming that words that are close in meaning will occur in similar pieces of</div><div class="clear"></div>
<div class="linenb">&nbsp;259</div><div class="codeline">text (the distributional hypothesis), and thus matrix containing word counts</div><div class="clear"></div>
<div class="linenb">&nbsp;260</div><div class="codeline">per document (rows represent unique words and columns represent each document)</div><div class="clear"></div>
<div class="linenb">&nbsp;261</div><div class="codeline">is constructed from a large piece of text and  singular value decomposition</div><div class="clear"></div>
<div class="linenb">&nbsp;262</div><div class="codeline">(<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [DVD, SD, Sad, Sod, Syd, SSD, STD, SVG, SVN, Sid, VD, Svn, S VD] (5200) [lt:en:MORFOLOGIK_RULE_EN_GB]">SVD</span>) is used to reduce the number of rows while preserving the similarity</div><div class="clear"></div>
<div class="linenb">&nbsp;263</div><div class="codeline">structure among columns. Documents are then compared by taking the cosine of</div><div class="clear"></div>
<div class="linenb">&nbsp;264</div><div class="codeline">the angle between the two vectors, where angles close to $0$ represent very</div><div class="clear"></div>
<div class="linenb">&nbsp;265</div><div class="codeline">similar documents, and angles close to $\pi/2$ represent dis-similar documents.</div><div class="clear"></div>
<div class="linenb">&nbsp;266</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;267</div><div class="codeline">\texttt{Word2vec} \cite{mikolov2013distributed} is a recent technique to create</div><div class="clear"></div>
<div class="linenb">&nbsp;268</div><div class="codeline">unsupervised word embeddings for <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Nap, Nip, Alp, LP, Np, PLP, N LP] (5578) [lt:en:MORFOLOGIK_RULE_EN_GB]">NLP</span> from unstructured data, whose informal</div><div class="clear"></div>
<div class="linenb">&nbsp;269</div><div class="codeline">correctness is based on the distributional hypothesis. The \texttt{word2vec} algorithm uses a shallow neural</div><div class="clear"></div>
<div class="linenb">&nbsp;270</div><div class="codeline">model to learn word associations from a large corpus of</div><div class="clear"></div>
<div class="linenb">&nbsp;271</div><div class="codeline">text. Once trained, such a model can detect synonymous words or suggest</div><div class="clear"></div>
<div class="linenb">&nbsp;272</div><div class="codeline">additional words for a partial sentence.  As befitting the name,</div><div class="clear"></div>
<div class="linenb">&nbsp;273</div><div class="codeline">\texttt{word2vec} represents each distinct surface syntactic word with a</div><div class="clear"></div>
<div class="linenb">&nbsp;274</div><div class="codeline">vector.<span class="highlight" title="Add a space between sentences. Suggestions: [ The] (5985) [lt:en:SENTENCE_WHITESPACE]">The</span> training mechanism yields vectors such that the cosine of the angle</div><div class="clear"></div>
<div class="linenb">&nbsp;275</div><div class="codeline">between the vectors reflects <span class="highlight" title="Maybe you need to remove one determiner so that only 'the' or 'the' is left.. Suggestions: [the] (6086) [lt:en:DT_DT]">the the</span> level of semantic similarity between the</div><div class="clear"></div>
<div class="linenb">&nbsp;276</div><div class="codeline">words represented by those vectors.</div><div class="clear"></div>
<div class="linenb">&nbsp;277</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;278</div><div class="codeline">On the other hand, it is very unclear why the \texttt{word2vec} training regime</div><div class="clear"></div>
<div class="linenb">&nbsp;279</div><div class="codeline">is as successful as it is. In comparison to <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Lisa, USA, BSA, CSA, ESA, LSD, NSA, RSA, Elsa, FSA, LGA, SSA, DSA, Asa, GSA, Isa, La, Lea, SA, Sa, Ls, L SA, LS A] (6287) [lt:en:MORFOLOGIK_RULE_EN_GB]">LSA</span>, which has</div><div class="clear"></div>
<div class="linenb">&nbsp;280</div><div class="codeline">theoretical guarantees since it is based on linear-algebraic ideas such as <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [DVD, SD, Sad, Sod, Syd, SSD, STD, SVG, SVN, Sid, VD, Svn, S VD] (6377) [lt:en:MORFOLOGIK_RULE_EN_GB]">SVD</span>,</div><div class="clear"></div>
<div class="linenb">&nbsp;281</div><div class="codeline">the correctness of \texttt{word2vec} is far less clear. In this thesis, we</div><div class="clear"></div>
<div class="linenb">&nbsp;282</div><div class="codeline">attempt to provide a <span class="keyword1">\emph</span>{linguistically} as well as <span class="keyword1">\emph</span>{mathematically}</div><div class="clear"></div>
<div class="linenb">&nbsp;283</div><div class="codeline">motivated explanation for the correctness of \texttt{word2vec}. We begin with a</div><div class="clear"></div>
<div class="linenb">&nbsp;284</div><div class="codeline">deep dive into the \texttt{word2vec} implementation. Following this, we chase a</div><div class="clear"></div>
<div class="linenb">&nbsp;285</div><div class="codeline"><span class="keyword1">\emph</span>{linguistic} theory of meaning, by considering <span class="keyword1">\emph</span>{Montague semantics}</div><div class="clear"></div>
<div class="linenb">&nbsp;286</div><div class="codeline">\cite{sep-montague-semantics}. Developing on this idea, we borrow the tools of</div><div class="clear"></div>
<div class="linenb">&nbsp;287</div><div class="codeline"><span class="keyword1">\emph</span>{Abstract Interpretation} \cite{cousout1996abstract}, a general framework</div><div class="clear"></div>
<div class="linenb">&nbsp;288</div><div class="codeline">enabling the construction and the soundness proof of approximated semantics of</div><div class="clear"></div>
<div class="linenb">&nbsp;289</div><div class="codeline">programs. We recall here its core features, which is used to approximate the</div><div class="clear"></div>
<div class="linenb">&nbsp;290</div><div class="codeline">(formal) meaning/semantics of a program.  A core principle in the Abstract</div><div class="clear"></div>
<div class="linenb">&nbsp;291</div><div class="codeline">Interpretation theory is that all kinds of semantics can be expressed within</div><div class="clear"></div>
<div class="linenb">&nbsp;292</div><div class="codeline">the framework of <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [fix points] (7143) [lt:en:MORFOLOGIK_RULE_EN_GB]">fixpoints</span> of monotonic operators in partially ordered</div><div class="clear"></div>
<div class="linenb">&nbsp;293</div><div class="codeline">structures.  In this thesis, we use ideas from abstract interpretation to</div><div class="clear"></div>
<div class="linenb">&nbsp;294</div><div class="codeline">propose a scheme to extract <span class="keyword1">\emph</span>{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Montague] (7299) [lt:en:MORFOLOGIK_RULE_EN_GB]">Montagueian</span> semantics} from</div><div class="clear"></div>
<div class="linenb">&nbsp;295</div><div class="codeline">\texttt{word2vec}, and evaluate the performance of our proposed system.</div><div class="clear"></div>
<div class="linenb">&nbsp;296</div><div class="codeline">Finally, we generalize \texttt{word2vec} far beyond its original setting.</div><div class="clear"></div>
<div class="linenb">&nbsp;297</div><div class="codeline">Concretely, we tackle the following questions:</div><div class="clear"></div>
<div class="linenb">&nbsp;298</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;299</div><div class="codeline"><span class="keyword2">\begin{enumerate}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;300</div><div class="codeline">    <span class="keyword1">\item</span> How \texttt{word2vec} <span class="keyword1">\emph</span>{really} works, including an</div><div class="clear"></div>
<div class="linenb">&nbsp;301</div><div class="codeline">        investigation of all the tricks that are used in its reference C</div><div class="clear"></div>
<div class="linenb">&nbsp;302</div><div class="codeline">        implementation and the bearings they have on the quality of the</div><div class="clear"></div>
<div class="linenb">&nbsp;303</div><div class="codeline">        generated word vectors. This is answered in \autoref{chapter:<span class="highlight-spelling" title="Possible spelling mistake found (7752) [lt:en:MORFOLOGIK_RULE_EN_GB]">deep-dive-wtov}</span>,</div><div class="clear"></div>
<div class="linenb">&nbsp;304</div><div class="codeline">        where we <span class="highlight-spelling" title="Possible spelling mistake. 'analyze' is American English.. Suggestions: [analyse] (7785) [lt:en:MORFOLOGIK_RULE_EN_GB]">analyze</span> the \texttt{word2vec} sources and extract insights from this process.</div><div class="clear"></div>
<div class="linenb">&nbsp;305</div><div class="codeline">    <span class="keyword1">\item</span> What is a general theory of meaning that can be adapted to</div><div class="clear"></div>
<div class="linenb">&nbsp;306</div><div class="codeline">        statistical machine learning? Why is abstract interpretation a</div><div class="clear"></div>
<div class="linenb">&nbsp;307</div><div class="codeline">        potential candidate? This is answered in \autoref{chapter:abstract-interpretation},</div><div class="clear"></div>
<div class="linenb">&nbsp;308</div><div class="codeline">        where we explain Abstract Interpretation, and link this theory to Montague semantics.</div><div class="clear"></div>
<div class="linenb">&nbsp;309</div><div class="codeline">    <span class="keyword1">\item</span> How can Abstract Interpretation be melded into the \texttt{word2vec}</div><div class="clear"></div>
<div class="linenb">&nbsp;310</div><div class="codeline">        training regime? This is answered in</div><div class="clear"></div>
<div class="linenb">&nbsp;311</div><div class="codeline">        \autoref{chapter:fuzzy-set-representation}, where we create new</div><div class="clear"></div>
<div class="linenb">&nbsp;312</div><div class="codeline">        <span class="keyword1">\emph</span>{fuzzy embeddings} and evaluate their effectiveness.</div><div class="clear"></div>
<div class="linenb">&nbsp;313</div><div class="codeline">    <span class="keyword1">\item</span> What is the largest setting where \texttt{word2vec} can be</div><div class="clear"></div>
<div class="linenb">&nbsp;314</div><div class="codeline">        implemented? In particular, how much of the mathematical structure of a</div><div class="clear"></div>
<div class="linenb">&nbsp;315</div><div class="codeline">        vector is exploited by \texttt{word2vec} embeddings, and by how much</div><div class="clear"></div>
<div class="linenb">&nbsp;316</div><div class="codeline">        can we generalize this training regime? This is answered in</div><div class="clear"></div>
<div class="linenb">&nbsp;317</div><div class="codeline">        \autoref{chapter:geometrization} where we generalize \texttt{word2vec} to arbitrary Lie groups.</div><div class="clear"></div>
<div class="linenb">&nbsp;318</div><div class="codeline"><span class="keyword2">\end{enumerate}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;319</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;320</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;321</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;322</div><div class="codeline">\<span class="highlight-sh" title="If a section has sub-sections, it should have more than one such sub-section. [sh:nsubdiv]"><span class="highlight-sh" title="This chapter is very short (about 1 words). You should consider merging it with another section or make it longer. [sh:seclen]">chapter</span></span>{Background}</div><div class="clear"></div>
<div class="linenb">&nbsp;323</div><div class="codeline">\<span class="highlight-sh" title="Avoid stacked headings, i.e. consecutive headings without text in between. [sh:stacked]">section</span>{A deep dive into \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (8782) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>wtov}</div><div class="clear"></div>
<div class="linenb">&nbsp;324</div><div class="codeline"><span class="keyword1">\label</span>{chapter:deep-dive-wtov}</div><div class="clear"></div>
<div class="linenb">&nbsp;325</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;326</div><div class="codeline">\epigraph{Understanding an idea meant entangling it so thoroughly with all the</div><div class="clear"></div>
<div class="linenb">&nbsp;327</div><div class="codeline">other symbols in your mind that it changed the way you thought about</div><div class="clear"></div>
<div class="linenb">&nbsp;328</div><div class="codeline">everything.}{<span class="highlight" title="Add a space between sentences. Suggestions: [ Greg] (8938) [lt:en:SENTENCE_WHITESPACE]">Greg</span> <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Egan., Egan!, Egan?, Egan:, Egan,, Egan;] (8943) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>Egan}</div><div class="clear"></div>
<div class="linenb">&nbsp;329</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;330</div><div class="codeline"><span class="comment"><span class="comment">% \textinit{T}he popular opinion in the NLP literature</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;331</div><div class="codeline">The popular opinion in the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Nap, Nip, Alp, LP, Np, PLP, N LP] (8976) [lt:en:MORFOLOGIK_RULE_EN_GB]">NLP</span> literature</div><div class="clear"></div>
<div class="linenb">&nbsp;332</div><div class="codeline">is that that systems such as \texttt{word2vec} learn</div><div class="clear"></div>
<div class="linenb">&nbsp;333</div><div class="codeline">vector representations <span class="highlight-sh" title="Put all references in a single \cite command [sh:c:mul]">\cite{levy2014neural}, \cite</span>{pennington2014glove}.  A word</div><div class="clear"></div>
<div class="linenb">&nbsp;334</div><div class="codeline">embedding learned as a vector, where words with a similar meaning can be given</div><div class="clear"></div>
<div class="linenb">&nbsp;335</div><div class="codeline">similar vectors. More specifically, the aim of providing vector representations</div><div class="clear"></div>
<div class="linenb">&nbsp;336</div><div class="codeline">to words is to understand that words that occur in <span class="keyword1">\textit</span>{similar contexts}</div><div class="clear"></div>
<div class="linenb">&nbsp;337</div><div class="codeline">should be given ``similar'' vectors. <span class="highlight" title="“While” at the beginning of a sentence usually requires a 2nd clause. Maybe a comma, question or exclamation mark is missing, or the sentence is incomplete and should be joined with the following sentence. (9340) [lt:en:SENTENCE_FRAGMENT]">While</span> \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (9347) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> was not the first mechanism to</div><div class="clear"></div>
<div class="linenb">&nbsp;338</div><div class="codeline">think of embedding words in a vector space</div><div class="clear"></div>
<div class="linenb">&nbsp;339</div><div class="codeline">\cite{baroni2010distributional,bruni2012distributional}. However, it is the</div><div class="clear"></div>
<div class="linenb">&nbsp;340</div><div class="codeline">first which achieved an efficient regime for training and the requisite</div><div class="clear"></div>
<div class="linenb">&nbsp;341</div><div class="codeline">reduction in dimensionality for storing and <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [evolution, evaluation] (9566) [lt:en:MORFOLOGIK_RULE_EN_GB]">evalution</span>, thereby making it a</div><div class="clear"></div>
<div class="linenb">&nbsp;342</div><div class="codeline">benchmark for modern natural language processing. However, few in-depth <span class="highlight" title="Do not mix variants of the same word ('analyse' and 'analyze') within a single text.. Suggestions: [analyze] (9669) [lt:en:EN_WORD_COHERENCY]"></span>analyses</div><div class="clear"></div>
<div class="linenb">&nbsp;343</div><div class="codeline">of the model and <span class="keyword1">\textit</span>{why} it is accurate in downstream tasks and efficient</div><div class="clear"></div>
<div class="linenb">&nbsp;344</div><div class="codeline">to train made it an important development in the field.</div><div class="clear"></div>
<div class="linenb">&nbsp;345</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;346</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;347</div><div class="codeline">Hence, this forms as the launching point for our study. We will</div><div class="clear"></div>
<div class="linenb">&nbsp;348</div><div class="codeline">first describe the popular description of the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [algorithm] (9916) [lt:en:MORFOLOGIK_RULE_EN_GB]">algorith</span> derived from</div><div class="clear"></div>
<div class="linenb">&nbsp;349</div><div class="codeline">\cite{mikolov2013efficient}. Next, we dissect the</div><div class="clear"></div>
<div class="linenb">&nbsp;350</div><div class="codeline">source code of \texttt{word2vec}. We find that there are several open questions</div><div class="clear"></div>
<div class="linenb">&nbsp;351</div><div class="codeline">about the relationship between the algorithms, pseudocodes, and descriptions</div><div class="clear"></div>
<div class="linenb">&nbsp;352</div><div class="codeline">available as opposed to the actual implementation of the \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (10170) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> algorithms.</div><div class="clear"></div>
<div class="linenb">&nbsp;353</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Therefore, Wherefore, THere fore] (10187) [lt:en:MORFOLOGIK_RULE_EN_GB]">THerefore</span>, armed with detailed knowledge of the training mechanism from the</div><div class="clear"></div>
<div class="linenb">&nbsp;354</div><div class="codeline">codebase, we lay out the list of open questions in the design of</div><div class="clear"></div>
<div class="linenb">&nbsp;355</div><div class="codeline">\texttt{word2vec}, the mathematical framework it may be trying to represent, and</div><div class="clear"></div>
<div class="linenb">&nbsp;356</div><div class="codeline">the linguistic significance of that framework, beyond <span class="keyword1">\textit</span>{the vector</div><div class="clear"></div>
<div class="linenb">&nbsp;357</div><div class="codeline">  representation of words}. The focus of these questions extends beyond just the</div><div class="clear"></div>
<div class="linenb">&nbsp;358</div><div class="codeline">training and touches upon interpretation, evaluation, and analysis of the output</div><div class="clear"></div>
<div class="linenb">&nbsp;359</div><div class="codeline">of the unsupervised training mechanism.</div><div class="clear"></div>
<div class="linenb">&nbsp;360</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;361</div><div class="codeline">To answer these questions, we take a deep-dive into <span class="highlight" title="If the text is a generality, 'of the' is not necessary. Do you mean 'some'?. Suggestions: [some] (10719) [lt:en:SOME_OF_THE]">some of the</span> possible</div><div class="clear"></div>
<div class="linenb">&nbsp;362</div><div class="codeline">mathematical theories that might be help provide relevant insight into both the</div><div class="clear"></div>
<div class="linenb">&nbsp;363</div><div class="codeline">performance and the significance of the current training regime. These theories</div><div class="clear"></div>
<div class="linenb">&nbsp;364</div><div class="codeline">include:</div><div class="clear"></div>
<div class="linenb">&nbsp;365</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;366</div><div class="codeline">  <span class="keyword1">\item</span> The theory of abstract interpretation as model of semantic</div><div class="clear"></div>
<div class="linenb">&nbsp;367</div><div class="codeline">    representation which connects <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Montague, montage, Montagu] (11005) [lt:en:MORFOLOGIK_RULE_EN_GB]">montague</span> semantics and the hierarchy of words</div><div class="clear"></div>
<div class="linenb">&nbsp;368</div><div class="codeline">    to the distributional <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [domain, domino, doming, do min] (11077) [lt:en:MORFOLOGIK_RULE_EN_GB]">domin</span>, detailed  in</div><div class="clear"></div>
<div class="linenb">&nbsp;369</div><div class="codeline">    \autoref{chapter:abstract-interpretation}</div><div class="clear"></div>
<div class="linenb">&nbsp;370</div><div class="codeline"> <span class="highlight" title="Put a space after the comma, but not before the comma. Suggestions: [,] (11134) [lt:en:COMMA_PARENTHESIS_WHITESPACE]"> <span class="keyword1">\item</span> ,</span> and one possible implementation of the notion of abstract</div><div class="clear"></div>
<div class="linenb">&nbsp;371</div><div class="codeline">    interpretation to rethink word vector as fuzzy set representations, detailed</div><div class="clear"></div>
<div class="linenb">&nbsp;372</div><div class="codeline">    in \autoref{chapter:fuzzy-set-representation}.</div><div class="clear"></div>
<div class="linenb">&nbsp;373</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;374</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;375</div><div class="codeline"><span class="keyword1">\subsection</span>{\<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (11320) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> in the Literature}</div><div class="clear"></div>
<div class="linenb">&nbsp;376</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;377</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htb]</div><div class="clear"></div>
<div class="linenb">&nbsp;378</div><div class="codeline"><span class="keyword2">\begin{minted}</span>[linenos]{cpp}</div><div class="clear"></div>
<div class="linenb">&nbsp;379</div><div class="codeline">Maintain a word -&gt; vector mapping.</div><div class="clear"></div>
<div class="linenb">&nbsp;380</div><div class="codeline">while(1) {</div><div class="clear"></div>
<div class="linenb">&nbsp;381</div><div class="codeline">  vf = vector corresponding to focus word</div><div class="clear"></div>
<div class="linenb">&nbsp;382</div><div class="codeline">  vc = vector corresponding to context word</div><div class="clear"></div>
<div class="linenb">&nbsp;383</div><div class="codeline">  train such that (vc . vf = 1)</div><div class="clear"></div>
<div class="linenb">&nbsp;384</div><div class="codeline">  for(0 &lt;= i &lt; negative samples):</div><div class="clear"></div>
<div class="linenb">&nbsp;385</div><div class="codeline">  vneg = vector of word *not* in context</div><div class="clear"></div>
<div class="linenb">&nbsp;386</div><div class="codeline">  train such that (vf . vneg = 0)</div><div class="clear"></div>
<div class="linenb">&nbsp;387</div><div class="codeline">}</div><div class="clear"></div>
<div class="linenb">&nbsp;388</div><div class="codeline"><span class="keyword2">\end{minted}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;389</div><div class="codeline"><span class="keyword1">\caption</span>{word2vec:  high-level <span class="keyword1">\emph</span>{incorrect} pseudocode. This is the popular</div><div class="clear"></div>
<div class="linenb">&nbsp;390</div><div class="codeline">    explanation of available on Wikipedia and the TensorFlow page.}</div><div class="clear"></div>
<div class="linenb">&nbsp;391</div><div class="codeline"><span class="keyword1">\label</span>{<span class="highlight-sh" title="Figure fig:wrong-w2v-pseudocode is never referenced in the text [sh:figref]">f</span>ig:wrong-w2v-pseudocode}</div><div class="clear"></div>
<div class="linenb">&nbsp;392</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;393</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;394</div><div class="codeline"><span class="comment"><span class="comment">% TODO: fix the wikipedia implementation</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;395</div><div class="codeline"><span class="comment"><span class="comment">% Indeed, if I google "word2vec skipgram", the results I get are:</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;396</div><div class="codeline"><span class="comment"><span class="comment">% - [The wikipedia page which describes the algorithm on a high level](https://en.wikipedia.org/wiki/Word2vec#Training_algorithm)</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;397</div><div class="codeline"><span class="comment"><span class="comment">% - [The tensorflow page with the same explanation](https://www.tensorflow.org/tutorials/representation/word2vec)</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;398</div><div class="codeline"><span class="comment"><span class="comment">% - [The towards data science blog which describes the same algorithm](https://towardsdatascience.com/word2vec-skip-gram-model-part-1-intuition-78614e4d6e0b)</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;399</div><div class="codeline"><span class="comment"><span class="comment">%</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;400</div><div class="codeline"><span class="comment"><span class="comment">% The list goes on. However, __every single one of these implementations is wrong__.</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;401</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;402</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htb]</div><div class="clear"></div>
<div class="linenb">&nbsp;403</div><div class="codeline">  <span class="keyword1">\includegraphics</span>[width=\textwidth]{./w2v-diagram-from-paper.png}</div><div class="clear"></div>
<div class="linenb">&nbsp;404</div><div class="codeline">  <span class="keyword1">\caption</span>{The diagram provided as an approximation of the word2vec training</div><div class="clear"></div>
<div class="linenb">&nbsp;405</div><div class="codeline">    mechanisms CBOW and Skip-gram, and the caption provided in the paper</div><div class="clear"></div>
<div class="linenb">&nbsp;406</div><div class="codeline">    \cite{mikolov2013efficient}. The diagram is clearly meant to be a</div><div class="clear"></div>
<div class="linenb">&nbsp;407</div><div class="codeline">    simplified representation of the algorithm, as the caption only shows the</div><div class="clear"></div>
<div class="linenb">&nbsp;408</div><div class="codeline">    method of prediction of the `input' and `output' words.}</div><div class="clear"></div>
<div class="linenb">&nbsp;409</div><div class="codeline">  <span class="keyword1">\label</span>{<span class="highlight-sh" title="Figure fig:w2v-diagram-from-paper is never referenced in the text [sh:figref]">f</span>ig:w2v-diagram-from-paper}</div><div class="clear"></div>
<div class="linenb">&nbsp;410</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;411</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;412</div><div class="codeline">The algorithms known as \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (11372) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> in literature today are a product of two papers on</div><div class="clear"></div>
<div class="linenb">&nbsp;413</div><div class="codeline">efficient distributed representations of lexical semantics, namely</div><div class="clear"></div>
<div class="linenb">&nbsp;414</div><div class="codeline">\cite{mikolov2013efficient} and \cite{mikolov2013distributed}. Both papers</div><div class="clear"></div>
<div class="linenb">&nbsp;415</div><div class="codeline">summarize aspects of the entire codebase including a summary of training,</div><div class="clear"></div>
<div class="linenb">&nbsp;416</div><div class="codeline">tuning, parameters and <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [hyper parameters] (11617) [lt:en:MORFOLOGIK_RULE_EN_GB]">hyperparameters</span>, evaluation metrics, qualitative and</div><div class="clear"></div>
<div class="linenb">&nbsp;417</div><div class="codeline">quantitative analyses, as well as some <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [linguistic] (11709) [lt:en:MORFOLOGIK_RULE_EN_GB]">lingusitic</span> insights. In combination, the</div><div class="clear"></div>
<div class="linenb">&nbsp;418</div><div class="codeline">literature in itself is too terse to extract the pseudocode from. However, both</div><div class="clear"></div>
<div class="linenb">&nbsp;419</div><div class="codeline">these publications provide a graphical <span class="keyword1">\textit</span>{approximation} of their training</div><div class="clear"></div>
<div class="linenb">&nbsp;420</div><div class="codeline">mechanism, which is provided in \autoref{fig:w2v-diagram-from-paper}.</div><div class="clear"></div>
<div class="linenb">&nbsp;421</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;422</div><div class="codeline"><span class="highlight" title="Did you forget a comma after a conjunctive/linking adverb?. Suggestions: [Also,] (11962) [lt:en:SENT_START_CONJUNCTIVE_LINKING_ADVERB_COMMA]">Also</span> note, the classic explanation of \texttt{word2vec}, in skip-gram, with negative</div><div class="clear"></div>
<div class="linenb">&nbsp;423</div><div class="codeline">sampling is the pseudocode shown in \autoref{fig:wrong-w2v-pseudocode}, based on</div><div class="clear"></div>
<div class="linenb">&nbsp;424</div><div class="codeline">the explanations available on<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> \href{https://en.wi</span>kipedia.org/wiki/Word2vec#Training_algorithm}{Wikipedia}</div><div class="clear"></div>
<div class="linenb">&nbsp;425</div><div class="codeline">and the<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> \href{https://www.te</span>nsorflow.org/tutorials/representation/word2vec}{TensorFlow} re-implementation.</div><div class="clear"></div>
<div class="linenb">&nbsp;426</div><div class="codeline">Interestingly, the simplified diagrammatic process and</div><div class="clear"></div>
<div class="linenb">&nbsp;427</div><div class="codeline">the pseudocode are nearly isomorphic, they represent the same phenomenon.</div><div class="clear"></div>
<div class="linenb">&nbsp;428</div><div class="codeline">However, the original \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (12456) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> \texttt{C} implementation does not do what is explained above.</div><div class="clear"></div>
<div class="linenb">&nbsp;429</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;430</div><div class="codeline">One of the main offerings of the paper presented above was the actual lexical</div><div class="clear"></div>
<div class="linenb">&nbsp;431</div><div class="codeline">distributional representation, a list of words and their vector counterparts</div><div class="clear"></div>
<div class="linenb">&nbsp;432</div><div class="codeline">which were irrevocably the best performing representations developed for English</div><div class="clear"></div>
<div class="linenb">&nbsp;433</div><div class="codeline">data at the time. So most downstream implementations based on these word vectors</div><div class="clear"></div>
<div class="linenb">&nbsp;434</div><div class="codeline">used the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [retrained, p retrained, pre trained] (12842) [lt:en:MORFOLOGIK_RULE_EN_GB]">pretrained</span> embeddings directly.</div><div class="clear"></div>
<div class="linenb">&nbsp;435</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;436</div><div class="codeline">All other analyses and implementations of the \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (12922) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> codebase either (a) directly</div><div class="clear"></div>
<div class="linenb">&nbsp;437</div><div class="codeline">invoke the original C implementation of \texttt{word2vec},</div><div class="clear"></div>
<div class="linenb">&nbsp;438</div><div class="codeline">or (b) invoke the \texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [genesis, denim, genie, genii, sensum] (13024) [lt:en:MORFOLOGIK_RULE_EN_GB]">gensim}</span> implementation \cite{vrehuuvrek2011gensim},</div><div class="clear"></div>
<div class="linenb">&nbsp;439</div><div class="codeline">which is <span class="keyword1">\emph</span>{transliterated} from the C source to the extent</div><div class="clear"></div>
<div class="linenb">&nbsp;440</div><div class="codeline">that the variables names are the same as that of the C implementation.</div><div class="clear"></div>
<div class="linenb">&nbsp;441</div><div class="codeline">\todo{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [genesis, denim, genie, genii, sensum] (13178) [lt:en:MORFOLOGIK_RULE_EN_GB]">gensim</span> implementation <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [links., links!, links?, links:, links,, links;] (13200) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>links}</div><div class="clear"></div>
<div class="linenb">&nbsp;442</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;443</div><div class="codeline">Therefore, if we are to raise questions about what the \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (13263) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> algorithm aims to</div><div class="clear"></div>
<div class="linenb">&nbsp;444</div><div class="codeline">accomplish in the space of word representations, it is imperative to perform a</div><div class="clear"></div>
<div class="linenb">&nbsp;445</div><div class="codeline">deep-dive into the source code itself.</div><div class="clear"></div>
<div class="linenb">&nbsp;446</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;447</div><div class="codeline"><span class="keyword1">\subsection</span>{\<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (13406) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> in the sources}</div><div class="clear"></div>
<div class="linenb">&nbsp;448</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;449</div><div class="codeline">We <span class="highlight-spelling" title="Possible spelling mistake. 'analyze' is American English.. Suggestions: [analyse] (13430) [lt:en:MORFOLOGIK_RULE_EN_GB]">analyze</span> the original C implementation of \texttt{word2vec}, to point out</div><div class="clear"></div>
<div class="linenb">&nbsp;450</div><div class="codeline">salient features, curious implementation decisions and bugs in the</div><div class="clear"></div>
<div class="linenb">&nbsp;451</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [implementation sources] (13561) [lt:en:MORFOLOGIK_RULE_EN_GB]">implementation\footnote{sources</span> taken from</div><div class="clear"></div>
<div class="linenb">&nbsp;452</div><div class="codeline">\url{https://github.com/tmikolov/word2vec/blob/master/word2vec.c}}.</div><div class="clear"></div>
<div class="linenb">&nbsp;453</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;454</div><div class="codeline">This necessitates interleaving high level explanations with direct snippets of</div><div class="clear"></div>
<div class="linenb">&nbsp;455</div><div class="codeline">the C code in order to understand wherein the difference between the pseudocode</div><div class="clear"></div>
<div class="linenb">&nbsp;456</div><div class="codeline">and the actual code lies, in order to improve the state of surrounding</div><div class="clear"></div>
<div class="linenb">&nbsp;457</div><div class="codeline">literature and demystify the differences between the implementation and its</div><div class="clear"></div>
<div class="linenb">&nbsp;458</div><div class="codeline">understanding.</div><div class="clear"></div>
<div class="linenb">&nbsp;459</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;460</div><div class="codeline">The core training loop of \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (13947) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> (trained using negative sampling, in skip-gram mode)</div><div class="clear"></div>
<div class="linenb">&nbsp;461</div><div class="codeline">ingests a corpus, and then attempts to learn <span class="keyword1">\emph</span>{two} representations for a</div><div class="clear"></div>
<div class="linenb">&nbsp;462</div><div class="codeline">given word, called as the positive and negative representation. At a high</div><div class="clear"></div>
<div class="linenb">&nbsp;463</div><div class="codeline">level, the python pseudocode at \autoref{fig:w2v-py-pseudocode} explains the</div><div class="clear"></div>
<div class="linenb">&nbsp;464</div><div class="codeline">implementation of \texttt{word2vec}.</div><div class="clear"></div>
<div class="linenb">&nbsp;465</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;466</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;467</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Initialization}</div><div class="clear"></div>
<div class="linenb">&nbsp;468</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;469</div><div class="codeline">The first main difference between the simplified representation and the actual</div><div class="clear"></div>
<div class="linenb">&nbsp;470</div><div class="codeline">code is the presence of <span class="keyword1">\textit</span>{two} vectors for each word instead of one. These</div><div class="clear"></div>
<div class="linenb">&nbsp;471</div><div class="codeline">vectors are:</div><div class="clear"></div>
<div class="linenb">&nbsp;472</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;473</div><div class="codeline">(a) An array called \texttt{syn0} holds the vector embedding of a word when it occurs</div><div class="clear"></div>
<div class="linenb">&nbsp;474</div><div class="codeline">as a <span class="keyword1">\emph</span>{focus word}. This is array random initialized.</div><div class="clear"></div>
<div class="linenb">&nbsp;475</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;476</div><div class="codeline"><span class="keyword2">\begin{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [minted] (14557) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>minted}</span>{cpp}</div><div class="clear"></div>
<div class="linenb">&nbsp;477</div><div class="codeline">//<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Nikolova, trichology] (14570) [lt:en:MORFOLOGIK_RULE_EN_GB]">tmikolov</span>/word2vec/blob/master/word2vec.c#</span>L369</div><div class="clear"></div>
<div class="linenb">&nbsp;478</div><div class="codeline">for (a = 0; a &lt; <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'vocab _ size' is correct. (14632) [lt:en:WORD_CONTAINS_UNDERSCORE]">vocab_size</span>; a++) for (b = 0; b &lt; layer1_size; b++) {</div><div class="clear"></div>
<div class="linenb">&nbsp;479</div><div class="codeline"> <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'next _ random' is correct. (14685) [lt:en:WORD_CONTAINS_UNDERSCORE]">next_random</span> = <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'next _ random' is correct. (14699) [lt:en:WORD_CONTAINS_UNDERSCORE]">next_random</span> * (unsigned <span class="highlight" title="Possible typo: you repeated a word. Suggestions: [long] (14723) [lt:en:ENGLISH_WORD_REPEAT_RULE]">long long</span>)25214903917 + 11;</div><div class="clear"></div>
<div class="linenb">&nbsp;480</div><div class="codeline"> syn0[a * layer1_size + b] =</div><div class="clear"></div>
<div class="linenb">&nbsp;481</div><div class="codeline"> (((<span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'next _ random' is correct. (14784) [lt:en:WORD_CONTAINS_UNDERSCORE]">next_random</span> &amp; 0xFFFF) / (real)65536) <span class="highlight" title="Consider using an m-dash if you do not want to join two words.. Suggestions: [—] (14821) [lt:en:DASH_RULE]">-</span> 0.5) / layer1_size;</div><div class="clear"></div>
<div class="linenb">&nbsp;482</div><div class="codeline">}</div><div class="clear"></div>
<div class="linenb">&nbsp;483</div><div class="codeline"><span class="keyword2">\end{minted}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;484</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;485</div><div class="codeline">(b) Another array called \texttt{syn1neg} holds the vector of a word when it occurs</div><div class="clear"></div>
<div class="linenb">&nbsp;486</div><div class="codeline">as a <span class="keyword1">\emph</span>{context word}. This is zero initialized.</div><div class="clear"></div>
<div class="linenb">&nbsp;487</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;488</div><div class="codeline"><span class="keyword2">\begin{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [minted] (14973) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>minted}</span>{cpp}</div><div class="clear"></div>
<div class="linenb">&nbsp;489</div><div class="codeline">//<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Nikolova, trichology] (14986) [lt:en:MORFOLOGIK_RULE_EN_GB]">tmikolov</span>/word2vec/blob/master/word2vec.c#</span>L365</div><div class="clear"></div>
<div class="linenb">&nbsp;490</div><div class="codeline">for (a = 0; a &lt; <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'vocab _ size' is correct. (15048) [lt:en:WORD_CONTAINS_UNDERSCORE]">vocab_size</span>; a++) for (b = 0; b &lt; layer1_size; b++)</div><div class="clear"></div>
<div class="linenb">&nbsp;491</div><div class="codeline">syn1neg[a * layer1_size + b] = 0;</div><div class="clear"></div>
<div class="linenb">&nbsp;492</div><div class="codeline"><span class="keyword2">\end{<span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [minted., minted!, minted?, minted:, minted,, minted;] (15133) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>minted}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;493</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;494</div><div class="codeline">Note that the array name \texttt{syn1neg} is used only in the skip-gram negative</div><div class="clear"></div>
<div class="linenb">&nbsp;495</div><div class="codeline">sampling representation (<span class="highlight-spelling" title="Possible spelling mistake. Did you mean 'referred', the past tense form of the verb 'refer'?. Suggestions: [referred, referee, revered, refereed, refired, refer ed] (15238) [lt:en:MORFOLOGIK_RULE_EN_GB]">refered</span> to hereafter as <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Signs, Sons, Sins, Sans, Suns] (15262) [lt:en:MORFOLOGIK_RULE_EN_GB]">SGNS</span>). Other training regimes</div><div class="clear"></div>
<div class="linenb">&nbsp;496</div><div class="codeline">such as hierarchical <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [soft max] (15313) [lt:en:MORFOLOGIK_RULE_EN_GB]">softmax</span> also train on two vectors, named \texttt{syn1}.</div><div class="clear"></div>
<div class="linenb">&nbsp;497</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Infant, Intact, Infect, Infarct, Infract, In fact] (15360) [lt:en:MORFOLOGIK_RULE_EN_GB]">Infact</span>, there are similar corollaries in the training and update of these arrays</div><div class="clear"></div>
<div class="linenb">&nbsp;498</div><div class="codeline">as well. For the sake of brevity, we showcase only the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Signs, Sons, Sins, Sans, Suns] (15496) [lt:en:MORFOLOGIK_RULE_EN_GB]">SGNS</span> algorithm as it is</div><div class="clear"></div>
<div class="linenb">&nbsp;499</div><div class="codeline">the most prominent.</div><div class="clear"></div>
<div class="linenb">&nbsp;500</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;501</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Training}</div><div class="clear"></div>
<div class="linenb">&nbsp;502</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;503</div><div class="codeline">During training (<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Signs, Sons, Sins, Sans, Suns] (15568) [lt:en:MORFOLOGIK_RULE_EN_GB]">SGNS</span> detailed here, though other cases are</div><div class="clear"></div>
<div class="linenb">&nbsp;504</div><div class="codeline">also similar), we first pick a focus word. This is held constant throughout</div><div class="clear"></div>
<div class="linenb">&nbsp;505</div><div class="codeline">the positive and negative sample training. The gradients of the focus vector</div><div class="clear"></div>
<div class="linenb">&nbsp;506</div><div class="codeline">are accumulated in a buffer, and are applied to the focus word</div><div class="clear"></div>
<div class="linenb">&nbsp;507</div><div class="codeline"><span class="keyword1">\emph</span>{after} it has been affected by both positive and negative samples.</div><div class="clear"></div>
<div class="linenb">&nbsp;508</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;509</div><div class="codeline">In the code snippet below, line number \circled{4} decides whether we are</div><div class="clear"></div>
<div class="linenb">&nbsp;510</div><div class="codeline">picking a positive sample (\texttt{d = 0}) or a negative sample (\texttt{d &gt; 0}).</div><div class="clear"></div>
<div class="linenb">&nbsp;511</div><div class="codeline">If we are picking a positive sample, then we expect</div><div class="clear"></div>
<div class="linenb">&nbsp;512</div><div class="codeline">at \circled{5} to find the dot-product with the \texttt{word} to be \texttt{1}.</div><div class="clear"></div>
<div class="linenb">&nbsp;513</div><div class="codeline">On the other hand, if we are picking a negative sample, then we expect at \circled{10} to pick</div><div class="clear"></div>
<div class="linenb">&nbsp;514</div><div class="codeline">a random word, and at \circled{13} for the dot-product to be zero. \circled{20} computes</div><div class="clear"></div>
<div class="linenb">&nbsp;515</div><div class="codeline">the dot-product between the focus word and the picked context word.</div><div class="clear"></div>
<div class="linenb">&nbsp;516</div><div class="codeline">\circled{23}-\circled{25} computes the gradient $g \equiv \sigma(\texttt{label} - \texttt{focus} \cdot \texttt{ctx})$.</div><div class="clear"></div>
<div class="linenb">&nbsp;517</div><div class="codeline">\circled{30}-\circled{31} performs the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [backdrop, back prop] (16398) [lt:en:MORFOLOGIK_RULE_EN_GB]">backprop</span> of the loss of the focus and context word. Note that</div><div class="clear"></div>
<div class="linenb">&nbsp;518</div><div class="codeline">the gradient of the focus word is stored into a buffer \texttt{neu1e}. This ensures that the gradient of</div><div class="clear"></div>
<div class="linenb">&nbsp;519</div><div class="codeline">the focus word is held constant <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [through, thought, through t] (16588) [lt:en:MORFOLOGIK_RULE_EN_GB]">throught</span> the positive and negative samples. Finally, on</div><div class="clear"></div>
<div class="linenb">&nbsp;520</div><div class="codeline">\circled{36}, the buffered gradient \texttt{neu1e} is propagated into the focus word.</div><div class="clear"></div>
<div class="linenb">&nbsp;521</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;522</div><div class="codeline"> <span class="comment">% \todo{check for correctness: tmikolov/word2vec/blob/master/word2vec.c#L478, the</span></div><div class="clear"></div>
<div class="linenb">&nbsp;523</div><div class="codeline"> <span class="comment">% formula should involve neu1, not syn0}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;524</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;525</div><div class="codeline"><span class="keyword2">\begin{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Minted] (16713) [lt:en:UPPERCASE_SENTENCE_START]">minted}</span></span>[<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [linens] (16720) [lt:en:MORFOLOGIK_RULE_EN_GB]">linenos</span>]{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [cap, cup, CPU, cop, CPA, CPI, CPR, PPP, CSP, opp, app, CDP, cpl, cpd, Copp, cps, pp, c pp] (16728) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>cpp}</div><div class="clear"></div>
<div class="linenb">&nbsp;526</div><div class="codeline">  //<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Nikolova, trichology] (16737) [lt:en:MORFOLOGIK_RULE_EN_GB]">tmikolov</span>/word2vec/blob/master/word2vec.c#</span><span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [L465., L465!, L465?, L465:, L465,, L465;] (16778) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>L465</div><div class="clear"></div>
<div class="linenb">&nbsp;527</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;528</div><div class="codeline">  for (d = 0; d &lt; negative + 1; d++) {</div><div class="clear"></div>
<div class="linenb">&nbsp;529</div><div class="codeline"> // if we are performing negative sampling, in the 1st iteration,</div><div class="clear"></div>
<div class="linenb">&nbsp;530</div><div class="codeline"> // pick a word from the context and set the dot product target to 1</div><div class="clear"></div>
<div class="linenb">&nbsp;531</div><div class="codeline"> if (d == 0) {</div><div class="clear"></div>
<div class="linenb">&nbsp;532</div><div class="codeline">   target = word; label = 1;</div><div class="clear"></div>
<div class="linenb">&nbsp;533</div><div class="codeline"> } else {</div><div class="clear"></div>
<div class="linenb">&nbsp;534</div><div class="codeline">   // for all other iterations, pick a word randomly and set the dot</div><div class="clear"></div>
<div class="linenb">&nbsp;535</div><div class="codeline">   //product target to 0</div><div class="clear"></div>
<div class="linenb">&nbsp;536</div><div class="codeline">   <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'next _ random' is correct. (17105) [lt:en:WORD_CONTAINS_UNDERSCORE]">next_random</span> = <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'next _ random' is correct. (17119) [lt:en:WORD_CONTAINS_UNDERSCORE]">next_random</span> * (unsigned <span class="highlight" title="Possible typo: you repeated a word. Suggestions: [long] (17143) [lt:en:ENGLISH_WORD_REPEAT_RULE]">long long</span>)25214903917 + 11;</div><div class="clear"></div>
<div class="linenb">&nbsp;537</div><div class="codeline">   target = table<span class="highlight" title="Unpaired symbol: ']' seems to be missing (17188) [lt:en:EN_UNPAIRED_BRACKETS]">[</span>(<span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'next _ random' is correct. (17190) [lt:en:WORD_CONTAINS_UNDERSCORE]">next_random</span> <span class="highlight-sh" title="Use \og{} and \fg{} instead of &lt;&lt; and &gt;&gt;. [sh:d:007]">&gt;&gt; 16) <span class="comment">% table_size];</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;538</div><div class="codeline">   if (target == 0) target = <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'next _ random' is correct. (17239) [lt:en:WORD_CONTAINS_UNDERSCORE]">next_random</span> <span class="comment">% (vocab_size - 1) + 1;</span></div><div class="clear"></div>
<div class="linenb">&nbsp;539</div><div class="codeline">   if (target == word) continue;</div><div class="clear"></div>
<div class="linenb">&nbsp;540</div><div class="codeline">   label = 0;</div><div class="clear"></div>
<div class="linenb">&nbsp;541</div><div class="codeline"> }</div><div class="clear"></div>
<div class="linenb">&nbsp;542</div><div class="codeline"> l2 = target * layer1_size;</div><div class="clear"></div>
<div class="linenb">&nbsp;543</div><div class="codeline"> f = 0;</div><div class="clear"></div>
<div class="linenb">&nbsp;544</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;545</div><div class="codeline"> // find dot product of original vector with negative sample vector</div><div class="clear"></div>
<div class="linenb">&nbsp;546</div><div class="codeline"> // store in f</div><div class="clear"></div>
<div class="linenb">&nbsp;547</div><div class="codeline"> for (c = 0; c &lt; layer1_size; c++) f += syn0[c + l1] * syn1neg[c + l2];</div><div class="clear"></div>
<div class="linenb">&nbsp;548</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;549</div><div class="codeline"> // set g = sigmoid(f) (roughly, the actual formula is slightly more complex)</div><div class="clear"></div>
<div class="linenb">&nbsp;550</div><div class="codeline"> if (f &gt; <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'MAX _ EXP' is correct. (17581) [lt:en:WORD_CONTAINS_UNDERSCORE]">MAX_EXP</span>) g = (label <span class="highlight" title="Consider using an m-dash if you do not want to join two words.. Suggestions: [—] (17601) [lt:en:DASH_RULE]">-</span> 1) * alpha;</div><div class="clear"></div>
<div class="linenb">&nbsp;551</div><div class="codeline"> else if (f &lt; <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word '-MAX _ EXP' is correct. (17629) [lt:en:WORD_CONTAINS_UNDERSCORE]">-MAX_EXP</span>) g = (label <span class="highlight" title="Consider using an m-dash if you do not want to join two words.. Suggestions: [—] (17650) [lt:en:DASH_RULE]">-</span> 0) * alpha;</div><div class="clear"></div>
<div class="linenb">&nbsp;552</div><div class="codeline"> else g = (label <span class="highlight" title="Consider using an m-dash if you do not want to join two words.. Suggestions: [—] (17681) [lt:en:DASH_RULE]">-</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [expiable] (17683) [lt:en:MORFOLOGIK_RULE_EN_GB]">expTable</span>[(<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [in, it, into, ink, TNT, inn, mint, ant, hint, ITT, pint, tint, lint, nit, inst, Ind, Inc, Inn, Intu, Mint, NT, dint, ing, ins, intl, in t, ICT] (17693) [lt:en:MORFOLOGIK_RULE_EN_GB]">int</span>)((f + <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'MAX _ EXP' is correct. (17703) [lt:en:WORD_CONTAINS_UNDERSCORE]">MAX_EXP</span>) * (<span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'EXP _ TABLE' is correct. (17715) [lt:en:WORD_CONTAINS_UNDERSCORE]">EXP_TABLE</span>_SIZE / <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'MAX _ EXP' is correct. (17732) [lt:en:WORD_CONTAINS_UNDERSCORE]">MAX_EXP</span> / 2))]) * alpha;</div><div class="clear"></div>
<div class="linenb">&nbsp;553</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;554</div><div class="codeline"> // 1. <span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Update] (17765) [lt:en:UPPERCASE_SENTENCE_START]">update</span> the vector syn1neg,</div><div class="clear"></div>
<div class="linenb">&nbsp;555</div><div class="codeline"> // 2. DO NOT UPDATE syn0</div><div class="clear"></div>
<div class="linenb">&nbsp;556</div><div class="codeline"> // 3. STORE THE syn0 gradient in a temporary buffer neu1e</div><div class="clear"></div>
<div class="linenb">&nbsp;557</div><div class="codeline"> for (c = 0; c &lt; layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];</div><div class="clear"></div>
<div class="linenb">&nbsp;558</div><div class="codeline"> for (c = 0; c &lt; layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];</div><div class="clear"></div>
<div class="linenb">&nbsp;559</div><div class="codeline">}</div><div class="clear"></div>
<div class="linenb">&nbsp;560</div><div class="codeline">// Finally, after all samples, update syn0 from neu1e</div><div class="clear"></div>
<div class="linenb">&nbsp;561</div><div class="codeline">//<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Nikolova, trichology] (18075) [lt:en:MORFOLOGIK_RULE_EN_GB]">tmikolov</span>/word2vec/blob/master/word2vec.c#</span>L541</div><div class="clear"></div>
<div class="linenb">&nbsp;562</div><div class="codeline">// Learn weights input <span class="highlight" title="Do you wish to insert an arrow?. Suggestions: [≥, →, ⇾, ⇉, ⇒, ⇨, ⇛] (18144) [lt:en:ARROWS]">-&gt;</span> hidden</div><div class="clear"></div>
<div class="linenb">&nbsp;563</div><div class="codeline">for (c = 0; c &lt; layer1_size; c++) syn0[c + l1] += neu1e[c];</div><div class="clear"></div>
<div class="linenb">&nbsp;564</div><div class="codeline"><span class="keyword2">\end{minted}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;565</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;566</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Pseudocode Implementation}</div><div class="clear"></div>
<div class="linenb">&nbsp;567</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;568</div><div class="codeline">We outline what we have learnt from delving into the C sources</div><div class="clear"></div>
<div class="linenb">&nbsp;569</div><div class="codeline">of \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (18316) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> to provide high-level pseudocode of the algorithm.</div><div class="clear"></div>
<div class="linenb">&nbsp;570</div><div class="codeline"><span class="keyword2">\begin{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [minted python] (18372) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>minted}</span>{python}</div><div class="clear"></div>
<div class="linenb">&nbsp;571</div><div class="codeline">def learn(<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, lie, mix, fix, lid, lip, Lin, Liz, lax, lib, lux, nix, lox, lit, liq, Bix, Hix, Li, Lib, Lit, Liu, Wix, XIX, ix, lx, pix, xix, l ix] (18395) [lt:en:MORFOLOGIK_RULE_EN_GB]">lix</span>: <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [in, it, into, ink, TNT, inn, mint, ant, hint, ITT, pint, tint, lint, nit, inst, Ind, Inc, Inn, Intu, Mint, NT, dint, ing, ins, intl, in t, ICT] (18400) [lt:en:MORFOLOGIK_RULE_EN_GB]">int</span>, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, mix, Prix, Rio, fix, rim, rid, rig, Rex, rib, rip, nix, Bix, Hix, Rux, Wix, XIX, ix, pix, xix, r ix] (18405) [lt:en:MORFOLOGIK_RULE_EN_GB]">rix</span>:<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [in, it, into, ink, TNT, inn, mint, ant, hint, ITT, pint, tint, lint, nit, inst, Ind, Inc, Inn, Intu, Mint, NT, dint, ing, ins, intl, in t, ICT] (18409) [lt:en:MORFOLOGIK_RULE_EN_GB]">int</span>,<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Larry, Carr, lair, Barr, Lara, Lars, lard, lark, parr, Farr, Marr, Warr, arr, l arr] (18414) [lt:en:MORFOLOGIK_RULE_EN_GB]">larr</span>:<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Np, no, up, HP, SNP, VP, ng, nu, GNP, PNP, NPD, NY, nap, nip, WNP, IP, op, BP, EP, GP, LP, MP, N, NS, NT, NW, NZ, Na, Nb, Nd, Ne, Ni, P, RP, Up, XP, ap, mp, n, na, nm, ns, né, p, pp, n p] (18419) [lt:en:MORFOLOGIK_RULE_EN_GB]">np</span>.ar</span>ray, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [rare, Carr, rarer, Barr, parr, Farr, Marr, Warr, arr, r arr] (18429) [lt:en:MORFOLOGIK_RULE_EN_GB]">rarr</span>:<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Np, no, up, HP, SNP, VP, ng, nu, GNP, PNP, NPD, NY, nap, nip, WNP, IP, op, BP, EP, GP, LP, MP, N, NS, NT, NW, NZ, Na, Nb, Nd, Ne, Ni, P, RP, Up, XP, ap, mp, n, na, nm, ns, né, p, pp, n p] (18434) [lt:en:MORFOLOGIK_RULE_EN_GB]">np<span class="highlight-sh" title="There should be a space after a comma. [sh:d:001]"></span><span class="highlight" title="Put a space after the comma. Suggestions: [, array] (18436) [lt:en:COMMA_PARENTHESIS_WHITESPACE]">,a</span>rray</span>,</div><div class="clear"></div>
<div class="linenb">&nbsp;572</div><div class="codeline">  target: float):</div><div class="clear"></div>
<div class="linenb">&nbsp;573</div><div class="codeline">  <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (18464) [lt:en:EN_QUOTES]">"</span><span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"></span>"</span><span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"></span>"</div><div class="clear"></div>
<div class="linenb">&nbsp;574</div><div class="codeline">  gradient descent on</div><div class="clear"></div>
<div class="linenb">&nbsp;575</div><div class="codeline">  loss = (target <span class="highlight" title="Consider using an m-dash if you do not want to join two words.. Suggestions: [—] (18507) [lt:en:DASH_RULE]">-</span> dot(l, r))^2 where</div><div class="clear"></div>
<div class="linenb">&nbsp;576</div><div class="codeline">  l = <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Larry, Carr, lair, Barr, Lara, Lars, lard, lark, parr, Farr, Marr, Warr, arr, l arr] (18534) [lt:en:MORFOLOGIK_RULE_EN_GB]">larr</span>[<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, lie, mix, fix, lid, lip, Lin, Liz, lax, lib, lux, nix, lox, lit, liq, Bix, Hix, Li, Lib, Lit, Liu, Wix, XIX, ix, lx, pix, xix, l ix] (18539) [lt:en:MORFOLOGIK_RULE_EN_GB]">lix</span>]; r = <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [rare, Carr, rarer, Barr, parr, Farr, Marr, Warr, arr, r arr] (18549) [lt:en:MORFOLOGIK_RULE_EN_GB]">rarr</span>[<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, mix, Prix, Rio, fix, rim, rid, rig, Rex, rib, rip, nix, Bix, Hix, Rux, Wix, XIX, ix, pix, xix, r ix] (18554) [lt:en:MORFOLOGIK_RULE_EN_GB]">rix</span>]</div><div class="clear"></div>
<div class="linenb">&nbsp;577</div><div class="codeline">  <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (18561) [lt:en:EN_QUOTES]">"</span><span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"></span>"</span><span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"></span>"</div><div class="clear"></div>
<div class="linenb">&nbsp;578</div><div class="codeline">  dot =<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Np, no, up, HP, SNP, VP, ng, nu, GNP, PNP, NPD, NY, nap, nip, WNP, IP, op, BP, EP, GP, LP, MP, N, NS, NT, NW, NZ, Na, Nb, Nd, Ne, Ni, P, RP, Up, XP, ap, mp, n, na, nm, ns, né, p, pp, n p] (18573) [lt:en:MORFOLOGIK_RULE_EN_GB]">np</span>.do</span>t(<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Larry, Carr, lair, Barr, Lara, Lars, lard, lark, parr, Farr, Marr, Warr, arr, l arr] (18580) [lt:en:MORFOLOGIK_RULE_EN_GB]">larr</span>[<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, lie, mix, fix, lid, lip, Lin, Liz, lax, lib, lux, nix, lox, lit, liq, Bix, Hix, Li, Lib, Lit, Liu, Wix, XIX, ix, lx, pix, xix, l ix] (18585) [lt:en:MORFOLOGIK_RULE_EN_GB]">lix</span>], <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [rare, Carr, rarer, Barr, parr, Farr, Marr, Warr, arr, r arr] (18591) [lt:en:MORFOLOGIK_RULE_EN_GB]">rarr</span>[<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, mix, Prix, Rio, fix, rim, rid, rig, Rex, rib, rip, nix, Bix, Hix, Rux, Wix, XIX, ix, pix, xix, r ix] (18596) [lt:en:MORFOLOGIK_RULE_EN_GB]">rix</span>])</div><div class="clear"></div>
<div class="linenb">&nbsp;579</div><div class="codeline">  gloss = 2 * (target <span class="highlight" title="Consider using an m-dash if you do not want to join two words.. Suggestions: [—] (18624) [lt:en:DASH_RULE]">-</span> out)</div><div class="clear"></div>
<div class="linenb">&nbsp;580</div><div class="codeline">  #<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [loss, gloss, floss, dross, doss, d loss] (18634) [lt:en:MORFOLOGIK_RULE_EN_GB]">dloss</span>/<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [do, Dr, dB, ml, DLR, DSL, DLA, DLL, DZ, cl, DJ, da, Al, D, DC, DHL, De, Del, Du, Dy, El, L, UL, XL, d, fl, kl, l, ll, pl, d l] (18640) [lt:en:MORFOLOGIK_RULE_EN_GB]">dl</span> = 2 * (target <span class="highlight" title="Consider using an m-dash if you do not want to join two words.. Suggestions: [—] (18657) [lt:en:DASH_RULE]">-</span> dot(l, r)) r</div><div class="clear"></div>
<div class="linenb">&nbsp;581</div><div class="codeline">  #<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [loss, gloss, floss, dross, doss, d loss] (18675) [lt:en:MORFOLOGIK_RULE_EN_GB]">dloss</span>/<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Dr, or, do, Mr, dry, Jr, DDR, DRM, dB, DLR, fr, DVR, DZ, HDR, qr, DJ, da, BR, Bdr, D, DC, De, Dry, Du, Dy, IR, Or, Pr, Sr, Ur, VR, Zr, d, der, er, gr, hr, r, yr, d r, tr] (18681) [lt:en:MORFOLOGIK_RULE_EN_GB]">dr</span> = 2 * (target <span class="highlight" title="Consider using an m-dash if you do not want to join two words.. Suggestions: [—] (18698) [lt:en:DASH_RULE]">-</span> dot(l, r)) l</div><div class="clear"></div>
<div class="linenb">&nbsp;582</div><div class="codeline">  <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [grad, l grad, lg rad] (18715) [lt:en:MORFOLOGIK_RULE_EN_GB]">lgrad</span> =  EPSILON * gloss * <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [rare, Carr, rarer, Barr, parr, Farr, Marr, Warr, arr, r arr] (18742) [lt:en:MORFOLOGIK_RULE_EN_GB]">rarr</span>[<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, mix, Prix, Rio, fix, rim, rid, rig, Rex, rib, rip, nix, Bix, Hix, Rux, Wix, XIX, ix, pix, xix, r ix] (18747) [lt:en:MORFOLOGIK_RULE_EN_GB]">rix</span>]</div><div class="clear"></div>
<div class="linenb">&nbsp;583</div><div class="codeline">  <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [grad, r grad] (18754) [lt:en:MORFOLOGIK_RULE_EN_GB]">rgrad</span> =  EPSILON * gloss * <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [rare, Carr, rarer, Barr, parr, Farr, Marr, Warr, arr, r arr] (18781) [lt:en:MORFOLOGIK_RULE_EN_GB]">rarr</span>[<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, mix, Prix, Rio, fix, rim, rid, rig, Rex, rib, rip, nix, Bix, Hix, Rux, Wix, XIX, ix, pix, xix, r ix] (18786) [lt:en:MORFOLOGIK_RULE_EN_GB]">rix</span>]</div><div class="clear"></div>
<div class="linenb">&nbsp;584</div><div class="codeline">  # l -= <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [ups, GPS, LPs, eds, IPS, ops, esp, reps, fps, bps, PEPs, ems, MPs, PS, EP, EPA, ETs, Es, IPs, MEPs, PPS, cps, peps] (18800) [lt:en:MORFOLOGIK_RULE_EN_GB]">eps</span> * <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [loss, gloss, floss, dross, doss, d loss] (18806) [lt:en:MORFOLOGIK_RULE_EN_GB]">dloss</span>/<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [do, Dr, dB, ml, DLR, DSL, DLA, DLL, DZ, cl, DJ, da, Al, D, DC, DHL, De, Del, Du, Dy, El, L, UL, XL, d, fl, kl, l, ll, pl, d l] (18812) [lt:en:MORFOLOGIK_RULE_EN_GB]">dl</span>; r -= <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [ups, GPS, LPs, eds, IPS, ops, esp, reps, fps, bps, PEPs, ems, MPs, PS, EP, EPA, ETs, Es, IPs, MEPs, PPS, cps, peps] (18821) [lt:en:MORFOLOGIK_RULE_EN_GB]">eps</span> * <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [loss, gloss, floss, dross, doss, d loss] (18827) [lt:en:MORFOLOGIK_RULE_EN_GB]">dloss</span>/<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Dr, or, do, Mr, dry, Jr, DDR, DRM, dB, DLR, fr, DVR, DZ, HDR, qr, DJ, da, BR, Bdr, D, DC, De, Dry, Du, Dy, IR, Or, Pr, Sr, Ur, VR, Zr, d, der, er, gr, hr, r, yr, d r, tr] (18833) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>dr</div><div class="clear"></div>
<div class="linenb">&nbsp;585</div><div class="codeline">  <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Larry, Carr, lair, Barr, Lara, Lars, lard, lark, parr, Farr, Marr, Warr, arr, l arr] (18838) [lt:en:MORFOLOGIK_RULE_EN_GB]">larr</span>[<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, lie, mix, fix, lid, lip, Lin, Liz, lax, lib, lux, nix, lox, lit, liq, Bix, Hix, Li, Lib, Lit, Liu, Wix, XIX, ix, lx, pix, xix, l ix] (18843) [lt:en:MORFOLOGIK_RULE_EN_GB]">lix</span>] += EPSILON * gloss * <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [rare, Carr, rarer, Barr, parr, Farr, Marr, Warr, arr, r arr] (18869) [lt:en:MORFOLOGIK_RULE_EN_GB]">rarr</span>[<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, mix, Prix, Rio, fix, rim, rid, rig, Rex, rib, rip, nix, Bix, Hix, Rux, Wix, XIX, ix, pix, xix, r ix] (18874) [lt:en:MORFOLOGIK_RULE_EN_GB]">rix</span>]</div><div class="clear"></div>
<div class="linenb">&nbsp;586</div><div class="codeline">  <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [rare, Carr, rarer, Barr, parr, Farr, Marr, Warr, arr, r arr] (18881) [lt:en:MORFOLOGIK_RULE_EN_GB]">rarr</span>[<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, mix, Prix, Rio, fix, rim, rid, rig, Rex, rib, rip, nix, Bix, Hix, Rux, Wix, XIX, ix, pix, xix, r ix] (18886) [lt:en:MORFOLOGIK_RULE_EN_GB]">rix</span>] += EPSILON * gloss * <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Larry, Carr, lair, Barr, Lara, Lars, lard, lark, parr, Farr, Marr, Warr, arr, l arr] (18912) [lt:en:MORFOLOGIK_RULE_EN_GB]">larr</span>[<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, lie, mix, fix, lid, lip, Lin, Liz, lax, lib, lux, nix, lox, lit, liq, Bix, Hix, Li, Lib, Lit, Liu, Wix, XIX, ix, lx, pix, xix, l ix] (18917) [lt:en:MORFOLOGIK_RULE_EN_GB]">lix</span>]</div><div class="clear"></div>
<div class="linenb">&nbsp;587</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;588</div><div class="codeline"><span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Def] (18923) [lt:en:UPPERCASE_SENTENCE_START]">def</span> train(corpus: list, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Diarize, Dimerize] (18947) [lt:en:MORFOLOGIK_RULE_EN_GB]">DIMSIZE</span>: <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [in, it, into, ink, TNT, inn, mint, ant, hint, ITT, pint, tint, lint, nit, inst, Ind, Inc, Inn, Intu, Mint, NT, dint, ing, ins, intl, in t, ICT] (18956) [lt:en:MORFOLOGIK_RULE_EN_GB]">int</span>):</div><div class="clear"></div>
<div class="linenb">&nbsp;589</div><div class="codeline">  <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (18964) [lt:en:EN_QUOTES]">"</span><span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"></span>"</span><span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"></span>"</div><div class="clear"></div>
<div class="linenb">&nbsp;590</div><div class="codeline">  train word2vec of dimension <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Diarize, Dimerize] (18998) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>DIMSIZE</div><div class="clear"></div>
<div class="linenb">&nbsp;591</div><div class="codeline">  on the given corpus, which is a list of words</div><div class="clear"></div>
<div class="linenb">&nbsp;592</div><div class="codeline">  from the source corpus.</div><div class="clear"></div>
<div class="linenb">&nbsp;593</div><div class="codeline">  Example:</div><div class="clear"></div>
<div class="linenb">&nbsp;594</div><div class="codeline">  train([<span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (19100) [lt:en:EN_QUOTES]">"</span></span>the<span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart closing quote here: '”'.. Suggestions: [”] (19104) [lt:en:EN_QUOTES]">"</span></span>, <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (19107) [lt:en:EN_QUOTES]">"</span></span>man<span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart closing quote here: '”'.. Suggestions: [”] (19111) [lt:en:EN_QUOTES]">"</span></span>, <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (19114) [lt:en:EN_QUOTES]">"</span></span>was<span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart closing quote here: '”'.. Suggestions: [”] (19118) [lt:en:EN_QUOTES]">"</span></span> <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (19120) [lt:en:EN_QUOTES]">"</span></span>tall<span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart closing quote here: '”'.. Suggestions: [”] (19125) [lt:en:EN_QUOTES]">"</span></span>, <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (19128) [lt:en:EN_QUOTES]">"</span></span>the<span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart closing quote here: '”'.. Suggestions: [”] (19132) [lt:en:EN_QUOTES]">"</span></span>, <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (19135) [lt:en:EN_QUOTES]">"</span></span>quick<span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart closing quote here: '”'.. Suggestions: [”] (19141) [lt:en:EN_QUOTES]">"</span></span>, <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (19144) [lt:en:EN_QUOTES]">"</span></span>brown<span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart closing quote here: '”'.. Suggestions: [”] (19150) [lt:en:EN_QUOTES]">"</span></span>, <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (19153) [lt:en:EN_QUOTES]">"</span></span>fox<span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart closing quote here: '”'.. Suggestions: [”] (19157) [lt:en:EN_QUOTES]">"</span></span>], 20)</div><div class="clear"></div>
<div class="linenb">&nbsp;595</div><div class="codeline">  <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (19167) [lt:en:EN_QUOTES]">"</span><span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"></span>"</span><span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"></span>"</div><div class="clear"></div>
<div class="linenb">&nbsp;596</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;597</div><div class="codeline">  # vocabulary is set of words in corpus</div><div class="clear"></div>
<div class="linenb">&nbsp;598</div><div class="codeline">  <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [vocal] (19215) [lt:en:MORFOLOGIK_RULE_EN_GB]">vocab</span> = set(corpus)</div><div class="clear"></div>
<div class="linenb">&nbsp;599</div><div class="codeline">  <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Vocalize] (19237) [lt:en:MORFOLOGIK_RULE_EN_GB]">VOCABSIZE</span> = <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Len, led, men, let, ten, leg, Lee, Ben, lens, pen, Leon, den, lean, lend, lent, Lin, Zen, yen, Lena, Leno, Lev, Lew, Lyn, fen, gen, hen, lien, glen, Olen, Leo, Alen, Fen, Glen, Jen, Ken, LAN, LED, Le, Lea, Les, Ley, Pen, Ren, Sen, Ven, Wen, ben, en, ken, le, lea, lee, lei, lez, l en, le n] (19249) [lt:en:MORFOLOGIK_RULE_EN_GB]">len</span>(<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [vocal] (19253) [lt:en:MORFOLOGIK_RULE_EN_GB]">vocab</span>)</div><div class="clear"></div>
<div class="linenb">&nbsp;600</div><div class="codeline">  # map each unique word to an index</div><div class="clear"></div>
<div class="linenb">&nbsp;601</div><div class="codeline">  # for array indexing.</div><div class="clear"></div>
<div class="linenb">&nbsp;602</div><div class="codeline">  <span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Vocab2ix] (19323) [lt:en:UPPERCASE_SENTENCE_START]">vocab2ix</span> = <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [diet, dirt, dice, duct, edict, dicta, Pict, dick, dicot, dint, ICT] (19334) [lt:en:MORFOLOGIK_RULE_EN_GB]">dict</span>([(word, ix) for (ix, word) in enumerate(corpus)])</div><div class="clear"></div>
<div class="linenb">&nbsp;603</div><div class="codeline">  # positive and negative sample vectors.</div><div class="clear"></div>
<div class="linenb">&nbsp;604</div><div class="codeline">  # positive vectors are random initialized</div><div class="clear"></div>
<div class="linenb">&nbsp;605</div><div class="codeline">  <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [loss, pass, post, boss, posts, Ross, pose, POWs, poses, toss, moss, pods, pots, pops, posh, posse, Foss, Voss, joss, posy, puss, doss, FOSS, Goss, Moss, Noss, OSS, POS, Pass, Post, SOSs, piss, pons] (19477) [lt:en:MORFOLOGIK_RULE_EN_GB]">poss</span> =<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Np, no, up, HP, SNP, VP, ng, nu, GNP, PNP, NPD, NY, nap, nip, WNP, IP, op, BP, EP, GP, LP, MP, N, NS, NT, NW, NZ, Na, Nb, Nd, Ne, Ni, P, RP, Up, XP, ap, mp, n, na, nm, ns, né, p, pp, n p] (19484) [lt:en:MORFOLOGIK_RULE_EN_GB]">np</span>.ra</span>nd((<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Vocalize] (19493) [lt:en:MORFOLOGIK_RULE_EN_GB]">VOCABSIZE</span>, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Diarize, Dimerize] (19504) [lt:en:MORFOLOGIK_RULE_EN_GB]">DIMSIZE</span>))</div><div class="clear"></div>
<div class="linenb">&nbsp;606</div><div class="codeline">  # negative vectors are zero initialized</div><div class="clear"></div>
<div class="linenb">&nbsp;607</div><div class="codeline">  <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [news, legs, nets, begs, pegs, kegs, ness, nags, neg, regs, Ness, News, neds, neg s] (19558) [lt:en:MORFOLOGIK_RULE_EN_GB]">negs</span> =<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Np, no, up, HP, SNP, VP, ng, nu, GNP, PNP, NPD, NY, nap, nip, WNP, IP, op, BP, EP, GP, LP, MP, N, NS, NT, NW, NZ, Na, Nb, Nd, Ne, Ni, P, RP, Up, XP, ap, mp, n, na, nm, ns, né, p, pp, n p] (19565) [lt:en:MORFOLOGIK_RULE_EN_GB]">np</span>.ze</span>ros((<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Vocalize] (19575) [lt:en:MORFOLOGIK_RULE_EN_GB]">VOCABSIZE</span>, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Diarize, Dimerize] (19586) [lt:en:MORFOLOGIK_RULE_EN_GB]">DIMSIZE</span>))</div><div class="clear"></div>
<div class="linenb">&nbsp;608</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;609</div><div class="codeline">  # for every location in the corpus</div><div class="clear"></div>
<div class="linenb">&nbsp;610</div><div class="codeline">  for <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Wix, six, win, mix, fix, wax, wit, Wii, wig, nix, Bix, Hix, WI, Wil, XIX, ix, pix, xix, w ix] (19640) [lt:en:MORFOLOGIK_RULE_EN_GB]">wix</span> in range(<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Len, led, men, let, ten, leg, Lee, Ben, lens, pen, Leon, den, lean, lend, lent, Lin, Zen, yen, Lena, Leno, Lev, Lew, Lyn, fen, gen, hen, lien, glen, Olen, Leo, Alen, Fen, Glen, Jen, Ken, LAN, LED, Le, Lea, Les, Ley, Pen, Ren, Sen, Ven, Wen, ben, en, ken, le, lea, lee, lei, lez, l en, le n] (19653) [lt:en:MORFOLOGIK_RULE_EN_GB]">len</span>(corpus)):</div><div class="clear"></div>
<div class="linenb">&nbsp;611</div><div class="codeline">    # find word at location,</div><div class="clear"></div>
<div class="linenb">&nbsp;612</div><div class="codeline">    w = vocab2ix[corpus[<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Wix, six, win, mix, fix, wax, wit, Wii, wig, nix, Bix, Hix, WI, Wil, XIX, ix, pix, xix, w ix] (19720) [lt:en:MORFOLOGIK_RULE_EN_GB]">wix</span>]]</div><div class="clear"></div>
<div class="linenb">&nbsp;613</div><div class="codeline">    l = max(<span class="highlight-spelling" title="Possible spelling mistake found (19738) [lt:en:MORFOLOGIK_RULE_EN_GB]">wix-WINDOWSIZE</span>, 0)</div><div class="clear"></div>
<div class="linenb">&nbsp;614</div><div class="codeline">    r = min(<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Wix, six, win, mix, fix, wax, wit, Wii, wig, nix, Bix, Hix, WI, Wil, XIX, ix, pix, xix, w ix] (19769) [lt:en:MORFOLOGIK_RULE_EN_GB]">wix</span>+<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Windowsill] (19773) [lt:en:MORFOLOGIK_RULE_EN_GB]">WINDOWSIZE</span>, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Len, led, men, let, ten, leg, Lee, Ben, lens, pen, Leon, den, lean, lend, lent, Lin, Zen, yen, Lena, Leno, Lev, Lew, Lyn, fen, gen, hen, lien, glen, Olen, Leo, Alen, Fen, Glen, Jen, Ken, LAN, LED, Le, Lea, Les, Ley, Pen, Ren, Sen, Ven, Wen, ben, en, ken, le, lea, lee, lei, lez, l en, le n] (19785) [lt:en:MORFOLOGIK_RULE_EN_GB]">len</span>(corpus)-1)</div><div class="clear"></div>
<div class="linenb">&nbsp;615</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;616</div><div class="codeline">    # for every positive sample, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [in, is, I, he, it, we, be, me, if, die, ice, lie, tie, IEC, IQ, id, pie, ire, vie, ye, OE, IEE, fie, CE, IP, Ce, De, Fe, Ge, IA, IC, ID, IDE, IR, IU, Ide, Ike, Ile, Ive, Le, Ne, PE, Se, Te, e, hie, i, i3, i5, i7, i9, ii, ise, ite, iv, ix, ize, le, né, re, ve, i e, IG] (19834) [lt:en:MORFOLOGIK_RULE_EN_GB]">ie</span>, word in the range [l, r]</div><div class="clear"></div>
<div class="linenb">&nbsp;617</div><div class="codeline">    for w2ix in range(l, r+1):</div><div class="clear"></div>
<div class="linenb">&nbsp;618</div><div class="codeline">        w2 = vocab2ix[corpus[w2ix]]</div><div class="clear"></div>
<div class="linenb">&nbsp;619</div><div class="codeline">        # learn the positive sample.</div><div class="clear"></div>
<div class="linenb">&nbsp;620</div><div class="codeline">        <span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Learn] (19975) [lt:en:UPPERCASE_SENTENCE_START]">learn</span>(<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, lie, mix, fix, lid, lip, Lin, Liz, lax, lib, lux, nix, lox, lit, liq, Bix, Hix, Li, Lib, Lit, Liu, Wix, XIX, ix, lx, pix, xix, l ix] (19981) [lt:en:MORFOLOGIK_RULE_EN_GB]">lix</span>=w, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, mix, Prix, Rio, fix, rim, rid, rig, Rex, rib, rip, nix, Bix, Hix, Rux, Wix, XIX, ix, pix, xix, r ix] (19988) [lt:en:MORFOLOGIK_RULE_EN_GB]">rix</span>=w2, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Larry, Carr, lair, Barr, Lara, Lars, lard, lark, parr, Farr, Marr, Warr, arr, l arr] (19996) [lt:en:MORFOLOGIK_RULE_EN_GB]">larr</span>=<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [loss, pass, post, boss, posts, Ross, pose, POWs, poses, toss, moss, pods, pots, pops, posh, posse, Foss, Voss, joss, posy, puss, doss, FOSS, Goss, Moss, Noss, OSS, POS, Pass, Post, SOSs, piss, pons] (20001) [lt:en:MORFOLOGIK_RULE_EN_GB]">poss</span>, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [rare, Carr, rarer, Barr, parr, Farr, Marr, Warr, arr, r arr] (20007) [lt:en:MORFOLOGIK_RULE_EN_GB]">rarr</span>=<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [loss, pass, post, boss, posts, Ross, pose, POWs, poses, toss, moss, pods, pots, pops, posh, posse, Foss, Voss, joss, posy, puss, doss, FOSS, Goss, Moss, Noss, OSS, POS, Pass, Post, SOSs, piss, pons] (20012) [lt:en:MORFOLOGIK_RULE_EN_GB]">poss</span>, target=1.0)</div><div class="clear"></div>
<div class="linenb">&nbsp;621</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;622</div><div class="codeline">    # learn negative samples for the word.</div><div class="clear"></div>
<div class="linenb">&nbsp;623</div><div class="codeline">    <span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [For] (20078) [lt:en:UPPERCASE_SENTENCE_START]">for</span> _ in range(<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Oversamples, Resamples] (20093) [lt:en:MORFOLOGIK_RULE_EN_GB]">NNEGSAMPLES</span>)</div><div class="clear"></div>
<div class="linenb">&nbsp;624</div><div class="codeline">        # pick a random word.</div><div class="clear"></div>
<div class="linenb">&nbsp;625</div><div class="codeline">        <span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [W2ix] (20144) [lt:en:UPPERCASE_SENTENCE_START]">w2ix</span> =<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> random.<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [ran dint] (20158) [lt:en:MORFOLOGIK_RULE_EN_GB]">ra</span>ndint</span>(0, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Len, led, men, let, ten, leg, Lee, Ben, lens, pen, Leon, den, lean, lend, lent, Lin, Zen, yen, Lena, Leno, Lev, Lew, Lyn, fen, gen, hen, lien, glen, Olen, Leo, Alen, Fen, Glen, Jen, Ken, LAN, LED, Le, Lea, Les, Ley, Pen, Ren, Sen, Ven, Wen, ben, en, ken, le, lea, lee, lei, lez, l en, le n] (20169) [lt:en:MORFOLOGIK_RULE_EN_GB]">len</span>(corpus)-1)</div><div class="clear"></div>
<div class="linenb">&nbsp;626</div><div class="codeline">        w2 = vocab2ix[corpus[w2ix]]</div><div class="clear"></div>
<div class="linenb">&nbsp;627</div><div class="codeline">        learn(<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, lie, mix, fix, lid, lip, Lin, Liz, lax, lib, lux, nix, lox, lit, liq, Bix, Hix, Li, Lib, Lit, Liu, Wix, XIX, ix, lx, pix, xix, l ix] (20234) [lt:en:MORFOLOGIK_RULE_EN_GB]">lix</span>=w, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [six, mix, Prix, Rio, fix, rim, rid, rig, Rex, rib, rip, nix, Bix, Hix, Rux, Wix, XIX, ix, pix, xix, r ix] (20241) [lt:en:MORFOLOGIK_RULE_EN_GB]">rix</span>=w2, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Larry, Carr, lair, Barr, Lara, Lars, lard, lark, parr, Farr, Marr, Warr, arr, l arr] (20249) [lt:en:MORFOLOGIK_RULE_EN_GB]">larr</span>=<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [loss, pass, post, boss, posts, Ross, pose, POWs, poses, toss, moss, pods, pots, pops, posh, posse, Foss, Voss, joss, posy, puss, doss, FOSS, Goss, Moss, Noss, OSS, POS, Pass, Post, SOSs, piss, pons] (20254) [lt:en:MORFOLOGIK_RULE_EN_GB]">poss</span>, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [rare, Carr, rarer, Barr, parr, Farr, Marr, Warr, arr, r arr] (20260) [lt:en:MORFOLOGIK_RULE_EN_GB]">rarr</span>=<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [news, legs, nets, begs, pegs, kegs, ness, nags, neg, regs, Ness, News, neds, neg s] (20265) [lt:en:MORFOLOGIK_RULE_EN_GB]">negs</span>, out=out, target=0.0)</div><div class="clear"></div>
<div class="linenb">&nbsp;628</div><div class="codeline"><span class="keyword2">\end{<span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [minted., minted!, minted?, minted:, minted,, minted;] (20292) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>minted}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;629</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;630</div><div class="codeline">\<span class="highlight-sh" title="If a section has sub-sections, it should have more than one such sub-section. [sh:nsubdiv]"><span class="highlight-sh" title="This subsection is very short (about 47 words). You should consider merging it with another section or make it longer. [sh:seclen]"><span class="highlight-sh" title="This subsection is very short (about 48 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsection</span></span></span>{Bugs}</div><div class="clear"></div>
<div class="linenb">&nbsp;631</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;632</div><div class="codeline">In this subsection, we list <span class="highlight" title="If the text is a generality, 'of the' is not necessary. Do you mean 'some'?. Suggestions: [some] (20334) [lt:en:SOME_OF_THE]">some of the</span> bugs we discovered in the \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (20373) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>wtov</div><div class="clear"></div>
<div class="linenb">&nbsp;633</div><div class="codeline">codebase. While these do not impact training significantly, they do point out</div><div class="clear"></div>
<div class="linenb">&nbsp;634</div><div class="codeline">the dangers of using C as programming language, as well as provides justification</div><div class="clear"></div>
<div class="linenb">&nbsp;635</div><div class="codeline">for reading the original sources.</div><div class="clear"></div>
<div class="linenb">&nbsp;636</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;637</div><div class="codeline">\<span class="highlight-sh" title="This subsubsection is very short (about 142 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsubsection</span>{Epoch <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [resetting., resetting!, resetting?, resetting:, resetting,, resetting;] (20579) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>resetting}</div><div class="clear"></div>
<div class="linenb">&nbsp;638</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;639</div><div class="codeline"><span class="keyword2">\begin{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Minted] (20590) [lt:en:UPPERCASE_SENTENCE_START]">minted}</span></span>[<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [linens] (20597) [lt:en:MORFOLOGIK_RULE_EN_GB]">linenos</span>]{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [cap, cup, CPU, cop, CPA, CPI, CPR, PPP, CSP, opp, app, CDP, cpl, cpd, Copp, cps, pp, c pp] (20605) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>cpp}</div><div class="clear"></div>
<div class="linenb">&nbsp;640</div><div class="codeline">if (<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [of, elf, emf, EOL, e of, eon] (20613) [lt:en:MORFOLOGIK_RULE_EN_GB]">eof</span> || (<span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'word _ count' is correct. (20621) [lt:en:WORD_CONTAINS_UNDERSCORE]">word_count</span> &gt; <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'train _ words' is correct. (20634) [lt:en:WORD_CONTAINS_UNDERSCORE]">train_words</span> / <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'num _ threads' is correct. (20648) [lt:en:WORD_CONTAINS_UNDERSCORE]">num_threads</span>)) {</div><div class="clear"></div>
<div class="linenb">&nbsp;641</div><div class="codeline">  <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'word _ count' is correct. (20665) [lt:en:WORD_CONTAINS_UNDERSCORE]">word_count</span>_actual += <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'word _ count' is correct. (20686) [lt:en:WORD_CONTAINS_UNDERSCORE]">word_count</span> <span class="highlight" title="Consider using an m-dash if you do not want to join two words.. Suggestions: [—] (20697) [lt:en:DASH_RULE]">-</span> <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'last _ word' is correct. (20699) [lt:en:WORD_CONTAINS_UNDERSCORE]">last_word</span>_count; <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'local _ iter-' is correct. (20716) [lt:en:WORD_CONTAINS_UNDERSCORE]">local_iter-</span>-;</div><div class="clear"></div>
<div class="linenb">&nbsp;642</div><div class="codeline">  if (<span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'local _ iter' is correct. (20736) [lt:en:WORD_CONTAINS_UNDERSCORE]">local_iter</span> == 0) break;</div><div class="clear"></div>
<div class="linenb">&nbsp;643</div><div class="codeline">  <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'word _ count' is correct. (20762) [lt:en:WORD_CONTAINS_UNDERSCORE]">word_count</span> = 0; <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'last _ word' is correct. (20778) [lt:en:WORD_CONTAINS_UNDERSCORE]">last_word</span>_count = 0; <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'sentence _ length' is correct. (20799) [lt:en:WORD_CONTAINS_UNDERSCORE]">sentence_length</span> = 0;</div><div class="clear"></div>
<div class="linenb">&nbsp;644</div><div class="codeline">  // <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [of, elf, emf, EOL, e of, eon] (20825) [lt:en:MORFOLOGIK_RULE_EN_GB]">eof</span> = 0; /* Missing code! */</div><div class="clear"></div>
<div class="linenb">&nbsp;645</div><div class="codeline">  <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [seek, f seek] (20856) [lt:en:MORFOLOGIK_RULE_EN_GB]">fseek</span>(<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [phi, Fi, I, if, FM, FBI, fit, ft, fix, Hi, fig, hi, pi, fr, FYI, Fri, fib, fie, fin, AI, BFI, CI, Ci, EFI, F, FIA, FX, FY, Fe, Fis, Li, Ni, Si, Ti, UI, VI, WI, Xi, bi, f, fa, ff, fir, fl, fo, fs, fu, i, ii, mi, oi, phis, pho, php, qi, vi, xi, f i] (20862) [lt:en:MORFOLOGIK_RULE_EN_GB]">fi</span>, <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'file _ size' is correct. (20866) [lt:en:WORD_CONTAINS_UNDERSCORE]">file_size</span> / (<span class="highlight" title="Possible typo: you repeated a word. Suggestions: [long] (20879) [lt:en:ENGLISH_WORD_REPEAT_RULE]">long long</span>)<span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'num _ threads' is correct. (20889) [lt:en:WORD_CONTAINS_UNDERSCORE]">num_threads</span> * (<span class="highlight" title="Possible typo: you repeated a word. Suggestions: [long] (20904) [lt:en:ENGLISH_WORD_REPEAT_RULE]">long long</span>)id,</div><div class="clear"></div>
<div class="linenb">&nbsp;646</div><div class="codeline">     <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'SEEK _ SET' is correct. (20923) [lt:en:WORD_CONTAINS_UNDERSCORE]">SEEK_SET</span>);</div><div class="clear"></div>
<div class="linenb">&nbsp;647</div><div class="codeline">  continue;</div><div class="clear"></div>
<div class="linenb">&nbsp;648</div><div class="codeline">}</div><div class="clear"></div>
<div class="linenb">&nbsp;649</div><div class="codeline"><span class="keyword2">\end{minted}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;650</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;651</div><div class="codeline">\<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (20956) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> trains on multiple threads in parallel. The thread that reads</div><div class="clear"></div>
<div class="linenb">&nbsp;652</div><div class="codeline">the final chunk of text does not reset its \texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [of, elf, emf, EOL, e of, eon] (21066) [lt:en:MORFOLOGIK_RULE_EN_GB]">eof}</span> (end-of-file) state</div><div class="clear"></div>
<div class="linenb">&nbsp;653</div><div class="codeline">upon reaching the end of file. The code at line \circled{5} ought to have been present,</div><div class="clear"></div>
<div class="linenb">&nbsp;654</div><div class="codeline">but is missing. Thus, the final fragment of text is trained for only a single</div><div class="clear"></div>
<div class="linenb">&nbsp;655</div><div class="codeline">epoch, which causes the word vectors to miss data about the last section of the document.</div><div class="clear"></div>
<div class="linenb">&nbsp;656</div><div class="codeline">This causes the overall accuracy  to be lowered than the potential optima.</div><div class="clear"></div>
<div class="linenb">&nbsp;657</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;658</div><div class="codeline"><span class="keyword1">\subsection</span>{Initialization <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [choices., choices!, choices?, choices:, choices,, choices;] (21427) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>choices}</div><div class="clear"></div>
<div class="linenb">&nbsp;659</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;660</div><div class="codeline">We conjecture that since the negative samples come from all over the text and</div><div class="clear"></div>
<div class="linenb">&nbsp;661</div><div class="codeline">are not really weighed by frequency, you can wind up picking <span class="keyword1">\emph</span>{any word},</div><div class="clear"></div>
<div class="linenb">&nbsp;662</div><div class="codeline">and more often than not, <span class="keyword1">\emph</span>{a word whose vector has not been trained much at</div><div class="clear"></div>
<div class="linenb">&nbsp;663</div><div class="codeline">all}.  If this vector actually had a value, then it could move the actually</div><div class="clear"></div>
<div class="linenb">&nbsp;664</div><div class="codeline">important focus word randomly. The solution is to set all negative samples to</div><div class="clear"></div>
<div class="linenb">&nbsp;665</div><div class="codeline">zero, so that <span class="keyword1">\emph</span>{only vectors that have occurred somewhat frequently} will</div><div class="clear"></div>
<div class="linenb">&nbsp;666</div><div class="codeline">affect the representation of another vector. This also explains <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Glove, Love, Globe, Gloves, Grove, Clove, Gloved, Glover] (21947) [lt:en:MORFOLOGIK_RULE_EN_GB]">GloVe</span>'s radical</div><div class="clear"></div>
<div class="linenb">&nbsp;667</div><div class="codeline">choice of having a separate vector for the negative context --- they re-used</div><div class="clear"></div>
<div class="linenb">&nbsp;668</div><div class="codeline">\<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (22041) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span>'s  scheme, re-interpreting the negative vector and positive vector as</div><div class="clear"></div>
<div class="linenb">&nbsp;669</div><div class="codeline">accounting for different aspects of <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [co-occurrence] (22152) [lt:en:MORFOLOGIK_RULE_EN_GB]">co-occurence</span>.</div><div class="clear"></div>
<div class="linenb">&nbsp;670</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;671</div><div class="codeline"><span class="keyword1">\subsection</span>{Evaluation}</div><div class="clear"></div>
<div class="linenb">&nbsp;672</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;673</div><div class="codeline">\<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (22180) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> can be evaluated in two manners, either by application to a downstream</div><div class="clear"></div>
<div class="linenb">&nbsp;674</div><div class="codeline">task along with a corpus, a model which trains for that task, and observe the</div><div class="clear"></div>
<div class="linenb">&nbsp;675</div><div class="codeline">difference in performance on using different embeddings. This model of</div><div class="clear"></div>
<div class="linenb">&nbsp;676</div><div class="codeline">evaluation is known as extrinsic evaluation, and it was this downstream</div><div class="clear"></div>
<div class="linenb">&nbsp;677</div><div class="codeline">performance that made the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [retrained, p retrained, pre trained] (22503) [lt:en:MORFOLOGIK_RULE_EN_GB]">pretrained</span> \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (22515) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> an important <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [component] (22533) [lt:en:MORFOLOGIK_RULE_EN_GB]">comonent</span> of <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Nap, Nip, Alp, LP, Np, PLP, N LP] (22545) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>NLP</div><div class="clear"></div>
<div class="linenb">&nbsp;678</div><div class="codeline">research.</div><div class="clear"></div>
<div class="linenb">&nbsp;679</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;680</div><div class="codeline">However, \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (22570) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> literature is evaluated by performing direct operations between</div><div class="clear"></div>
<div class="linenb">&nbsp;681</div><div class="codeline">vectors such as vector addition and dot product calculation. These operations</div><div class="clear"></div>
<div class="linenb">&nbsp;682</div><div class="codeline">are then compared to lexical semantic <span class="highlight" title="Do not mix variants of the same word ('analyse' and 'analyze') within a single text.. Suggestions: [analyze] (22755) [lt:en:EN_WORD_COHERENCY]">analyses</span> such as similarity, analogy, and</div><div class="clear"></div>
<div class="linenb">&nbsp;683</div><div class="codeline">compositionality. For example, similarity is computed using cosine similarity,</div><div class="clear"></div>
<div class="linenb">&nbsp;684</div><div class="codeline">compositionality using vector addition, and analogy using vector addition</div><div class="clear"></div>
<div class="linenb">&nbsp;685</div><div class="codeline">and subtraction of the <span class="keyword1">\textit</span>{length-normalized vectors}, specifically</div><div class="clear"></div>
<div class="linenb">&nbsp;686</div><div class="codeline">\texttt{syn0} vectors.</div><div class="clear"></div>
<div class="linenb">&nbsp;687</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;688</div><div class="codeline">The analyses are done of corpora also introduced in</div><div class="clear"></div>
<div class="linenb">&nbsp;689</div><div class="codeline">\cite{mikolov2013distributed}, and are heavily qualitative in nature.</div><div class="clear"></div>
<div class="linenb">&nbsp;690</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;691</div><div class="codeline"><span class="keyword1">\subsection</span>{Relationship to <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Glove, Love, Globe, Gloves, Grove, Clove, Gloved, Glover] (23141) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>GloVe}</div><div class="clear"></div>
<div class="linenb">&nbsp;692</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;693</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Glove, Love, Globe, Gloves, Grove, Clove, Gloved, Glover] (23148) [lt:en:MORFOLOGIK_RULE_EN_GB]">GloVe</span> \cite{pennington2014glove} is an unsupervised word embedding learning</div><div class="clear"></div>
<div class="linenb">&nbsp;694</div><div class="codeline">algorithm inspired by \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (23224) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span>. Training is performed on global word <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [co-occurrence] (23267) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>co-occurence</div><div class="clear"></div>
<div class="linenb">&nbsp;695</div><div class="codeline">matrix created from a corpus. The resulting representations contain linear</div><div class="clear"></div>
<div class="linenb">&nbsp;696</div><div class="codeline">substructures of the vector space.</div><div class="clear"></div>
<div class="linenb">&nbsp;697</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;698</div><div class="codeline">The innovation in \texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Glove, Love, Globe, Gloves, Grove, Clove, Gloved, Glover] (23409) [lt:en:MORFOLOGIK_RULE_EN_GB]">GloVe}</span> to have the training objective of <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Glove, Love, Globe, Gloves, Grove, Clove, Gloved, Glover] (23449) [lt:en:MORFOLOGIK_RULE_EN_GB]">GloVe</span> to learn</div><div class="clear"></div>
<div class="linenb">&nbsp;699</div><div class="codeline">vectors such that their dot product equals the logarithm of the words'</div><div class="clear"></div>
<div class="linenb">&nbsp;700</div><div class="codeline">probability of co-occurrence. Since the logarithm of a ratio</div><div class="clear"></div>
<div class="linenb">&nbsp;701</div><div class="codeline">equals the difference of logarithms, this objective associates the logarithm</div><div class="clear"></div>
<div class="linenb">&nbsp;702</div><div class="codeline">of ratios of co-occurrence probabilities with vector differences in the word</div><div class="clear"></div>
<div class="linenb">&nbsp;703</div><div class="codeline">vector space. Because these ratios can encode meaning, this</div><div class="clear"></div>
<div class="linenb">&nbsp;704</div><div class="codeline">information gets encoded as vector differences as well.</div><div class="clear"></div>
<div class="linenb">&nbsp;705</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;706</div><div class="codeline">During training, the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Glove, Love, Globe, Gloves, Grove, Clove, Gloved, Glover] (23888) [lt:en:MORFOLOGIK_RULE_EN_GB]">GloVe</span> implementation uses <span class="keyword1">\emph</span>{two vectors for each word},</div><div class="clear"></div>
<div class="linenb">&nbsp;707</div><div class="codeline">one where it appears as a focus word, and one where it appears as a context</div><div class="clear"></div>
<div class="linenb">&nbsp;708</div><div class="codeline">word, much as \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (24032) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> does. The source code snippet is taken from the file</div><div class="clear"></div>
<div class="linenb">&nbsp;709</div><div class="codeline">\texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [arc, PRC, sic, sac, sec, CRC, SSC, SRA, SRO, IRC, SRN, Sac, Sc, Soc, Sr, Sri, orc] (24090) [lt:en:MORFOLOGIK_RULE_EN_GB]">src</span>/glove.c} at the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [GitHub, Git hub] (24109) [lt:en:MORFOLOGIK_RULE_EN_GB]">Github</span> repository</div><div class="clear"></div>
<div class="linenb">&nbsp;710</div><div class="codeline">\texttt{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Stanford] (24127) [lt:en:MORFOLOGIK_RULE_EN_GB]">stanfordnlp</span>/glove}\footnote{\url{https://github.com/stanfordnlp/GloVe/blob/master/src/glove.c\#L190-L193}}.</div><div class="clear"></div>
<div class="linenb">&nbsp;711</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;712</div><div class="codeline"><span class="keyword2">\begin{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [minted] (24147) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>minted}</span>{cpp}</div><div class="clear"></div>
<div class="linenb">&nbsp;713</div><div class="codeline">/* Calculate cost, save diff for gradients */</div><div class="clear"></div>
<div class="linenb">&nbsp;714</div><div class="codeline">diff = 0;</div><div class="clear"></div>
<div class="linenb">&nbsp;715</div><div class="codeline">// dot product of word and context word vector</div><div class="clear"></div>
<div class="linenb">&nbsp;716</div><div class="codeline">for (b = 0; b &lt; <span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'vector _ size' is correct. (24276) [lt:en:WORD_CONTAINS_UNDERSCORE]">vector_size</span>; b++) diff += W[b + l1] * W[b + l2]; </div><div class="clear"></div>
<div class="linenb">&nbsp;717</div><div class="codeline"> // add separate bias for each word</div><div class="clear"></div>
<div class="linenb">&nbsp;718</div><div class="codeline">diff += W[<span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'vector _ size' is correct. (24372) [lt:en:WORD_CONTAINS_UNDERSCORE]">vector_size</span> + l1] + W[<span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'vector _ size' is correct. (24394) [lt:en:WORD_CONTAINS_UNDERSCORE]">vector_size</span> + l2];</div><div class="clear"></div>
<div class="linenb">&nbsp;719</div><div class="codeline">// target:<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> log(<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [or, car, CD, Dr, Mr, cm, Jr, cry, CPR, CRT, CV, CRC, CSR, VCR, fr, OCR, cl, cur, cw, qr, CE, BR, C, CA, CB, CI, CRM, Ca, Car, Ce, Ch, Ci, Cm, Co, Cs, Cu, IR, Or, Pr, Sr, Ur, VR, Zr, c, ca, cc, cf, cir, ck, co, cor, cu, er, gr, hr, r, yr, c r, tr] (24428) [lt:en:MORFOLOGIK_RULE_EN_GB]">cr</span>.<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Val, van, oval, var, cal, gal, pal, vat, vial, Vail, vale, veal, Vax, Al, Cal, Eval, Hal, PAL, Sal, Tal, Vale, Valk, Van, vol, v al] (24431) [lt:en:MORFOLOGIK_RULE_EN_GB]">va</span>l</span>)</div><div class="clear"></div>
<div class="linenb">&nbsp;720</div><div class="codeline">diff = diff <span class="highlight" title="Consider using an m-dash if you do not want to join two words.. Suggestions: [—] (24448) [lt:en:DASH_RULE]">-<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"></span> log(<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [or, car, CD, Dr, Mr, cm, Jr, cry, CPR, CRT, CV, CRC, CSR, VCR, fr, OCR, cl, cur, cw, qr, CE, BR, C, CA, CB, CI, CRM, Ca, Car, Ce, Ch, Ci, Cm, Co, Cs, Cu, IR, Or, Pr, Sr, Ur, VR, Zr, c, ca, cc, cf, cir, ck, co, cor, cu, er, gr, hr, r, yr, c r, tr] (24454) [lt:en:MORFOLOGIK_RULE_EN_GB]">cr</span>.<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Val, van, oval, var, cal, gal, pal, vat, vial, Vail, vale, veal, Vax, Al, Cal, Eval, Hal, PAL, Sal, Tal, Vale, Valk, Van, vol, v al] (24457) [lt:en:MORFOLOGIK_RULE_EN_GB]">va</span>l</span>); </div><div class="clear"></div>
<div class="linenb">&nbsp;721</div><div class="codeline"><span class="keyword2">\end{<span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [minted., minted!, minted?, minted:, minted,, minted;] (24464) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>minted}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;722</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;723</div><div class="codeline"><span class="keyword1">\subsection</span>{Conclusion}</div><div class="clear"></div>
<div class="linenb">&nbsp;724</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;725</div><div class="codeline">The output of the training regime are popularly interpreted as vectors.</div><div class="clear"></div>
<div class="linenb">&nbsp;726</div><div class="codeline">However, we augment this discussion by bringing in nuance. In particular, we</div><div class="clear"></div>
<div class="linenb">&nbsp;727</div><div class="codeline">note that:</div><div class="clear"></div>
<div class="linenb">&nbsp;728</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;729</div><div class="codeline"><span class="keyword1">\item</span> Scalar multiples of the same vector represent the same concept as per the testing regime.</div><div class="clear"></div>
<div class="linenb">&nbsp;730</div><div class="codeline"><span class="keyword1">\item</span> Vector addition has no clear meaning in the representation.</div><div class="clear"></div>
<div class="linenb">&nbsp;731</div><div class="codeline"><span class="keyword1">\item</span> The identity element (the zero vector) holds no semantic meaning in the representation.</div><div class="clear"></div>
<div class="linenb">&nbsp;732</div><div class="codeline"><span class="keyword1">\item</span> The reality of the training regime as-implemented makes it unclear as to</div><div class="clear"></div>
<div class="linenb">&nbsp;733</div><div class="codeline">      what mathematical object is being learnt.</div><div class="clear"></div>
<div class="linenb">&nbsp;734</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;735</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;736</div><div class="codeline">We learn that the \texttt{word2vec} training regime creates two sets of</div><div class="clear"></div>
<div class="linenb">&nbsp;737</div><div class="codeline">vectors, henceforth referred to as \texttt{syn0} and \texttt{syn1neg}. Training proceeds</div><div class="clear"></div>
<div class="linenb">&nbsp;738</div><div class="codeline">by defining a loss function which attempts to bring similar vectors close together by trying</div><div class="clear"></div>
<div class="linenb">&nbsp;739</div><div class="codeline">to make the vectors point along the same direction (have dot-product 1),</div><div class="clear"></div>
<div class="linenb">&nbsp;740</div><div class="codeline">and attempts to push dissimilar vectors far away, by trying to make the vectors</div><div class="clear"></div>
<div class="linenb">&nbsp;741</div><div class="codeline">orthogonal (have a dot product of $0$).</div><div class="clear"></div>
<div class="linenb">&nbsp;742</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;743</div><div class="codeline">At the end of the training regime, the negative vectors \texttt{syn1neg} are</div><div class="clear"></div>
<div class="linenb">&nbsp;744</div><div class="codeline">thrown away, while the positive vectors</div><div class="clear"></div>
<div class="linenb">&nbsp;745</div><div class="codeline">\texttt{syn0} are the ones that are saved. The training regime uses a</div><div class="clear"></div>
<div class="linenb">&nbsp;746</div><div class="codeline">variation of gradient descent. The trained vectors are <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [denormalized, normalized, renormalized] (25649) [lt:en:MORFOLOGIK_RULE_EN_GB]">un-normalized</span>.</div><div class="clear"></div>
<div class="linenb">&nbsp;747</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;748</div><div class="codeline">During evaluation, the vectors are first normalized by length. Next,</div><div class="clear"></div>
<div class="linenb">&nbsp;749</div><div class="codeline">similarity is performed by performing cosine similarity, while analogy</div><div class="clear"></div>
<div class="linenb">&nbsp;750</div><div class="codeline">is performed by adding and subtracting vectors.</div><div class="clear"></div>
<div class="linenb">&nbsp;751</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;752</div><div class="codeline">Thus, this leaves the question open as to what is really being learnt by</div><div class="clear"></div>
<div class="linenb">&nbsp;753</div><div class="codeline">\texttt{word2vec}. We answer this question by hypothesizing that the</div><div class="clear"></div>
<div class="linenb">&nbsp;754</div><div class="codeline">representation that is learnt by \texttt{word2vec} in fact encodes <span class="keyword1">\emph</span>{sets</div><div class="clear"></div>
<div class="linenb">&nbsp;755</div><div class="codeline">of word senses}, which we extract from \texttt{word2vec} by using ideas of</div><div class="clear"></div>
<div class="linenb">&nbsp;756</div><div class="codeline">abstract interpretation.</div><div class="clear"></div>
<div class="linenb">&nbsp;757</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;758</div><div class="codeline">We explain the ideas of abstract interpretation in</div><div class="clear"></div>
<div class="linenb">&nbsp;759</div><div class="codeline">\autoref{chapter:abstract-interpretation}, and then proceed to use these ideas</div><div class="clear"></div>
<div class="linenb">&nbsp;760</div><div class="codeline">to build fuzzy set representations in</div><div class="clear"></div>
<div class="linenb">&nbsp;761</div><div class="codeline">\autoref{chapter:abstract-interpretation}. Finally, we propose an abstract</div><div class="clear"></div>
<div class="linenb">&nbsp;762</div><div class="codeline">version of the \texttt{word2vec} training algorithm on any choice of Lie group</div><div class="clear"></div>
<div class="linenb">&nbsp;763</div><div class="codeline">in \autoref{chapter:geometrization}.</div><div class="clear"></div>
<div class="linenb">&nbsp;764</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;765</div><div class="codeline"><span class="keyword2">\begin{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Slogan] (26462) [lt:en:UPPERCASE_SENTENCE_START]"></span>slogan}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;766</div><div class="codeline">    word2vec = dot product + gradient descent + some vector operations.</div><div class="clear"></div>
<div class="linenb">&nbsp;767</div><div class="codeline"><span class="keyword2">\end{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Slogan] (26541) [lt:en:UPPERCASE_SENTENCE_START]"></span>slogan}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;768</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;769</div><div class="codeline">\chapter{Abstract <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Interpretation., Interpretation!, Interpretation?, Interpretation:, Interpretation,, Interpretation;] (26558) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>Interpretation}</div><div class="clear"></div>
<div class="linenb">&nbsp;770</div><div class="codeline"><span class="keyword1">\label</span>{chapter:abstract-interpretation}</div><div class="clear"></div>
<div class="linenb">&nbsp;771</div><div class="codeline">\epigraph{Among the thousand-and-one faces whereby form chooses to reveal itself to us, the one that fascinates me more than any other, and continues to fascinate me, is the structure hidden in mathematical<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> things.}{<span class="highlight" title="Add a space between sentences. Suggestions: [ Alexander] (26778) [lt:en:SENTENCE_WHITESPACE]">Al</span>exander</span> <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Grothendieck., Grothendieck!, Grothendieck?, Grothendieck:, Grothendieck,, Grothendieck;] (26788) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>Grothendieck}</div><div class="clear"></div>
<div class="linenb">&nbsp;772</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;773</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;774</div><div class="codeline"><span class="highlight" title="The genitive is possibly missing.. Suggestions: [Montague's grammar] (26803) [lt:en:MISSING_GENITIVE]">Montague grammar</span> is an approach to natural language semantics pioneered by</div><div class="clear"></div>
<div class="linenb">&nbsp;775</div><div class="codeline">Richard Montague \cite{sep-montague-semantics}. <span class="highlight" title="The genitive is possibly missing.. Suggestions: [Montague's grammar] (26900) [lt:en:MISSING_GENITIVE]">Montague grammar</span> is based</div><div class="clear"></div>
<div class="linenb">&nbsp;776</div><div class="codeline">on mathematical logic.  <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (26950) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">Montague</span> held the view that natural language was a</div><div class="clear"></div>
<div class="linenb">&nbsp;777</div><div class="codeline">formal language very much in the same sense as predicate logic was a formal</div><div class="clear"></div>
<div class="linenb">&nbsp;778</div><div class="codeline">language. As such, in Montague’s view, the study of natural language belonged</div><div class="clear"></div>
<div class="linenb">&nbsp;779</div><div class="codeline">to mathematics. To quote:</div><div class="clear"></div>
<div class="linenb">&nbsp;780</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;781</div><div class="codeline"><span class="keyword2">\begin{quote}</span> There is in my opinion no important theoretical difference</div><div class="clear"></div>
<div class="linenb">&nbsp;782</div><div class="codeline">    between natural languages and the artificial languages of logicians; indeed</div><div class="clear"></div>
<div class="linenb">&nbsp;783</div><div class="codeline">    I consider it possible to comprehend the syntax and semantics of both kinds</div><div class="clear"></div>
<div class="linenb">&nbsp;784</div><div class="codeline">    of languages with a single natural and mathematically precise theory.</div><div class="clear"></div>
<div class="linenb">&nbsp;785</div><div class="codeline"><span class="keyword2">\end{quote}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;786</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;787</div><div class="codeline"><span class="highlight" title="The genitive is possibly missing.. Suggestions: [Montague's semantics] (27478) [lt:en:MISSING_GENITIVE]">Montague semantics</span> is used to describe the semantic properties of language.</div><div class="clear"></div>
<div class="linenb">&nbsp;788</div><div class="codeline">Broadly speaking, a sentence is given meaning by constructing the set of all</div><div class="clear"></div>
<div class="linenb">&nbsp;789</div><div class="codeline">possible worlds where that sentence is true. For a mathematical example, the</div><div class="clear"></div>
<div class="linenb">&nbsp;790</div><div class="codeline">sentence $l \equiv (\forall x \in \Z, x &lt; 2)$ is given meaning by constructing</div><div class="clear"></div>
<div class="linenb">&nbsp;791</div><div class="codeline">the set $S_l \equiv \{ x \in \Z : x &lt; 2 \} = \{1, 0, -1, \dots \}$. A false</div><div class="clear"></div>
<div class="linenb">&nbsp;792</div><div class="codeline">proposition, such that $l' \equiv \forall x \in \Z, x &gt; x + 1$ is given meaning</div><div class="clear"></div>
<div class="linenb">&nbsp;793</div><div class="codeline">by the <span class="keyword1">\emph</span>{empty set} $S_{l'} \equiv \{ x \in \Z: x &gt; x + 1 \} = \emptyset$.</div><div class="clear"></div>
<div class="linenb">&nbsp;794</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;795</div><div class="codeline">According to Montague, statements in natural language can also be written in the</div><div class="clear"></div>
<div class="linenb">&nbsp;796</div><div class="codeline">form of such predicates and have defined truth values. However, given that</div><div class="clear"></div>
<div class="linenb">&nbsp;797</div><div class="codeline">natural language can express notions of the past, present, and future, as well</div><div class="clear"></div>
<div class="linenb">&nbsp;798</div><div class="codeline">as real and imaginary. Therefore, the study of natural language semantics is</div><div class="clear"></div>
<div class="linenb">&nbsp;799</div><div class="codeline">then understood as the construction of a model of expression, therefore <span class="highlight-spelling" title="Possible spelling mistake. Did you mean 'labelled', the past tense form of the verb 'label'?. Suggestions: [labelled, label ed] (28218) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>labeled</div><div class="clear"></div>
<div class="linenb">&nbsp;800</div><div class="codeline">``model-theoretic semantics<span class="highlight" title="Unpaired symbol: ''' seems to be missing (28253) [lt:en:EN_UNPAIRED_BRACKETS]">'</span>'. Note also, that because natural language is</div><div class="clear"></div>
<div class="linenb">&nbsp;801</div><div class="codeline">highly expressive, the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [turn, turf, Turk, tush, Tur, Turf, turd] (28324) [lt:en:MORFOLOGIK_RULE_EN_GB]">turh</span> value of a predicate is determined by its truth in</div><div class="clear"></div>
<div class="linenb">&nbsp;802</div><div class="codeline">any world where that model of semantics is applicable. Two conclusions arise</div><div class="clear"></div>
<div class="linenb">&nbsp;803</div><div class="codeline">from this, first that Montague semantics operates in the realm of predicates or</div><div class="clear"></div>
<div class="linenb">&nbsp;804</div><div class="codeline">statements, and the second, that it is <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [incomputable] (28576) [lt:en:MORFOLOGIK_RULE_EN_GB]">uncomputable</span>.</div><div class="clear"></div>
<div class="linenb">&nbsp;805</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;806</div><div class="codeline">How then, do we study the nature of individual words and/or phrases which are</div><div class="clear"></div>
<div class="linenb">&nbsp;807</div><div class="codeline">not full predicates? One possible method is by redefining the idea of truth or</div><div class="clear"></div>
<div class="linenb">&nbsp;808</div><div class="codeline">falsehood. Montague considers that the truth value of a statement is predicated</div><div class="clear"></div>
<div class="linenb">&nbsp;809</div><div class="codeline">on the meaning of individual words and the method of syntactic combination. That</div><div class="clear"></div>
<div class="linenb">&nbsp;810</div><div class="codeline">is to say, Montague semantics is inherently compositional. With this notion in</div><div class="clear"></div>
<div class="linenb">&nbsp;811</div><div class="codeline">mind, we can consider the meaning of each word as that which is shared by all</div><div class="clear"></div>
<div class="linenb">&nbsp;812</div><div class="codeline">``users'' of that word, those who share that property, can observe that</div><div class="clear"></div>
<div class="linenb">&nbsp;813</div><div class="codeline">phenomenon, and extensionally validate its existence.</div><div class="clear"></div>
<div class="linenb">&nbsp;814</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;815</div><div class="codeline">As a linguistic example, the meaning of walk, or sing is defined as the set of</div><div class="clear"></div>
<div class="linenb">&nbsp;816</div><div class="codeline">individuals who share respectively the property of walking or the property of</div><div class="clear"></div>
<div class="linenb">&nbsp;817</div><div class="codeline">singing \cite{sep-montague-semantics}.  By appealing to the principle of compositionality, if there is a</div><div class="clear"></div>
<div class="linenb">&nbsp;818</div><div class="codeline">rule that combines these two expressions to the verb phrase walk and sing,</div><div class="clear"></div>
<div class="linenb">&nbsp;819</div><div class="codeline">there must be a corresponding rule that determines the meaning of that verb</div><div class="clear"></div>
<div class="linenb">&nbsp;820</div><div class="codeline">phrase. In this case, the resulting meaning will be the <span class="keyword1">\emph</span>{intersection} of</div><div class="clear"></div>
<div class="linenb">&nbsp;821</div><div class="codeline">the two sets.  Thus, the meaning of walk and sing is a subset of the meaning of</div><div class="clear"></div>
<div class="linenb">&nbsp;822</div><div class="codeline">walk.</div><div class="clear"></div>
<div class="linenb">&nbsp;823</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;824</div><div class="codeline">Ambiguity is dealt with by constructing sets which capture <span class="keyword1">\emph</span>{all possible</div><div class="clear"></div>
<div class="linenb">&nbsp;825</div><div class="codeline">meanings}.  For example, the sentence ``Every man loves a woman'' can be ascribed</div><div class="clear"></div>
<div class="linenb">&nbsp;826</div><div class="codeline">multiple meanings: (a) Every man loves the <span class="keyword1">\emph</span>{same} woman (say, Lilith), or</div><div class="clear"></div>
<div class="linenb">&nbsp;827</div><div class="codeline">(b) every man loves a <span class="keyword1">\emph</span>{different} woman. This is dealt with by considering</div><div class="clear"></div>
<div class="linenb">&nbsp;828</div><div class="codeline">the union of <span class="keyword1">\emph</span>{both sets of meanings}. To resolve ambiguity given more</div><div class="clear"></div>
<div class="linenb">&nbsp;829</div><div class="codeline">context, we intersect the union of both sets of meaning with the correct context.</div><div class="clear"></div>
<div class="linenb">&nbsp;830</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;831</div><div class="codeline">In general, we see that to associate <span class="keyword1">\emph</span>{syntax}<span class="highlight-sh" title="There should be a space after a comma. [sh:d:001]"><span class="highlight" title="Put a space after the comma. Suggestions: [, our] (30231) [lt:en:COMMA_PARENTHESIS_WHITESPACE]">,o</span>ur</span> strings of text with</div><div class="clear"></div>
<div class="linenb">&nbsp;832</div><div class="codeline"><span class="keyword1">\emph</span>{semantics}, we <span class="keyword1">\emph</span>{define semantics} to be sets of object which satisfy the word.</div><div class="clear"></div>
<div class="linenb">&nbsp;833</div><div class="codeline">This is very reminiscent of what happens in logic. For example, in propositional calculus,</div><div class="clear"></div>
<div class="linenb">&nbsp;834</div><div class="codeline">we can associate the syntactic string</div><div class="clear"></div>
<div class="linenb">&nbsp;835</div><div class="codeline">$(x \lor y)$, where $x$ and $y$ are variables is associated to <span class="keyword1">\emph</span>{all assignments} of $x$ and $y$ which make</div><div class="clear"></div>
<div class="linenb">&nbsp;836</div><div class="codeline">the expression true. Hence, we have that the semantics of $x \lor y$ is $\{ (x=T, y=T), (x=F, y=T), (x=T, y=F) \}$.</div><div class="clear"></div>
<div class="linenb">&nbsp;837</div><div class="codeline">See that this is really carrying the semantics of $(x \lor y)$, for if we change</div><div class="clear"></div>
<div class="linenb">&nbsp;838</div><div class="codeline">the syntactic string $(x \lor y)$ to another semantically equivalent string such</div><div class="clear"></div>
<div class="linenb">&nbsp;839</div><div class="codeline">as $(x \lor y \lor y)$, the set of values which makes $(x \lor y \lor y)$ true is</div><div class="clear"></div>
<div class="linenb">&nbsp;840</div><div class="codeline">the same as the set of values which make $(x \lor y)$ true. Thus, it is indeed the case</div><div class="clear"></div>
<div class="linenb">&nbsp;841</div><div class="codeline">that this notion of meaning is semantic.</div><div class="clear"></div>
<div class="linenb">&nbsp;842</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;843</div><div class="codeline">A general theory of such associations between syntax and semantics</div><div class="clear"></div>
<div class="linenb">&nbsp;844</div><div class="codeline">was developed by the programming languages community, who had to assign semantic</div><div class="clear"></div>
<div class="linenb">&nbsp;845</div><div class="codeline">meaning to the syntactic notion of strings in order to <span class="highlight-spelling" title="Possible spelling mistake. 'analyze' is American English.. Suggestions: [analyse] (31122) [lt:en:MORFOLOGIK_RULE_EN_GB]">analyze</span> and optimize</div><div class="clear"></div>
<div class="linenb">&nbsp;846</div><div class="codeline">computer programs. Towards this goal, they developed a powerful framework</div><div class="clear"></div>
<div class="linenb">&nbsp;847</div><div class="codeline">called <span class="keyword1">\emph</span>{Abstract Interpretation} \cite{cousot1977abstract} to not</div><div class="clear"></div>
<div class="linenb">&nbsp;848</div><div class="codeline">only capture the notion of approximating meaning, but also capture the notion of</div><div class="clear"></div>
<div class="linenb">&nbsp;849</div><div class="codeline">creating <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [hierarchies] (31349) [lt:en:MORFOLOGIK_RULE_EN_GB]">hieararchies</span> of approximations of meaning. This allows one to</div><div class="clear"></div>
<div class="linenb">&nbsp;850</div><div class="codeline">begin from the entire meaning of a program, which is <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [incomputable] (31464) [lt:en:MORFOLOGIK_RULE_EN_GB]">uncomputable</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [he, we, be, me, due, up, us, use, UK, UV, cue, sue, hue, rue, ye, um, OE, uh, Tue, CE, Ce, De, Fe, Ge, Le, Ne, PE, Se, Sue, Te, U, UI, UL, UN, US, UT, UX, Up, Ur, Ute, e, le, né, re, ve] (31477) [lt:en:MORFOLOGIK_RULE_EN_GB]">ue</span> to the Halting Problem<span class="highlight" title="Put a space after the comma, but not before the comma. Suggestions: [,] (31502) [lt:en:COMMA_PARENTHESIS_WHITESPACE]"></span> ,</div><div class="clear"></div>
<div class="linenb">&nbsp;851</div><div class="codeline">and create a lossy, approximate, but computable semantics of the program.</div><div class="clear"></div>
<div class="linenb">&nbsp;852</div><div class="codeline">It was used to unify many disparate program analysis techniques, such as</div><div class="clear"></div>
<div class="linenb">&nbsp;853</div><div class="codeline">dataflow analysis \cite{khedker2017data} and type checking \cite{file1991abstract}.</div><div class="clear"></div>
<div class="linenb">&nbsp;854</div><div class="codeline">The object that lies at the heart of Abstract Interpretation is the <span class="keyword1">\emph</span>{Galois connection}</div><div class="clear"></div>
<div class="linenb">&nbsp;855</div><div class="codeline">\cite{cousot1992comparing}, which is a way to relate two partial orders, such</div><div class="clear"></div>
<div class="linenb">&nbsp;856</div><div class="codeline">that one of them is an approximation of the other.</div><div class="clear"></div>
<div class="linenb">&nbsp;857</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;858</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;859</div><div class="codeline">We will show how the notion of a Galois connection provides a good notion of</div><div class="clear"></div>
<div class="linenb">&nbsp;860</div><div class="codeline">``approximation of meaning'', and how this directly relates to Montague's ideas</div><div class="clear"></div>
<div class="linenb">&nbsp;861</div><div class="codeline">of representing semantics as subsets.  We exploit Montague semantics as the</div><div class="clear"></div>
<div class="linenb">&nbsp;862</div><div class="codeline">bridge to connect the distributional <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [feature, nature, capture, lecture, mature, pasture, stature, ligature, rapture, facture] (32161) [lt:en:MORFOLOGIK_RULE_EN_GB]">laature</span> of \texttt{word2vec} with the</div><div class="clear"></div>
<div class="linenb">&nbsp;863</div><div class="codeline">set-theoretic nature of fuzzy sets. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (32226) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">We</span> conjecture that \texttt{word2vec}</div><div class="clear"></div>
<div class="linenb">&nbsp;864</div><div class="codeline">computes a sequence of abstract interpretations, first from the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [incomputable] (32318) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>uncomputable</div><div class="clear"></div>
<div class="linenb">&nbsp;865</div><div class="codeline">semantics of natural language that of the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Montague] (32373) [lt:en:MORFOLOGIK_RULE_EN_GB]">Montagueian</span> semantics, which we</div><div class="clear"></div>
<div class="linenb">&nbsp;866</div><div class="codeline">extract by exploiting fuzzy set theory. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (32445) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">We</span> garner evidence towards this</div><div class="clear"></div>
<div class="linenb">&nbsp;867</div><div class="codeline">conjecture.</div><div class="clear"></div>
<div class="linenb">&nbsp;868</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;869</div><div class="codeline"><span class="keyword1">\section</span>{Abstracting <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Size., Size!, Size?, Size:, Size,, Size;] (32502) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>Size}</div><div class="clear"></div>
<div class="linenb">&nbsp;870</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;871</div><div class="codeline">Let us consider the concept of size in the framework of <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Montague, montage, Montagu] (32564) [lt:en:MORFOLOGIK_RULE_EN_GB]">montague</span> semantics.  A</div><div class="clear"></div>
<div class="linenb">&nbsp;872</div><div class="codeline">word is associate to all concepts that are attached to it. In particular, if a</div><div class="clear"></div>
<div class="linenb">&nbsp;873</div><div class="codeline">word carries a connotation of being \texttt{large}, its semantics will contain</div><div class="clear"></div>
<div class="linenb">&nbsp;874</div><div class="codeline">all concepts of being long. For example, the word ``sun'' will contain</div><div class="clear"></div>
<div class="linenb">&nbsp;875</div><div class="codeline">concepts such as \texttt{\{hot, fire, huge, astronomical \}} where words such as</div><div class="clear"></div>
<div class="linenb">&nbsp;876</div><div class="codeline">\texttt{huge} and \texttt{astronomical} are to do with the concept of being large.</div><div class="clear"></div>
<div class="linenb">&nbsp;877</div><div class="codeline">Similarly, for a word which denotes something that</div><div class="clear"></div>
<div class="linenb">&nbsp;878</div><div class="codeline">is \texttt{small}, its semantics will contain all concepts related to being small. For example,</div><div class="clear"></div>
<div class="linenb">&nbsp;879</div><div class="codeline">the word \texttt{hair} will contain concepts such as \texttt{silky, strand, small, filament, thin},</div><div class="clear"></div>
<div class="linenb">&nbsp;880</div><div class="codeline">where concepts such as \texttt{small} and \texttt{thin} refer to size.</div><div class="clear"></div>
<div class="linenb">&nbsp;881</div><div class="codeline">For some word that represents <span class="keyword1">\emph</span>{both} large and small, such as \texttt{moderate},</div><div class="clear"></div>
<div class="linenb">&nbsp;882</div><div class="codeline">the semantics will contain concepts of <span class="keyword1">\emph</span>{both} large and small.</div><div class="clear"></div>
<div class="linenb">&nbsp;883</div><div class="codeline">Finally, for a word that represents neither, such as \texttt{Tea}, the semantics of the word</div><div class="clear"></div>
<div class="linenb">&nbsp;884</div><div class="codeline">will contain <span class="keyword1">\emph</span>{neither} largeness nor smallness. Thus, <span class="highlight" title="Do not mix variants of the same word ('amongst' and 'among') within a single text.. Suggestions: [among] (33480) [lt:en:EN_WORD_COHERENCY]">amongst</span> all possible</div><div class="clear"></div>
<div class="linenb">&nbsp;885</div><div class="codeline">concepts, we can focus on the small collection of four possible choices of</div><div class="clear"></div>
<div class="linenb">&nbsp;886</div><div class="codeline">having a notion of size: (1) being large, (2) being small, (3) being both, and</div><div class="clear"></div>
<div class="linenb">&nbsp;887</div><div class="codeline">being neither.</div><div class="clear"></div>
<div class="linenb">&nbsp;888</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;889</div><div class="codeline">To encode this formally, we first consider the collection of all semantics.</div><div class="clear"></div>
<div class="linenb">&nbsp;890</div><div class="codeline">This is going to be the collection of all subsets of the set of all objects,</div><div class="clear"></div>
<div class="linenb">&nbsp;891</div><div class="codeline">since the semantics of a word is given by the set of all  objects that denote the word.</div><div class="clear"></div>
<div class="linenb">&nbsp;892</div><div class="codeline">For example, the word \texttt{large} is denoted by the set of objects which are large,</div><div class="clear"></div>
<div class="linenb">&nbsp;893</div><div class="codeline">such as \texttt{\{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Nile, nice, mile, nine, file, pile, tile, bile, Nike, Niles, Nils, nil, vile, Niue, rile, wile, Ile, Mile, Nice, Nine, nil e] (33998) [lt:en:MORFOLOGIK_RULE_EN_GB]">nile</span>, train, rope,<span class="highlight-sh" title="There should not be a space before the period at the end of a sentence. [sh:d:003]"> ..</span>.<span class="highlight" title="Put a space after the comma, but not before the comma. Suggestions: [,] (34020) [lt:en:COMMA_PARENTHESIS_WHITESPACE]"></span> \}},</div><div class="clear"></div>
<div class="linenb">&nbsp;894</div><div class="codeline">while the word \texttt{small} is denoted by the set of objects which are small,</div><div class="clear"></div>
<div class="linenb">&nbsp;895</div><div class="codeline">such as \texttt{\{hair, hobbits, dots,<span class="highlight-sh" title="There should not be a space before the period at the end of a sentence. [sh:d:003]"> ..</span>.<span class="highlight" title="Don't put a space before the full stop. Suggestions: [.] (34126) [lt:en:COMMA_PARENTHESIS_WHITESPACE]"></span> \}}.</div><div class="clear"></div>
<div class="linenb">&nbsp;896</div><div class="codeline">\footnote{We avoid discussing concerns related</div><div class="clear"></div>
<div class="linenb">&nbsp;897</div><div class="codeline">to Russell's paradox; These can be obviated by either arbitrarily limiting the sizes of all sets</div><div class="clear"></div>
<div class="linenb">&nbsp;898</div><div class="codeline">involved, or performing more sophisticated set theoretic constructions}.</div><div class="clear"></div>
<div class="linenb">&nbsp;899</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;900</div><div class="codeline">The <span class="highlight-spelling" title="Possible spelling mistake. 'concretization' is American English.. Suggestions: [concretisation] (34340) [lt:en:MORFOLOGIK_RULE_EN_GB]">concretization</span> function attempts to make the idea of <span class="keyword1">\emph</span>{long} and</div><div class="clear"></div>
<div class="linenb">&nbsp;901</div><div class="codeline"><span class="keyword1">\emph</span>{short} concrete, by sending the concepts $\bot, L, S, \top$ to the empty</div><div class="clear"></div>
<div class="linenb">&nbsp;902</div><div class="codeline">set, the set of meanings of the word \texttt{long}, the set of meanings of the word</div><div class="clear"></div>
<div class="linenb">&nbsp;903</div><div class="codeline">\texttt{short}, and to the union of the two sets of meaning.</div><div class="clear"></div>
<div class="linenb">&nbsp;904</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;905</div><div class="codeline"><span class="keyword1">\section</span>{Interval <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [domain., domain!, domain?, domain:, domain,, domain;] (34594) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>domain}</div><div class="clear"></div>
<div class="linenb">&nbsp;906</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;907</div><div class="codeline">A more mathematical, second example is that of the interval domain, where we map</div><div class="clear"></div>
<div class="linenb">&nbsp;908</div><div class="codeline">subsets of the plane to rectangles whose axes are aligned with the x and y axes.</div><div class="clear"></div>
<div class="linenb">&nbsp;909</div><div class="codeline">These can be represented as a pair of intervals, and hence this is known as the</div><div class="clear"></div>
<div class="linenb">&nbsp;910</div><div class="codeline"><span class="keyword1">\emph</span>{interval domain}. The interval domain allows us to show a mathematical example</div><div class="clear"></div>
<div class="linenb">&nbsp;911</div><div class="codeline">of abstraction, as well as allowing us to show how to perform abstract interpretations</div><div class="clear"></div>
<div class="linenb">&nbsp;912</div><div class="codeline">of union and intersection, which is important to develop a compositional theory of meaning.</div><div class="clear"></div>
<div class="linenb">&nbsp;913</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;914</div><div class="codeline">The domain $I \equiv Z \times Z$ represents closed intervals. So an element $(1, 3)</div><div class="clear"></div>
<div class="linenb">&nbsp;915</div><div class="codeline">\in I$ is an abstract representation of the closed interval $[1, 3] = \{ 1, 2,</div><div class="clear"></div>
<div class="linenb">&nbsp;916</div><div class="codeline">3 \}$.  Similarly, the element $(1, 0) \in <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [In, Is, I, It, If, IQ, Id, IP, IA, IC, ID, IR, IU, I3, I5, I7, I9, Ii, Iv, Ix, IG] (35202) [lt:en:MORFOLOGIK_RULE_EN_GB]">I$</span> is an abstract representation of</div><div class="clear"></div>
<div class="linenb">&nbsp;917</div><div class="codeline">the interval $[1, 0] = \emptyset$, as there is no interval whose leftmost point</div><div class="clear"></div>
<div class="linenb">&nbsp;918</div><div class="codeline">is $1$ and rightmost point is $0$.  In this case, the abstraction function</div><div class="clear"></div>
<div class="linenb">&nbsp;919</div><div class="codeline">$\alpha: L \rightarrow L^\sharp$ goes from a set of integers to the smallest</div><div class="clear"></div>
<div class="linenb">&nbsp;920</div><div class="codeline">interval containing these numbers. For example, $\alpha(\{1, 2, 3\}) = (1, 3)$,</div><div class="clear"></div>
<div class="linenb">&nbsp;921</div><div class="codeline">and $\alpha(\{1, 5\}) = (1, 3, 5)$.  See that the latter is an approximation:</div><div class="clear"></div>
<div class="linenb">&nbsp;922</div><div class="codeline">we are representing the triple of numbers $1, 3$ and $5$ by the <span class="keyword1">\emph</span>{whole</div><div class="clear"></div>
<div class="linenb">&nbsp;923</div><div class="codeline">interval} $(1, 5)$, which we think of as $\{1, 2, 3, 4, 5\}$. To make this</div><div class="clear"></div>
<div class="linenb">&nbsp;924</div><div class="codeline">formal, we define the <span class="highlight-spelling" title="Possible spelling mistake. 'concretization' is American English.. Suggestions: [concretisation] (35650) [lt:en:MORFOLOGIK_RULE_EN_GB]">concretization</span> function $\gamma: L^\sharp \rightarrow L$,</div><div class="clear"></div>
<div class="linenb">&nbsp;925</div><div class="codeline">where $\gamma((l, r)) \equiv \{ x \in \mathbb Z : l \leq x \leq r \}$.</div><div class="clear"></div>
<div class="linenb">&nbsp;926</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;927</div><div class="codeline"><span class="keyword1">\includegraphics</span>[width=\textwidth]{./alpha-gamma-intervals.pdf}</div><div class="clear"></div>
<div class="linenb">&nbsp;928</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;929</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;930</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;931</div><div class="codeline"><span class="keyword1">\subsection</span>{Monotonicity in the Interval domain}</div><div class="clear"></div>
<div class="linenb">&nbsp;932</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;933</div><div class="codeline">The process of abstraction is monotonic. If we have a larger collection of points, then we necessarily</div><div class="clear"></div>
<div class="linenb">&nbsp;934</div><div class="codeline">get an equal or larger interval which bounds these points. The property where more information</div><div class="clear"></div>
<div class="linenb">&nbsp;935</div><div class="codeline">in the input yields more information in the output is called as <span class="keyword1">\emph</span>{monotonicity}. Formally speaking,</div><div class="clear"></div>
<div class="linenb">&nbsp;936</div><div class="codeline">given $x \leq x$, we are guaranteed that the abstraction $\alpha$ maintains that $\alpha(x) \leq \alpha(x')$.</div><div class="clear"></div>
<div class="linenb">&nbsp;937</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;938</div><div class="codeline"><span class="keyword1">\includegraphics</span>[width=\textwidth]{./monotone.pdf}</div><div class="clear"></div>
<div class="linenb">&nbsp;939</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;940</div><div class="codeline"><span class="keyword1">\subsection</span>{Unions in the Interval domain}</div><div class="clear"></div>
<div class="linenb">&nbsp;941</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;942</div><div class="codeline">To define <span class="keyword1">\emph</span>{union} and <span class="keyword1">\emph</span>{intersection} of our intervals, we intuitively</div><div class="clear"></div>
<div class="linenb">&nbsp;943</div><div class="codeline">want toe <span class="keyword1">\emph</span>{union} of two intervals to be the smallest interval that <span class="keyword1">\emph</span>{contains} them.</div><div class="clear"></div>
<div class="linenb">&nbsp;944</div><div class="codeline">Similarly, we want the <span class="keyword1">\emph</span>{intersection} of two intervals to be the <span class="keyword1">\emph</span>{largest} interval</div><div class="clear"></div>
<div class="linenb">&nbsp;945</div><div class="codeline"><span class="keyword1">\emph</span>{contained} in both of them.</div><div class="clear"></div>
<div class="linenb">&nbsp;946</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;947</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;948</div><div class="codeline"><span class="keyword1">\includegraphics</span>[width=\textwidth]{./union.pdf}</div><div class="clear"></div>
<div class="linenb">&nbsp;949</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;950</div><div class="codeline">This shows that the theory of abstract interpretation is compatible with set</div><div class="clear"></div>
<div class="linenb">&nbsp;951</div><div class="codeline">operations. In particular, the theory of abstract interpretation is capable of</div><div class="clear"></div>
<div class="linenb">&nbsp;952</div><div class="codeline">abstracting notions of union and intersection, since the union and intersection</div><div class="clear"></div>
<div class="linenb">&nbsp;953</div><div class="codeline">of the sets of integers is approximated by joins and meets in the abstract even-odd</div><div class="clear"></div>
<div class="linenb">&nbsp;954</div><div class="codeline">lattice.</div><div class="clear"></div>
<div class="linenb">&nbsp;955</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;956</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;957</div><div class="codeline">\<span class="highlight-sh" title="This subsection is very short (about 107 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsection</span>{The Galois connection <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [condition., condition!, condition?, condition:, condition,, condition;] (36735) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>condition}</div><div class="clear"></div>
<div class="linenb">&nbsp;958</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;959</div><div class="codeline">The abstract and the concrete world are linked by the properties:</div><div class="clear"></div>
<div class="linenb">&nbsp;960</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;961</div><div class="codeline"><span class="keyword2">\begin{align*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;962</div><div class="codeline">    &amp;(1) \quad C \subseteq (\gamma\circ \alpha)(C) \\</div><div class="clear"></div>
<div class="linenb">&nbsp;963</div><div class="codeline">    &amp;(2) \quad a = (\alpha \circ \gamma)(a) \\</div><div class="clear"></div>
<div class="linenb">&nbsp;964</div><div class="codeline"><span class="keyword2">\end{align*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;965</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;966</div><div class="codeline">These first equation tell us that abstracting a concrete idea $C$ into</div><div class="clear"></div>
<div class="linenb">&nbsp;967</div><div class="codeline">$\alpha(C)$ and then concretizing the abstract idea using $\gamma(\alpha(C))$</div><div class="clear"></div>
<div class="linenb">&nbsp;968</div><div class="codeline">might lead to a loss of information. This captures the intuition that the abstraction</div><div class="clear"></div>
<div class="linenb">&nbsp;969</div><div class="codeline">is lossy. The second equation tells us that if we start with an abstract object</div><div class="clear"></div>
<div class="linenb">&nbsp;970</div><div class="codeline"><span class="highlight" title="Did you forget something after 'a'? (37099) [lt:en:THE_PUNCT]">$a$,</span> then concretize it with $\gamma(a)$, this loses no information; Bringing</div><div class="clear"></div>
<div class="linenb">&nbsp;971</div><div class="codeline">it back up to the abstract world with $alpha(\gamma(a)))$ recovers the <span class="highlight" title="Did you forget something after 'a'? (37218) [lt:en:THE_SENT_END]"></span>$a$.</div><div class="clear"></div>
<div class="linenb">&nbsp;972</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;973</div><div class="codeline"><span class="keyword1">\section</span>{Formalism}</div><div class="clear"></div>
<div class="linenb">&nbsp;974</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;975</div><div class="codeline"><span class="keyword2">\begin{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Definition] (37233) [lt:en:UPPERCASE_SENTENCE_START]"></span>definition}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;976</div><div class="codeline">A partial order is a set $L$ equipped with a binary relation $\<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [led, let, leg, Lee, Len, Lev, Lew, seq, Leo, liq, EQ, LED, Le, Lea, Les, Ley, le, lea, lee, lei, lez, le q] (37305) [lt:en:MORFOLOGIK_RULE_EN_GB]">leq</span> \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [subset, subsets, subsected, subsere] (37310) [lt:en:MORFOLOGIK_RULE_EN_GB]">subseteq</span> L</div><div class="clear"></div>
<div class="linenb">&nbsp;977</div><div class="codeline">\times <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [LGA, La, Lea, Lx, LX a] (37328) [lt:en:MORFOLOGIK_RULE_EN_GB]">L$ which is (a) reflexive: ($a</span> \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [led, let, leg, Lee, Len, Lev, Lew, seq, Leo, liq, EQ, LED, Le, Lea, Les, Ley, le, lea, lee, lei, lez, le q] (37333) [lt:en:MORFOLOGIK_RULE_EN_GB]">leq</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [aka, axe, taxa, APA, aha, AAA, AA, AMA, ATA, Ada, Ana, Ara, Asa, Ava, Axe] (37337) [lt:en:MORFOLOGIK_RULE_EN_GB]">a$), (b) anti-symmetric: $a</span> \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [led, let, leg, Lee, Len, Lev, Lew, seq, Leo, liq, EQ, LED, Le, Lea, Les, Ley, le, lea, lee, lei, lez, le q] (37342) [lt:en:MORFOLOGIK_RULE_EN_GB]">leq</span> b</div><div class="clear"></div>
<div class="linenb">&nbsp;978</div><div class="codeline">\land b \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [led, let, leg, Lee, Len, Lev, Lew, seq, Leo, liq, EQ, LED, Le, Lea, Les, Ley, le, lea, lee, lei, lez, le q] (37357) [lt:en:MORFOLOGIK_RULE_EN_GB]">leq</span> a \implies a = <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [BSA, bra, Bea, boa, baa, BA, Ba, ba, bx, bxs] (37376) [lt:en:MORFOLOGIK_RULE_EN_GB]">b$, and (c) transitive: $a</span> \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [led, let, leg, Lee, Len, Lev, Lew, seq, Leo, liq, EQ, LED, Le, Lea, Les, Ley, le, lea, lee, lei, lez, le q] (37381) [lt:en:MORFOLOGIK_RULE_EN_GB]">leq</span> b \land b \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [led, let, leg, Lee, Len, Lev, Lew, seq, Leo, liq, EQ, LED, Le, Lea, Les, Ley, le, lea, lee, lei, lez, le q] (37396) [lt:en:MORFOLOGIK_RULE_EN_GB]">leq</span> c</div><div class="clear"></div>
<div class="linenb">&nbsp;979</div><div class="codeline">\implies a \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [led, let, leg, Lee, Len, Lev, Lew, seq, Leo, liq, EQ, LED, Le, Lea, Les, Ley, le, lea, lee, lei, lez, le q] (37414) [lt:en:MORFOLOGIK_RULE_EN_GB]">leq</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [CD, cm, CV, cl, cw, CE, C, CA, CB, CI, Ca, Ce, Ch, Ci, Cm, Co, Cs, Cu, c, ca, cc, cf, ck, co, cu] (37418) [lt:en:MORFOLOGIK_RULE_EN_GB]">c$</span>.</div><div class="clear"></div>
<div class="linenb">&nbsp;980</div><div class="codeline"><span class="keyword2">\end{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Definition] (37422) [lt:en:UPPERCASE_SENTENCE_START]"></span>definition}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;981</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;982</div><div class="codeline"><span class="keyword2">\begin{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Definition] (37434) [lt:en:UPPERCASE_SENTENCE_START]"></span>definition}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;983</div><div class="codeline">    A monotone map is a morphism of partial orders. Formally,</div><div class="clear"></div>
<div class="linenb">&nbsp;984</div><div class="codeline">it is a function $f: (L, \leq) \rightarrow (L^\sharp, \leq^\sharp)$ such that</div><div class="clear"></div>
<div class="linenb">&nbsp;985</div><div class="codeline">$a \leq b \implies f(a) \leq^\sharp f(b)$.</div><div class="clear"></div>
<div class="linenb">&nbsp;986</div><div class="codeline"><span class="keyword2">\end{definition}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;987</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;988</div><div class="codeline"><span class="keyword2">\begin{definition}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;989</div><div class="codeline">A <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Galois] (37564) [lt:en:MORFOLOGIK_RULE_EN_GB]">galois</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [connection] (37571) [lt:en:MORFOLOGIK_RULE_EN_GB]">connectio</span> between two</div><div class="clear"></div>
<div class="linenb">&nbsp;990</div><div class="codeline">lattice $(L, \leq)$ and $(L^\sharp, \leq^\sharp)$ is a pair of monotone maps</div><div class="clear"></div>
<div class="linenb">&nbsp;991</div><div class="codeline">$\alpha: (L, \leq) \rightarrow (L^\sharp, \leq^\sharp)$, and</div><div class="clear"></div>
<div class="linenb">&nbsp;992</div><div class="codeline">$\gamma: (L^\sharp, \leq^\sharp) \rightarrow  (L, \leq)$ which satisfy the</div><div class="clear"></div>
<div class="linenb">&nbsp;993</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Galois] (37663) [lt:en:MORFOLOGIK_RULE_EN_GB]">galois</span> connection property:</div><div class="clear"></div>
<div class="linenb">&nbsp;994</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;995</div><div class="codeline"><span class="keyword2">\begin{align*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;996</div><div class="codeline">    &amp;(1) \quad C \subseteq (\gamma\circ \alpha)(C) \\</div><div class="clear"></div>
<div class="linenb">&nbsp;997</div><div class="codeline">    &amp;(2) \quad a = (\alpha \circ \gamma)(a) \\</div><div class="clear"></div>
<div class="linenb">&nbsp;998</div><div class="codeline"><span class="keyword2">\end{align*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;999</div><div class="codeline"><span class="keyword2">\end{definition}</span></div><div class="clear"></div>
<div class="linenb">1000</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1001</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1002</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1003</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 57 words). You should consider merging it with another section or make it longer. [sh:seclen]">section</span>{Conclusion}</div><div class="clear"></div>
<div class="linenb">1004</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1005</div><div class="codeline">We learnt that meaning can be (and often is) represented by Galois connections.</div><div class="clear"></div>
<div class="linenb">1006</div><div class="codeline">In particular, the notion of Montague semantics is a Galois connection, which have been</div><div class="clear"></div>
<div class="linenb">1007</div><div class="codeline">exploited by the computer science community to <span class="highlight-spelling" title="Possible spelling mistake. 'analyze' is American English.. Suggestions: [analyse] (37933) [lt:en:MORFOLOGIK_RULE_EN_GB]">analyze</span> and optimize programs.</div><div class="clear"></div>
<div class="linenb">1008</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1009</div><div class="codeline"><span class="keyword2">\begin{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Slogan] (37965) [lt:en:UPPERCASE_SENTENCE_START]"></span>slogan}</span></div><div class="clear"></div>
<div class="linenb">1010</div><div class="codeline">    All meaning is abstract interpretation. Thus, linguistic meaning better be.</div><div class="clear"></div>
<div class="linenb">1011</div><div class="codeline"><span class="keyword2">\end{slogan}</span></div><div class="clear"></div>
<div class="linenb">1012</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1013</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1014</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1015</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1016</div><div class="codeline">\chapter{Fuzzy set representations}</div><div class="clear"></div>
<div class="linenb">1017</div><div class="codeline"><span class="keyword1">\label</span>{chapter:fuzzy-set-representation}</div><div class="clear"></div>
<div class="linenb">1018</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1019</div><div class="codeline">\epigraph{And if we tamper with our inheritance, so what? What is more ours to tamper with?}{<span class="highlight" title="Add a space between sentences. Suggestions: [ Ian] (38172) [lt:en:SENTENCE_WHITESPACE]">Ian</span> M <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Banks., Banks!, Banks?, Banks:, Banks,, Banks;] (38178) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>Banks}</div><div class="clear"></div>
<div class="linenb">1020</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1021</div><div class="codeline"><span class="comment"><span class="comment">% \textinit{W}e provide an alternate perspective on word representations, by</span></span></div><div class="clear"></div>
<div class="linenb">1022</div><div class="codeline">We provide an alternate perspective on word representations, by</div><div class="clear"></div>
<div class="linenb">1023</div><div class="codeline">reinterpreting the dimensions of the vector space of a word embedding as a</div><div class="clear"></div>
<div class="linenb">1024</div><div class="codeline">collection of features. This work was performed as joint work with <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Amok, Aloe] (38391) [lt:en:MORFOLOGIK_RULE_EN_GB]">Alok</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Death, Debate, Debach, Denbeath] (38396) [lt:en:MORFOLOGIK_RULE_EN_GB]">Debnath</span> and </div><div class="clear"></div>
<div class="linenb">1025</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Moujik, Soulie] (38409) [lt:en:MORFOLOGIK_RULE_EN_GB]">Souvik</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Bakeries, Bannered, Banshee, Bantered, Bargee, Bintree, Ganerew, Banterer] (38416) [lt:en:MORFOLOGIK_RULE_EN_GB]">Banerjee</span>. In this reinterpretation, every component of the word</div><div class="clear"></div>
<div class="linenb">1026</div><div class="codeline">vector is normalized against all the word vectors in the vocabulary. This idea</div><div class="clear"></div>
<div class="linenb">1027</div><div class="codeline">now allows us to view each vector as an $n$-tuple (akin to a fuzzy set), where</div><div class="clear"></div>
<div class="linenb">1028</div><div class="codeline">$n$ is the dimensionality of the word representation and each element</div><div class="clear"></div>
<div class="linenb">1029</div><div class="codeline">represents the probability of the word possessing a feature. Indeed, this</div><div class="clear"></div>
<div class="linenb">1030</div><div class="codeline">representation enables the use fuzzy set theoretic operations, such as union,</div><div class="clear"></div>
<div class="linenb">1031</div><div class="codeline">intersection and difference. Unlike previous attempts, we show that this</div><div class="clear"></div>
<div class="linenb">1032</div><div class="codeline">representation of words provides a notion of similarity which is inherently</div><div class="clear"></div>
<div class="linenb">1033</div><div class="codeline">asymmetric and hence closer to human similarity judgements. We compare the</div><div class="clear"></div>
<div class="linenb">1034</div><div class="codeline">performance of this representation with various benchmarks, and explore <span class="highlight" title="If the text is a generality, 'of the' is not necessary. Do you mean 'some'?. Suggestions: [some] (39152) [lt:en:SOME_OF_THE]">s</span>ome of</div><div class="clear"></div>
<div class="linenb">1035</div><div class="codeline">the unique properties including function word detection, detection of</div><div class="clear"></div>
<div class="linenb">1036</div><div class="codeline">polysemous words, and some insight into the interpretability provided by set</div><div class="clear"></div>
<div class="linenb">1037</div><div class="codeline">theoretic operations.</div><div class="clear"></div>
<div class="linenb">1038</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1039</div><div class="codeline"> Other word representations tried to provide</div><div class="clear"></div>
<div class="linenb">1040</div><div class="codeline">asymmetric notions of similarity in a non-contextualized setting, including</div><div class="clear"></div>
<div class="linenb">1041</div><div class="codeline">Gaussian embeddings \citep{vilnis2014word} and word similarity by dependency</div><div class="clear"></div>
<div class="linenb">1042</div><div class="codeline">\citep{gawron2014improving}. However, these models could not account for the</div><div class="clear"></div>
<div class="linenb">1043</div><div class="codeline">inherent compositionality of word embeddings \citep{mikolov2013distributed}.</div><div class="clear"></div>
<div class="linenb">1044</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1045</div><div class="codeline">Moreover, while work has been done on providing entailment for vector space</div><div class="clear"></div>
<div class="linenb">1046</div><div class="codeline">models by entirely reinterpreting word2vec as an entailment based semantic</div><div class="clear"></div>
<div class="linenb">1047</div><div class="codeline">model \citep{henderson2016vector}, it requires an external notion of</div><div class="clear"></div>
<div class="linenb">1048</div><div class="codeline">compositionality. Finally, word2vec and <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Glove, Love, Globe, Gloves, Grove, Clove, Gloved, Glover] (39849) [lt:en:MORFOLOGIK_RULE_EN_GB]">GloVe</span>, as such, <span class="highlight" title="The verb 'meaning' is a stative verb and sometimes the progressive form is not correct. Try a simple form instead. (39865) [lt:en:PROGRESSIVE_VERBS]">are meaning</span> conflation</div><div class="clear"></div>
<div class="linenb">1049</div><div class="codeline">deficient, meaning that a single word with all its possible meanings is</div><div class="clear"></div>
<div class="linenb">1050</div><div class="codeline">represented by a single vector \citep{camacho2018word}. Sense representation</div><div class="clear"></div>
<div class="linenb">1051</div><div class="codeline">models in non-contextualized representations such as multi-sense skip gram, by</div><div class="clear"></div>
<div class="linenb">1052</div><div class="codeline">performing joint clustering for local word neighbourhood. However, these sense</div><div class="clear"></div>
<div class="linenb">1053</div><div class="codeline">representations are conditioned on non-disambiguated senses in the context and</div><div class="clear"></div>
<div class="linenb">1054</div><div class="codeline">require additional conditioning on the intended senses \citep{li2015multi}.</div><div class="clear"></div>
<div class="linenb">1055</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1056</div><div class="codeline">In this chapter, we aim to answer the question: <span class="keyword1">\textit</span>{Can a single word</div><div class="clear"></div>
<div class="linenb">1057</div><div class="codeline">representation mechanism account for lexical similarity and analogy,</div><div class="clear"></div>
<div class="linenb">1058</div><div class="codeline">compositionality, lexical entailment <span class="keyword1">\textbf</span>{and} be used to detect and resolve</div><div class="clear"></div>
<div class="linenb">1059</div><div class="codeline">polysemy?} We find that by performing column-wise normalization of word vectors</div><div class="clear"></div>
<div class="linenb">1060</div><div class="codeline">trained using the word2vec skip-gram negative sampling regime, we can indeed</div><div class="clear"></div>
<div class="linenb">1061</div><div class="codeline">represent all the above characteristics in a single representation. We</div><div class="clear"></div>
<div class="linenb">1062</div><div class="codeline">interpret a column wise normalized word representation. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (40804) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">We</span> now treat these</div><div class="clear"></div>
<div class="linenb">1063</div><div class="codeline">representations as fuzzy sets and can therefore use fuzzy set theoretic</div><div class="clear"></div>
<div class="linenb">1064</div><div class="codeline">operations such as union, intersection, difference, etc. while also being able</div><div class="clear"></div>
<div class="linenb">1065</div><div class="codeline">to succinctly use asymmetric notions of similarity such as K-L divergence and</div><div class="clear"></div>
<div class="linenb">1066</div><div class="codeline">cross entropy. Finally, we show that this representation can highlight</div><div class="clear"></div>
<div class="linenb">1067</div><div class="codeline">syntactic features such as function words, use their properties to detect</div><div class="clear"></div>
<div class="linenb">1068</div><div class="codeline">polysemy, and resolve it qualitatively using the inherent compositionality of</div><div class="clear"></div>
<div class="linenb">1069</div><div class="codeline">this representation.</div><div class="clear"></div>
<div class="linenb">1070</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1071</div><div class="codeline">In order to make these experiments and their results observable in general, we</div><div class="clear"></div>
<div class="linenb">1072</div><div class="codeline">have provided the code which can be used to run these operations. \footnote{The code can</div><div class="clear"></div>
<div class="linenb">1073</div><div class="codeline">be found at \url{https://github.com/AlokDebnath/fuzzy_embeddings}}. The code</div><div class="clear"></div>
<div class="linenb">1074</div><div class="codeline">also has a working command line interface where users can perform qualitative</div><div class="clear"></div>
<div class="linenb">1075</div><div class="codeline">assessments on the set theoretic operations, similarity, analogy and</div><div class="clear"></div>
<div class="linenb">1076</div><div class="codeline">compositionality which are discussed in the paper.</div><div class="clear"></div>
<div class="linenb">1077</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1078</div><div class="codeline"><span class="keyword1">\section</span>{Related <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Work., Work!, Work?, Work:, Work,, Work;] (41686) [lt:en:PUNCTUATION_PARAGRAPH_END]">Work}</span> <span class="keyword1">\label</span>{sec: related}</div><div class="clear"></div>
<div class="linenb">1079</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1080</div><div class="codeline">The representation of words using logical paradigms such as fuzzy logic,</div><div class="clear"></div>
<div class="linenb">1081</div><div class="codeline">tensorial representations and other probabilistic approaches have been</div><div class="clear"></div>
<div class="linenb">1082</div><div class="codeline">attempted before. In this section, we uncover some of these representations in</div><div class="clear"></div>
<div class="linenb">1083</div><div class="codeline">detail.</div><div class="clear"></div>
<div class="linenb">1084</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1085</div><div class="codeline">\citet{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Lee1999measures] (41925) [lt:en:UPPERCASE_SENTENCE_START]">lee1999measures}</span> introduced measures of distributional similarity to</div><div class="clear"></div>
<div class="linenb">1086</div><div class="codeline">improve the probability estimation for unseen occurrences. The measure of</div><div class="clear"></div>
<div class="linenb">1087</div><div class="codeline">similarity of distributional word clusters was based on multiple measures</div><div class="clear"></div>
<div class="linenb">1088</div><div class="codeline">including <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Euclidean] (42151) [lt:en:MORFOLOGIK_RULE_EN_GB]">Euclidian</span> distance, cosine distance, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Accord, Packard, Jacquard, Racecard] (42188) [lt:en:MORFOLOGIK_RULE_EN_GB]">Jaccard</span>'s Coefficient, and</div><div class="clear"></div>
<div class="linenb">1089</div><div class="codeline">asymmetric measures like $\alpha$-skew divergence.</div><div class="clear"></div>
<div class="linenb">1090</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1091</div><div class="codeline">\citet{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Bergmair2011monte] (42260) [lt:en:UPPERCASE_SENTENCE_START]">bergmair2011monte}</span> used a fuzzy set theoretic view of features</div><div class="clear"></div>
<div class="linenb">1092</div><div class="codeline">associated with word representations. While these features were not adopted</div><div class="clear"></div>
<div class="linenb">1093</div><div class="codeline">from the vector space directly, it presents a unique perspective of entailment</div><div class="clear"></div>
<div class="linenb">1094</div><div class="codeline">chains for reasoning tasks. Their analysis of inference using fuzzy</div><div class="clear"></div>
<div class="linenb">1095</div><div class="codeline">representations provides interpretability in reasoning tasks.</div><div class="clear"></div>
<div class="linenb">1096</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1097</div><div class="codeline">\citet{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Grefenstette2013towards] (42608) [lt:en:UPPERCASE_SENTENCE_START]">grefenstette2013towards}</span> presents a <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [tensorial] (42643) [lt:en:MORFOLOGIK_RULE_EN_GB]">tenosrial</span> calculus for word</div><div class="clear"></div>
<div class="linenb">1098</div><div class="codeline">embeddings, which is based on compositional operators <span class="keyword1">\emph</span>{which uses} vector</div><div class="clear"></div>
<div class="linenb">1099</div><div class="codeline">representation of words to create a compositional distributional model of</div><div class="clear"></div>
<div class="linenb">1100</div><div class="codeline">meaning. By providing a category-theoretic framework, the model creates an</div><div class="clear"></div>
<div class="linenb">1101</div><div class="codeline">inherently compositional structure based on distributional word</div><div class="clear"></div>
<div class="linenb">1102</div><div class="codeline">representations. However, they showed that in this framework, quantifiers could</div><div class="clear"></div>
<div class="linenb">1103</div><div class="codeline">not be expressed.</div><div class="clear"></div>
<div class="linenb">1104</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1105</div><div class="codeline">\citet{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Herbelot2015building] (43055) [lt:en:UPPERCASE_SENTENCE_START]">herbelot2015building}</span> refers to a notion of general formal semantics</div><div class="clear"></div>
<div class="linenb">1106</div><div class="codeline">inferred from a distributional representation by creating relevant ontology</div><div class="clear"></div>
<div class="linenb">1107</div><div class="codeline">based on the existing distribution. This mapping is therefore from a standard</div><div class="clear"></div>
<div class="linenb">1108</div><div class="codeline">distributional model to a set-theoretic model, where dimensions are predicates</div><div class="clear"></div>
<div class="linenb">1109</div><div class="codeline">and weights are <span class="highlight" title="Do not mix variants of the same word ('generalise' and 'generalize') within a single text.. Suggestions: [generalize] (43372) [lt:en:EN_WORD_COHERENCY]">generalised</span> quantifiers.</div><div class="clear"></div>
<div class="linenb">1110</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1111</div><div class="codeline">\citet{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Emerson2016functional] (43398) [lt:en:UPPERCASE_SENTENCE_START]">emerson2016functional</span>, emerson2017semantic} developed functional</div><div class="clear"></div>
<div class="linenb">1112</div><div class="codeline">distributional semantics, which is a probabilistic framework based on model</div><div class="clear"></div>
<div class="linenb">1113</div><div class="codeline">theory. The framework relies on differentiating and learning entities and</div><div class="clear"></div>
<div class="linenb">1114</div><div class="codeline">predicates and their relations, on which Bayesian inference is performed. This</div><div class="clear"></div>
<div class="linenb">1115</div><div class="codeline">representation is inherently compositional, context dependent representation.</div><div class="clear"></div>
<div class="linenb">1116</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1117</div><div class="codeline"><span class="keyword1">\section</span>{Background: Fuzzy Sets and Fuzzy Logic} <span class="keyword1">\label</span>{sec: math}</div><div class="clear"></div>
<div class="linenb">1118</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1119</div><div class="codeline">In this section, we provide a basic background of fuzzy sets including some</div><div class="clear"></div>
<div class="linenb">1120</div><div class="codeline">fuzzy set operations, reinterpreting sets as tuples in a universe of finite</div><div class="clear"></div>
<div class="linenb">1121</div><div class="codeline">elements and showing some set operations. We also cover the computation of</div><div class="clear"></div>
<div class="linenb">1122</div><div class="codeline">fuzzy entropy as a Bernoulli random variable.</div><div class="clear"></div>
<div class="linenb">1123</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1124</div><div class="codeline">A fuzzy set is defined as a set with probabilistic set membership. Therefore, a</div><div class="clear"></div>
<div class="linenb">1125</div><div class="codeline">fuzzy set is denoted as $A = \{ (x, \mu_A(x)), x \in \Omega\}$,  where $x$ is</div><div class="clear"></div>
<div class="linenb">1126</div><div class="codeline">an element of set $A$ with a probability $\mu_A(x)$ such that $0 \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [led, let, leg, Lee, Len, Lev, Lew, seq, Leo, liq, EQ, LED, Le, Lea, Les, Ley, le, lea, lee, lei, lez, le q] (44259) [lt:en:MORFOLOGIK_RULE_EN_GB]">leq</span> \<span class="highlight" title="In standard English, a word does not contain an underscore character (_). Make sure that the word 'mu _ A' is correct. (44264) [lt:en:WORD_CONTAINS_UNDERSCORE]"></span>mu_A</div><div class="clear"></div>
<div class="linenb">1127</div><div class="codeline">\<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [led, let, leg, Lee, Len, Lev, Lew, seq, Leo, liq, EQ, LED, Le, Lea, Les, Ley, le, lea, lee, lei, lez, le q] (44270) [lt:en:MORFOLOGIK_RULE_EN_GB]">leq</span> 1$, and $\<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Omega, Omegas] (44277) [lt:en:MORFOLOGIK_RULE_EN_GB]">Omega$</span> is the universal set.</div><div class="clear"></div>
<div class="linenb">1128</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1129</div><div class="codeline">If our universe $\Omega$ is finite and of cardinality $n$, our notion of</div><div class="clear"></div>
<div class="linenb">1130</div><div class="codeline">probabilistic set membership is constrained to a maximum $n$ values. Therefore,</div><div class="clear"></div>
<div class="linenb">1131</div><div class="codeline">each fuzzy set $A$ can be represented as an $n$-tuple, with each member of the</div><div class="clear"></div>
<div class="linenb">1132</div><div class="codeline">tuple $A[i]$ being the probability of the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [with, it, its, ITU, ITT, itch, pith, nth, kith, ITV, 0th, 1th, 2th, 3th, 4th, 5th, 6th, 7th, 8th, 9th, Ito, Sith, Th, ath, ish, ite, it h] (44561) [lt:en:MORFOLOGIK_RULE_EN_GB]">$i$th</span> member of $\Omega$. We can</div><div class="clear"></div>
<div class="linenb">1133</div><div class="codeline">rewrite a fuzzy set as an $n$-tuple <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [a, MA, ma, pa, ta, da, A, AA, BA, Ba, CA, Ca, Ga, IA, La, Na, Oa, QA, Qa, Ra, SA, Sa, Ta, WA, ba, ca, ea, fa, ha, ka, la, mA, na, ya, à] (44619) [lt:en:MORFOLOGIK_RULE_EN_GB]">$A</span>' = <span class="highlight" title="Don't put a space after the opening parenthesis. Suggestions: [(] (44625) [lt:en:COMMA_PARENTHESIS_WHITESPACE]">( \mu_{</span>A<span class="highlight" title="Unpaired symbol: ''' seems to be missing (44628) [lt:en:EN_UNPAIRED_BRACKETS]">'}</span>(x), \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [for all, fora ll] (44635) [lt:en:MORFOLOGIK_RULE_EN_GB]">forall</span> x \in \Omega</div><div class="clear"></div>
<div class="linenb">1134</div><div class="codeline">)<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [A, MA, Ma, Pa, Ta, Da, AA, BA, Ba, CA, Ca, Ga, IA, La, Na, Oa, QA, Qa, Ra, SA, Sa, WA, X, XL, XP, Xi, Xu, Ea, Fa, Ha, Ka, mA, Xv, Xx, Ya, À, X A] (44656) [lt:en:MORFOLOGIK_RULE_EN_GB]">$, such that $\card{A</span><span class="highlight" title="Unpaired symbol: ''' seems to be missing (44658) [lt:en:EN_UNPAIRED_BRACKETS]">'}</span> = \card \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Omega, Omegas] (44669) [lt:en:MORFOLOGIK_RULE_EN_GB]">Omega$. In this representation, $A</span>[i]$ is the</div><div class="clear"></div>
<div class="linenb">1135</div><div class="codeline">probability of the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [with, it, its, ITU, ITT, itch, pith, nth, kith, ITV, 0th, 1th, 2th, 3th, 4th, 5th, 6th, 7th, 8th, 9th, Ito, Sith, Th, ath, ish, ite, it h] (44707) [lt:en:MORFOLOGIK_RULE_EN_GB]">$i$th</span> member of the tuple $A$. We define some common set</div><div class="clear"></div>
<div class="linenb">1136</div><div class="codeline">operations in terms of this representation as follows.</div><div class="clear"></div>
<div class="linenb">1137</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1138</div><div class="codeline"><span class="keyword2">\begin{align*}</span> &amp;(A \cap B)[i] \equiv  A[i] \times B[i] \quad</div><div class="clear"></div>
<div class="linenb">1139</div><div class="codeline">\text{(set intersection)} \\ &amp;(A \cup B)[i] \equiv  A[i] + B[i]  - A[i] \times</div><div class="clear"></div>
<div class="linenb">1140</div><div class="codeline">B[i] \, \text{(set union)}\\ &amp;(A \sqcup B)[i] \equiv  \max(1, \min(0, A[i] +</div><div class="clear"></div>
<div class="linenb">1141</div><div class="codeline">B[i])) \, \text{(disjoint union)}\\ &amp;(\lnot A)[i] \equiv 1 - A[i] \quad</div><div class="clear"></div>
<div class="linenb">1142</div><div class="codeline">\text{(complement)}\\ &amp;(A \setminus B)[i] \equiv A[i]  - \min(A[i], B[i]) \quad</div><div class="clear"></div>
<div class="linenb">1143</div><div class="codeline">\text{(set difference)} \\ &amp;(A \subseteq B) \equiv \forall x \in \Omega:</div><div class="clear"></div>
<div class="linenb">1144</div><div class="codeline">\mu_A(x) \leq \mu_B(x) \, \text{(set inclusion)}\\ &amp;\card A \equiv \sum_{i \in</div><div class="clear"></div>
<div class="linenb">1145</div><div class="codeline">\Omega} \mu_A (i) \quad \text{(cardinality)} \\</div><div class="clear"></div>
<div class="linenb">1146</div><div class="codeline">    <span class="comment">% &amp;H(A) \equiv \sum_i -A[i] \ln(A[i]) - (1 - A[i]) \ln(1 - A[i]) \;</span></div><div class="clear"></div>
<div class="linenb">1147</div><div class="codeline">    <span class="comment">% \text{(entropy)}</span></div><div class="clear"></div>
<div class="linenb">1148</div><div class="codeline"><span class="keyword2">\end{align*}</span></div><div class="clear"></div>
<div class="linenb">1149</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1150</div><div class="codeline">The notion of entropy in fuzzy sets is an extrapolation of Shannon entropy from</div><div class="clear"></div>
<div class="linenb">1151</div><div class="codeline">a single variable on the entire set. Formally, the fuzzy entropy of a set $S$</div><div class="clear"></div>
<div class="linenb">1152</div><div class="codeline">is a measure of the uncertainty of the elements belonging to the set. The</div><div class="clear"></div>
<div class="linenb">1153</div><div class="codeline">possibility of a member $x$ belonging to the set $S$ is a random variable</div><div class="clear"></div>
<div class="linenb">1154</div><div class="codeline">$X_i^S$ which is $true$ with probability $(p_i^S)$ and $false$ with probability</div><div class="clear"></div>
<div class="linenb">1155</div><div class="codeline">$(1-p^S_i)$. Therefore, $X_i^S$ is a Bernoulli random variable. In order to</div><div class="clear"></div>
<div class="linenb">1156</div><div class="codeline">compute the entropy of a fuzzy set, we sum the entropy values of each $X_i^S$:</div><div class="clear"></div>
<div class="linenb">1157</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1158</div><div class="codeline"><span class="keyword2">\begin{align*}</span> H(A) &amp;\equiv \sum_i H(X^A_i) \\ &amp;\equiv \sum_i</div><div class="clear"></div>
<div class="linenb">1159</div><div class="codeline">-p_i^A \ln p_i^A - (1 - p_i^A) \ln (1 - p_i^A) \\ &amp;\equiv  \sum_i -A[i] \ln</div><div class="clear"></div>
<div class="linenb">1160</div><div class="codeline">A[i] - (1 - A[i]) \ln (1 - A[i]) <span class="keyword2">\end{align*}</span></div><div class="clear"></div>
<div class="linenb">1161</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1162</div><div class="codeline">This formulation will be useful in <span class="highlight-sh" title="Use a capital letter when referring to a specific section: 'Section X' [sh:secmag]">section \ref</span>{ssec: similarity math} where we</div><div class="clear"></div>
<div class="linenb">1163</div><div class="codeline">discuss two asymmetric measures of similarity, cross-entropy and K-L</div><div class="clear"></div>
<div class="linenb">1164</div><div class="codeline">divergence, which can be seen as a natural extension of this formulation of</div><div class="clear"></div>
<div class="linenb">1165</div><div class="codeline">fuzzy entropy.</div><div class="clear"></div>
<div class="linenb">1166</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1167</div><div class="codeline"><span class="keyword1">\section</span>{Representation and <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Operations., Operations!, Operations?, Operations:, Operations,, Operations;] (45548) [lt:en:PUNCTUATION_PARAGRAPH_END]">Operations}</span> <span class="keyword1">\label</span>{sec: meat of the paper}</div><div class="clear"></div>
<div class="linenb">1168</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1169</div><div class="codeline">In this section, we use the mathematical formulation above to reinterpret word</div><div class="clear"></div>
<div class="linenb">1170</div><div class="codeline">embeddings. We first show how these word representations are created, then</div><div class="clear"></div>
<div class="linenb">1171</div><div class="codeline">detail the interpretation of each of the set operations with some examples. We</div><div class="clear"></div>
<div class="linenb">1172</div><div class="codeline">also look into some measures of similarity and their formulation in this</div><div class="clear"></div>
<div class="linenb">1173</div><div class="codeline">framework. All examples in this section have been taken using the Google News</div><div class="clear"></div>
<div class="linenb">1174</div><div class="codeline">Negative 300</div><div class="clear"></div>
<div class="linenb">1175</div><div class="codeline">vectors\footnote{\url{https://code.google.com/archive/p/word2vec/}}. We used</div><div class="clear"></div>
<div class="linenb">1176</div><div class="codeline">these gold standard <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [vectors., vectors!, vectors?, vectors:, vectors,, vectors;] (45995) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>vectors</div><div class="clear"></div>
<div class="linenb">1177</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1178</div><div class="codeline"><span class="keyword1">\subsection</span>{Constructing the Tuple of Feature Probabilities} <span class="keyword1">\label</span>{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [sec, spec, SSC, SSE, s sec] (46052) [lt:en:MORFOLOGIK_RULE_EN_GB]">ssec</span>:</div><div class="clear"></div>
<div class="linenb">1179</div><div class="codeline">constructing}</div><div class="clear"></div>
<div class="linenb">1180</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1181</div><div class="codeline">We start by converting the skip-gram negative sample word vectors into a tuple</div><div class="clear"></div>
<div class="linenb">1182</div><div class="codeline">of feature probabilities. In order to construct a tuple of features</div><div class="clear"></div>
<div class="linenb">1183</div><div class="codeline">representation in $\mathbb{R}^n$, we consider that the projection of a vector</div><div class="clear"></div>
<div class="linenb">1184</div><div class="codeline">$\vec v$ onto a dimension <span class="highlight" title="Is this the personal pronoun 'I'? It is spelled uppercase.. Suggestions: [I] (46303) [lt:en:I_LOWERCASE]">$i$</span> is a function of its probability of possessing</div><div class="clear"></div>
<div class="linenb">1185</div><div class="codeline">the feature associated with that dimension.  We compute the conversion from a</div><div class="clear"></div>
<div class="linenb">1186</div><div class="codeline">word vector to a tuple of features by first exponentiating the projection of</div><div class="clear"></div>
<div class="linenb">1187</div><div class="codeline">each vector along each direction, then averaging it over that feature for the</div><div class="clear"></div>
<div class="linenb">1188</div><div class="codeline">entire vocabulary size, <span class="highlight-sh" title="Use a backslash or comma after the second period; otherwise LaTeX will think it is a full stop ending a sentence. [sh:011]">i.e. </span>column-wise.</div><div class="clear"></div>
<div class="linenb">1189</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1190</div><div class="codeline"><span class="keyword2">\begin{align*}</span> &amp; v_{exp}[i] \equiv \exp \vec v[i] \\ &amp; \hat v[i]</div><div class="clear"></div>
<div class="linenb">1191</div><div class="codeline">\equiv \frac{v_{\text{exp}}[i]}{\sum_{w \in \text{VOCAB}} </div><div class="clear"></div>
<div class="linenb">1192</div><div class="codeline">w_{\text{exp}}[i]} <span class="keyword2">\end{align*}</span></div><div class="clear"></div>
<div class="linenb">1193</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1194</div><div class="codeline">This normalization then produces a tuple of probabilities associated with each</div><div class="clear"></div>
<div class="linenb">1195</div><div class="codeline">feature (corresponding to the dimensions of $\mathbb{R}^n$).</div><div class="clear"></div>
<div class="linenb">1196</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1197</div><div class="codeline">In line with our discussion from \ref{sec: math}, this tuple of probabilities</div><div class="clear"></div>
<div class="linenb">1198</div><div class="codeline">is akin to our representation of a fuzzy set. Let us consider the word $v$, and</div><div class="clear"></div>
<div class="linenb">1199</div><div class="codeline">its corresponding $n$-dimensional word vector $\vec v$. The projection of $\<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [IEC, Dec, sec, EEC, vet, veg, vex, Vic, Bec, EC, VLC, Ven, ve, ve c] (46966) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>vec</div><div class="clear"></div>
<div class="linenb">1200</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [via, axis, exit, vein, vain, void, VIP, VoIP, veil, vie, viz, Vail, viii, vim, Vic, Axis, EXIF, VI, XIX, Xi, axil, ixia, vi, vid, vig, vii, vis, vril, xi, xii, xiv, xix, xxi, xxii, xxiv, xxix] (46970) [lt:en:MORFOLOGIK_RULE_EN_GB]">v$ on a dimension $i$</span> normalized (as shown above) to be interpreted as</div><div class="clear"></div>
<div class="linenb">1201</div><div class="codeline"><span class="keyword1">\textit</span>{if this dimension <span class="highlight" title="Is this the personal pronoun 'I'? It is spelled uppercase.. Suggestions: [I] (47042) [lt:en:I_LOWERCASE]">$i$</span> were a property, what is probability that $v$</div><div class="clear"></div>
<div class="linenb">1202</div><div class="codeline">would possess that property?}</div><div class="clear"></div>
<div class="linenb">1203</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1204</div><div class="codeline">In word2vec, words are distributed in a vector space of a particular</div><div class="clear"></div>
<div class="linenb">1205</div><div class="codeline">dimensionality. Our representation attempts to provide some insight into how</div><div class="clear"></div>
<div class="linenb">1206</div><div class="codeline">the arrangement of vectors provides insight into the properties they share. We</div><div class="clear"></div>
<div class="linenb">1207</div><div class="codeline">do so by considering a function of the projection of a word vector onto a</div><div class="clear"></div>
<div class="linenb">1208</div><div class="codeline">dimension and interpreting as a probability. This allows us an avenue to</div><div class="clear"></div>
<div class="linenb">1209</div><div class="codeline">explore the relation between words in relation to the properties they share. It</div><div class="clear"></div>
<div class="linenb">1210</div><div class="codeline">also allows us <span class="highlight" title="Please check whether 'to' is missing here (to allow to do something).. Suggestions: [to access] (47585) [lt:en:ALLOW_TO_DO]">access</span> to the entire arsenal of set operations, which are</div><div class="clear"></div>
<div class="linenb">1211</div><div class="codeline">described below in <span class="highlight-sh" title="Use a capital letter when referring to a specific section: 'Section X' [sh:secmag]">section \ref</span>{ssec: set operations}.</div><div class="clear"></div>
<div class="linenb">1212</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1213</div><div class="codeline"><span class="keyword1">\subsection</span>{Operations on Feature Probabilities} <span class="keyword1">\label</span>{ssec: set operations}</div><div class="clear"></div>
<div class="linenb">1214</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1215</div><div class="codeline">Now that word vectors can be represented as tuples of feature probabilities, we</div><div class="clear"></div>
<div class="linenb">1216</div><div class="codeline">can apply fuzzy set theoretic operations in order to ascertain the veracity of</div><div class="clear"></div>
<div class="linenb">1217</div><div class="codeline">the implementation. We show qualitative examples of the set operations in this</div><div class="clear"></div>
<div class="linenb">1218</div><div class="codeline">subsection, and the information they capture. Throughout this subsection, we</div><div class="clear"></div>
<div class="linenb">1219</div><div class="codeline">follow the following notation: For any two words $w_1, w_2 \in \text{VOCAB}$,</div><div class="clear"></div>
<div class="linenb">1220</div><div class="codeline">$\hat w_1$ and $\hat w_2$ represents those words using our representation,</div><div class="clear"></div>
<div class="linenb">1221</div><div class="codeline">while $\vec w_1$ and $\vec w_2$ are the word2vec vectors of those words.</div><div class="clear"></div>
<div class="linenb">1222</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1223</div><div class="codeline">\<span class="highlight-sh" title="A heading of level n should not be followed by a heading of level n+2 or more. [sh:secskip]">paragraph</span>{Feature Union, Intersection and Difference} In <span class="highlight-sh" title="Use a capital letter when referring to a specific section: 'Section X' [sh:secmag]">section \ref</span>{sec:</div><div class="clear"></div>
<div class="linenb">1224</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [match, path, mate, myth, oath, bath, maths, hath, mat, mats, moth, Mach, Meath, mash, lath, matt, Bath, Kath, Mata, Rath, Wath, ath, mah, maty, meth, m ath, mat h] (48251) [lt:en:MORFOLOGIK_RULE_EN_GB]">math}</span>, we showed the formulation of fuzzy set operations, assuming a finite</div><div class="clear"></div>
<div class="linenb">1225</div><div class="codeline">universe of elements. As we saw in <span class="highlight-sh" title="Use a capital letter when referring to a specific section: 'Section X' [sh:secmag]">section \ref</span>{ssec: constructing},</div><div class="clear"></div>
<div class="linenb">1226</div><div class="codeline">considering each dimension as a feature allows us to reinterpret word vectors</div><div class="clear"></div>
<div class="linenb">1227</div><div class="codeline">as tuples of feature probabilities. Therefore, we can use the fuzzy set</div><div class="clear"></div>
<div class="linenb">1228</div><div class="codeline">theoretic operations on this reinterpretation of fuzzy sets. For convenience,</div><div class="clear"></div>
<div class="linenb">1229</div><div class="codeline">these operations have been called feature union, intersection and difference.</div><div class="clear"></div>
<div class="linenb">1230</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1231</div><div class="codeline">Intuitively, the feature intersection of words $\hat w_1$ and $\hat w_2$ should</div><div class="clear"></div>
<div class="linenb">1232</div><div class="codeline">give us that word $\hat w_{1 \cap 2}$ which has the features common between the</div><div class="clear"></div>
<div class="linenb">1233</div><div class="codeline">two words; an example of which is given in <span class="highlight-sh" title="Use a capital letter when referring to a specific table: 'Table X' [sh:tabmag]">table \ref</span>{tab: union}. Similarly,</div><div class="clear"></div>
<div class="linenb">1234</div><div class="codeline">the feature union $\hat w_{1 \cup 2} \simeq \hat w_1 \cup \hat w_2$ which has</div><div class="clear"></div>
<div class="linenb">1235</div><div class="codeline">the properties of both the words, normalized for those properties which are</div><div class="clear"></div>
<div class="linenb">1236</div><div class="codeline">common between the two, and feature difference $\hat w_{1 \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [set minus] (49030) [lt:en:MORFOLOGIK_RULE_EN_GB]">setminus</span> 2} \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [some, time, same, side, size, times, site, sides, sites, aimed, sized, Simon, sided, sizes, lime, sited, timed, sine, sire, sired, timer, Simeon, dime, mime, seq, siren, sixes, slime, SIMD, Simms, dimer, limes, sires, Simla, Timex, dimes, mimed, mimes, simmer, sines, sinew, aimer, rimes, slimes, mimeo, limed, limey, simon, sixer, simper, mimer, Himel, SIM, SIMs, Semer, Side, Simi, Simmel, Siméon, Sumer, Vimeo, rime, semen] (49042) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>simeq</div><div class="clear"></div>
<div class="linenb">1237</div><div class="codeline">\hat w_1 \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [set minus] (49058) [lt:en:MORFOLOGIK_RULE_EN_GB]">setminus</span> \hat w_2$ is that word which is similar to $w_<span class="highlight" title="The currency mark is usually put at the beginning of the number: '$1'.. Suggestions: [$1] (49078) [lt:en:CURRENCY]">1$</span> without the</div><div class="clear"></div>
<div class="linenb">1238</div><div class="codeline">features of $w_2$. Examples of feature intersection and feature difference are</div><div class="clear"></div>
<div class="linenb">1239</div><div class="codeline">shown in <span class="highlight-sh" title="Use a capital letter when referring to a specific table: 'Table X' [sh:tabmag]">table \ref</span>{tab: intersection} and \ref{tab: difference} respectively.</div><div class="clear"></div>
<div class="linenb">1240</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1241</div><div class="codeline">While feature union does not seem to have a word2vec analogue, we consider that</div><div class="clear"></div>
<div class="linenb">1242</div><div class="codeline">feature intersection is analogous to vector addition, and feature difference as</div><div class="clear"></div>
<div class="linenb">1243</div><div class="codeline">analogous to vector difference.</div><div class="clear"></div>
<div class="linenb">1244</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1245</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1246</div><div class="codeline"><span class="keyword2">\begin{table}</span></div><div class="clear"></div>
<div class="linenb">1247</div><div class="codeline">  \centering</div><div class="clear"></div>
<div class="linenb">1248</div><div class="codeline">  {\scriptsize</div><div class="clear"></div>
<div class="linenb">1249</div><div class="codeline">  <span class="keyword2">\begin{tabular}</span>{l l l l l}</div><div class="clear"></div>
<div class="linenb">1250</div><div class="codeline">      $\hat R$    &amp; $\vec R$ &amp; $\hat V$       &amp; $\vec V$  &amp; $\hat R \cup \hat V$  \\</div><div class="clear"></div>
<div class="linenb">1251</div><div class="codeline">      risen       &amp; cashew   &amp; wavelengths    &amp; yellowish &amp; flower                \\</div><div class="clear"></div>
<div class="linenb">1252</div><div class="codeline">      capita      &amp; risen    &amp; ultraviolet    &amp; whitish   &amp; red                   \\</div><div class="clear"></div>
<div class="linenb">1253</div><div class="codeline">      peaked      &amp; soared   &amp; purple         &amp; aquamarine&amp; stripes               \\</div><div class="clear"></div>
<div class="linenb">1254</div><div class="codeline">      declined    &amp; acuff    &amp; infrared       &amp; roans     &amp; flowers               \\</div><div class="clear"></div>
<div class="linenb">1255</div><div class="codeline">      increased   &amp; rafters  &amp; yellowish      &amp; bluish    &amp; green                 \\</div><div class="clear"></div>
<div class="linenb">1256</div><div class="codeline">      rises       &amp; equalled &amp; pigment        &amp; greenish  &amp; garlands              \\</div><div class="clear"></div>
<div class="linenb">1257</div><div class="codeline">  <span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">1258</div><div class="codeline">  }</div><div class="clear"></div>
<div class="linenb">1259</div><div class="codeline">  <span class="keyword1">\caption</span>{An example of feature union. \texttt{Rose} is represented by $R$</div><div class="clear"></div>
<div class="linenb">1260</div><div class="codeline">  and \texttt{Violet} by $V$. We see here that while the word rose and violet</div><div class="clear"></div>
<div class="linenb">1261</div><div class="codeline">  have different meanings and senses, the union $R \cup V$ captures the sense</div><div class="clear"></div>
<div class="linenb">1262</div><div class="codeline">  of the flower as well as of colours, which are the senses common to these</div><div class="clear"></div>
<div class="linenb">1263</div><div class="codeline">  two words. We list words closest to the given word in the table. Closeness</div><div class="clear"></div>
<div class="linenb">1264</div><div class="codeline">  measured by cosine similarity for word2vec and cross-entropy-similarity for</div><div class="clear"></div>
<div class="linenb">1265</div><div class="codeline">  our vectors.}</div><div class="clear"></div>
<div class="linenb">1266</div><div class="codeline">  <span class="keyword1">\label</span>{tab: union}</div><div class="clear"></div>
<div class="linenb">1267</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">1268</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1269</div><div class="codeline"><span class="keyword2">\begin{table}</span>[t]</div><div class="clear"></div>
<div class="linenb">1270</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">1271</div><div class="codeline">    {\small</div><div class="clear"></div>
<div class="linenb">1272</div><div class="codeline">    <span class="keyword2">\begin{tabular}</span>{l l l}</div><div class="clear"></div>
<div class="linenb">1273</div><div class="codeline">        $\hat C$        &amp; $\hat P$          &amp; $\hat C \cap \hat P$      \\</div><div class="clear"></div>
<div class="linenb">1274</div><div class="codeline">        hardware        &amp; vested            &amp; cpu                       \\</div><div class="clear"></div>
<div class="linenb">1275</div><div class="codeline">        graphics        &amp; purchasing        &amp; hardware                  \\</div><div class="clear"></div>
<div class="linenb">1276</div><div class="codeline">        multitasking    &amp; capita            &amp; powerpc                   \\</div><div class="clear"></div>
<div class="linenb">1277</div><div class="codeline">        console         &amp; exercise          &amp; machine                   \\</div><div class="clear"></div>
<div class="linenb">1278</div><div class="codeline">        firewire        &amp; parity            &amp; multitasking              \\</div><div class="clear"></div>
<div class="linenb">1279</div><div class="codeline">        mainframe       &amp; veto              &amp; microcode                 \\ \midrule</div><div class="clear"></div>
<div class="linenb">1280</div><div class="codeline">        $\vec C$        &amp; $\vec P$          &amp; $\vec C + \vec P$         \\</div><div class="clear"></div>
<div class="linenb">1281</div><div class="codeline">        bioses          &amp; centralize        &amp; expandability             \\</div><div class="clear"></div>
<div class="linenb">1282</div><div class="codeline">        scummvm         &amp; veto              &amp; writable                  \\</div><div class="clear"></div>
<div class="linenb">1283</div><div class="codeline">        hardware        &amp; decembrist        &amp; cpcs                      \\</div><div class="clear"></div>
<div class="linenb">1284</div><div class="codeline">        imovie          &amp; exercised         &amp; reconfigure               \\</div><div class="clear"></div>
<div class="linenb">1285</div><div class="codeline">        writable        &amp; redistribution    &amp; backplane                 \\</div><div class="clear"></div>
<div class="linenb">1286</div><div class="codeline">        console         &amp; devolving         &amp; oem</div><div class="clear"></div>
<div class="linenb">1287</div><div class="codeline">    <span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">1288</div><div class="codeline">    }</div><div class="clear"></div>
<div class="linenb">1289</div><div class="codeline">    <span class="keyword1">\caption</span>{An example of feature intersection with the possible word2vec</div><div class="clear"></div>
<div class="linenb">1290</div><div class="codeline">    analogue (vector addition). The word \texttt{computer} is represented by</div><div class="clear"></div>
<div class="linenb">1291</div><div class="codeline">    $C$ and \texttt{power} by $P$. Note that power is also a decent example of</div><div class="clear"></div>
<div class="linenb">1292</div><div class="codeline">    polysemy, and we see that in the context of computers, the connotations of</div><div class="clear"></div>
<div class="linenb">1293</div><div class="codeline">    hardware and the CPU are the most accessible. We list words closest to the</div><div class="clear"></div>
<div class="linenb">1294</div><div class="codeline">    given word in the table. Closeness measured by cosine similarity for</div><div class="clear"></div>
<div class="linenb">1295</div><div class="codeline">    word2vec and cross-entropy-similarity for our vectors.}</div><div class="clear"></div>
<div class="linenb">1296</div><div class="codeline">    <span class="keyword1">\label</span>{tab: intersection}</div><div class="clear"></div>
<div class="linenb">1297</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">1298</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1299</div><div class="codeline"><span class="keyword2">\begin{table}</span>[t]</div><div class="clear"></div>
<div class="linenb">1300</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">1301</div><div class="codeline">    {\small</div><div class="clear"></div>
<div class="linenb">1302</div><div class="codeline">    <span class="keyword2">\begin{tabular}</span>{l l l}</div><div class="clear"></div>
<div class="linenb">1303</div><div class="codeline">        $\hat F$    &amp; $\hat B $     &amp; $\hat F \setminus \hat B$    \\</div><div class="clear"></div>
<div class="linenb">1304</div><div class="codeline">        french      &amp; isles         &amp; communaut                    \\</div><div class="clear"></div>
<div class="linenb">1305</div><div class="codeline">        english     &amp; colonial      &amp; aise                         \\</div><div class="clear"></div>
<div class="linenb">1306</div><div class="codeline">        france      &amp; subcontinent  &amp; langue                       \\</div><div class="clear"></div>
<div class="linenb">1307</div><div class="codeline">        german      &amp; cinema        &amp; monet                        \\</div><div class="clear"></div>
<div class="linenb">1308</div><div class="codeline">        spanish     &amp; boer          &amp; dictionnaire                 \\</div><div class="clear"></div>
<div class="linenb">1309</div><div class="codeline">        british     &amp; canadians     &amp; gascon                       \\ \midrule</div><div class="clear"></div>
<div class="linenb">1310</div><div class="codeline">        $\vec F$    &amp; $\vec B$      &amp; $\vec F - \vec B$             \\</div><div class="clear"></div>
<div class="linenb">1311</div><div class="codeline">        french      &amp; scottish      &amp; ranjit                        \\</div><div class="clear"></div>
<div class="linenb">1312</div><div class="codeline">        english     &amp; american      &amp; privatised                    \\</div><div class="clear"></div>
<div class="linenb">1313</div><div class="codeline">        france      &amp; thatcherism   &amp; tardis                        \\</div><div class="clear"></div>
<div class="linenb">1314</div><div class="codeline">        german      &amp; netherlands   &amp; molloy                        \\</div><div class="clear"></div>
<div class="linenb">1315</div><div class="codeline">        spanish     &amp; hillier       &amp; isaacs                        \\</div><div class="clear"></div>
<div class="linenb">1316</div><div class="codeline">        british     &amp; cukcs         &amp; raj</div><div class="clear"></div>
<div class="linenb">1317</div><div class="codeline">    <span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">1318</div><div class="codeline">    }</div><div class="clear"></div>
<div class="linenb">1319</div><div class="codeline">    <span class="keyword1">\caption</span>{An example of feature difference, along with a possible word2vec</div><div class="clear"></div>
<div class="linenb">1320</div><div class="codeline">    analogue (vector difference). \texttt{French} is represented by $F$ and</div><div class="clear"></div>
<div class="linenb">1321</div><div class="codeline">    \texttt{British} by $B$. We see here that set difference capture french</div><div class="clear"></div>
<div class="linenb">1322</div><div class="codeline">    words from the dataset, while there does not seem to be any such</div><div class="clear"></div>
<div class="linenb">1323</div><div class="codeline">    correlation in the vector difference. We list words closest to the given</div><div class="clear"></div>
<div class="linenb">1324</div><div class="codeline">    word in the table. Closeness measured by cosine similarity for word2vec and</div><div class="clear"></div>
<div class="linenb">1325</div><div class="codeline">    cross-entropy-similarity for our vectors.}</div><div class="clear"></div>
<div class="linenb">1326</div><div class="codeline">    <span class="keyword1">\label</span>{tab: difference}</div><div class="clear"></div>
<div class="linenb">1327</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">1328</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1329</div><div class="codeline"><span class="keyword1">\paragraph</span>{<span class="highlight" title="This phrase is duplicated. You should probably leave only 'Feature Inclusion'.. Suggestions: [Feature Inclusion] (49403) [lt:en:PHRASE_REPETITION]">Feature Inclusion} Feature inclusion</span> is based on the subset relation</div><div class="clear"></div>
<div class="linenb">1330</div><div class="codeline">of fuzzy sets. We aim to capture feature inclusion by determining if there</div><div class="clear"></div>
<div class="linenb">1331</div><div class="codeline">exist two words $w_1$ and $w_2$ such that <span class="keyword1">\textit</span>{all} the feature</div><div class="clear"></div>
<div class="linenb">1332</div><div class="codeline">probabilities of $\hat w_1$ are less than that of $\hat w_2$, then $\hat w_2</div><div class="clear"></div>
<div class="linenb">1333</div><div class="codeline">\<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [subset, subsets, subsected, subsere] (49656) [lt:en:MORFOLOGIK_RULE_EN_GB]">subseteq</span> \hat w_<span class="highlight" title="The currency mark is usually put at the beginning of the number: '$1'.. Suggestions: [$1] (49672) [lt:en:CURRENCY]">1$</span>. We find that feature inclusion is closely linked to</div><div class="clear"></div>
<div class="linenb">1334</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [synonymy, toponymy, homonymy, hypogyny] (49728) [lt:en:MORFOLOGIK_RULE_EN_GB]">hyponymy</span>, which we will show in \ref{ssec: entailment}.</div><div class="clear"></div>
<div class="linenb">1335</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1336</div><div class="codeline"><span class="keyword1">\subsection</span>{Interpreting Entropy} <span class="keyword1">\label</span>{ssec: entropy math} For a word</div><div class="clear"></div>
<div class="linenb">1337</div><div class="codeline">represented using a tuple of feature probabilities, the notion of entropy is</div><div class="clear"></div>
<div class="linenb">1338</div><div class="codeline">strongly tied to the notion of certainty \citep{xuecheng1992entropy}, <span class="highlight-sh" title="Use a backslash or comma after the second period; otherwise LaTeX will think it is a full stop ending a sentence. [sh:011]">i.e. </span>with</div><div class="clear"></div>
<div class="linenb">1339</div><div class="codeline">what certainty does this word possess or not possess this set of features?</div><div class="clear"></div>
<div class="linenb">1340</div><div class="codeline">Formally, the fuzzy entropy of a set $S$ is a measure of the uncertainty of</div><div class="clear"></div>
<div class="linenb">1341</div><div class="codeline">elements belonging to the set. The possibility a member $x_i$ belonging to $S$</div><div class="clear"></div>
<div class="linenb">1342</div><div class="codeline">is a random variable $X^S_i$, which is \texttt{true} with probability $p^S_i$,</div><div class="clear"></div>
<div class="linenb">1343</div><div class="codeline">\texttt{false} with probability $(1 - p^S_i)$. Thus, $X^S_i$ is a Bernoulli</div><div class="clear"></div>
<div class="linenb">1344</div><div class="codeline">random variable. So, to measure the fuzzy entropy of a set, we add up the</div><div class="clear"></div>
<div class="linenb">1345</div><div class="codeline">entropy values of each of the $X^S_i$ \citep{mackay2003information}.</div><div class="clear"></div>
<div class="linenb">1346</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1347</div><div class="codeline">Intuitively, words with the highest entropy are those which have features which</div><div class="clear"></div>
<div class="linenb">1348</div><div class="codeline">are equally likely to belong to them and to their complement, <span class="highlight-sh" title="Use a backslash or comma after the second period; otherwise LaTeX will think it is a full stop ending a sentence. [sh:011]">i.e. </span>$\<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [for all, fora ll] (50520) [lt:en:MORFOLOGIK_RULE_EN_GB]">forall</span> i</div><div class="clear"></div>
<div class="linenb">1349</div><div class="codeline">\in \Omega, A[i] \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [some, time, same, side, size, times, site, sides, sites, aimed, sized, Simon, sided, sizes, lime, sited, timed, sine, sire, sired, timer, Simeon, dime, mime, seq, siren, sixes, slime, SIMD, Simms, dimer, limes, sires, Simla, Timex, dimes, mimed, mimes, simmer, sines, sinew, aimer, rimes, slimes, mimeo, limed, limey, simon, sixer, simper, mimer, Himel, SIM, SIMs, Semer, Side, Simi, Simmel, Siméon, Sumer, Vimeo, rime, semen] (50547) [lt:en:MORFOLOGIK_RULE_EN_GB]">simeq</span> 1 <span class="highlight" title="Consider using an m-dash if you do not want to join two words.. Suggestions: [—] (50555) [lt:en:DASH_RULE]">-</span> A[i]$. So words with high fuzzy entropy can occur</div><div class="clear"></div>
<div class="linenb">1350</div><div class="codeline">only in two scenarios: (1) The words occur with very low frequency so their</div><div class="clear"></div>
<div class="linenb">1351</div><div class="codeline">random initialization remained, or (2) The words occur around so <span class="highlight" title="Consider using 'many'.. Suggestions: [many] (50748) [lt:en:NUMEROUS_DIFFERENT]"></span>many different</div><div class="clear"></div>
<div class="linenb">1352</div><div class="codeline">word groups that their corresponding fuzzy sets have some probability of</div><div class="clear"></div>
<div class="linenb">1353</div><div class="codeline">possessing most of the features.</div><div class="clear"></div>
<div class="linenb">1354</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1355</div><div class="codeline">Therefore, our representation of words as tuples of features can be used to</div><div class="clear"></div>
<div class="linenb">1356</div><div class="codeline">isolate function words better than the more commonly considered notion of</div><div class="clear"></div>
<div class="linenb">1357</div><div class="codeline">simply using frequency, as it identifies the information theoretic distribution</div><div class="clear"></div>
<div class="linenb">1358</div><div class="codeline">of features based on the context the function word occurs in. Table \ref{tab:</div><div class="clear"></div>
<div class="linenb">1359</div><div class="codeline">function word list} provides the top 15 function words by entropy, and the</div><div class="clear"></div>
<div class="linenb">1360</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [correspondingly] (51247) [lt:en:MORFOLOGIK_RULE_EN_GB]">correspodingly</span> ranked words by frequency. We see that frequency is clearly not</div><div class="clear"></div>
<div class="linenb">1361</div><div class="codeline">a good enough measure to identify function words.</div><div class="clear"></div>
<div class="linenb">1362</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1363</div><div class="codeline"><span class="keyword2">\begin{table*}</span>[t]</div><div class="clear"></div>
<div class="linenb">1364</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">1365</div><div class="codeline">    <span class="keyword2">\begin{tabular}</span>{l r | l r | l r | l r | l r}</div><div class="clear"></div>
<div class="linenb">1366</div><div class="codeline">    and		&amp; the   &amp;   in		&amp;   one         &amp;   which	    &amp;   to          &amp;   however	&amp;   <span class="keyword1">\emph</span>{two}  &amp;   for	    &amp;   <span class="keyword1">\emph</span>{eight}  \\</div><div class="clear"></div>
<div class="linenb">1367</div><div class="codeline">    this    &amp; of    &amp;   of	    &amp;   in          &amp;   the		    &amp;   <span class="keyword1">\emph</span>{zero} &amp;   to		&amp;   is          &amp;   a	    &amp;   for \\</div><div class="clear"></div>
<div class="linenb">1368</div><div class="codeline">    as	    &amp; and   &amp;   only	&amp;   a           &amp;   also	    &amp;   <span class="keyword1">\emph</span>{nine} &amp;   it		&amp;   as          &amp;   but	    &amp;   <span class="keyword1">\emph</span>{s}</div><div class="clear"></div>
<div class="linenb">1369</div><div class="codeline">    <span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">1370</div><div class="codeline">    <span class="keyword1">\caption</span>{On the left: Top 15 words with highest entropy with frequency $\geq 100$ (note that all of them are function words). On the right: Top 15 words with the highest frequency. The non-function words have been emphasized for comparison.}</div><div class="clear"></div>
<div class="linenb">1371</div><div class="codeline">    <span class="keyword1">\label</span>{tab: function word list}</div><div class="clear"></div>
<div class="linenb">1372</div><div class="codeline"><span class="keyword2">\end{table*}</span></div><div class="clear"></div>
<div class="linenb">1373</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1374</div><div class="codeline"><span class="keyword1">\subsection</span>{Similarity Measures} <span class="keyword1">\label</span>{ssec: similarity math} One of the most</div><div class="clear"></div>
<div class="linenb">1375</div><div class="codeline">important notions in presenting a distributional word representation is its</div><div class="clear"></div>
<div class="linenb">1376</div><div class="codeline">ability to capture similarity \citep{van2006finding}. Since we use and modify</div><div class="clear"></div>
<div class="linenb">1377</div><div class="codeline">vector based word representations, we aim to preserve the <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (51608) [lt:en:EN_QUOTES]">"</span></span>distribution<span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart closing quote here: '”'.. Suggestions: [”] (51621) [lt:en:EN_QUOTES]">"</span></span> of the</div><div class="clear"></div>
<div class="linenb">1378</div><div class="codeline">vector embeddings, while providing a more robust interpretation of similarity</div><div class="clear"></div>
<div class="linenb">1379</div><div class="codeline">measures. With respect to similarity, we make two strong claims:</div><div class="clear"></div>
<div class="linenb">1380</div><div class="codeline"><span class="keyword2">\begin{enumerate}</span> <span class="keyword1">\item</span> Representing words as a tuple of feature probabilities</div><div class="clear"></div>
<div class="linenb">1381</div><div class="codeline">lends us an inherent notion of similarity. Feature difference provides this</div><div class="clear"></div>
<div class="linenb">1382</div><div class="codeline">notion, as it estimates the difference between two words along each feature</div><div class="clear"></div>
<div class="linenb">1383</div><div class="codeline">probability.  <span class="keyword1">\item</span> Our representation allows for an easy adoption of known</div><div class="clear"></div>
<div class="linenb">1384</div><div class="codeline">similarity measures such as K-L divergence and cross-entropy.  <span class="keyword2">\end{enumerate}</span></div><div class="clear"></div>
<div class="linenb">1385</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1386</div><div class="codeline">Note that feature difference (based on fuzzy set difference), K-L divergence</div><div class="clear"></div>
<div class="linenb">1387</div><div class="codeline">and cross-entropy are all asymmetric measures of similarity. As</div><div class="clear"></div>
<div class="linenb">1388</div><div class="codeline">\citet{nematzadeh2017evaluating} points out, human similarity judgements are</div><div class="clear"></div>
<div class="linenb">1389</div><div class="codeline">inherently asymmetric in nature. We would like to point out that while most</div><div class="clear"></div>
<div class="linenb">1390</div><div class="codeline">methods of introducing asymmetric similarity measures in word2vec account for</div><div class="clear"></div>
<div class="linenb">1391</div><div class="codeline">both the focus and context vector \citet{asr2018querying} and provide the</div><div class="clear"></div>
<div class="linenb">1392</div><div class="codeline">asymmetry by querying on this combination of focus and context representations</div><div class="clear"></div>
<div class="linenb">1393</div><div class="codeline">of each word. Our representation, on the other hand, uses only the focus</div><div class="clear"></div>
<div class="linenb">1394</div><div class="codeline">representations (which are a part of the word representations used for</div><div class="clear"></div>
<div class="linenb">1395</div><div class="codeline">downstream task as well as any other intrinsic evaluation), and still provides</div><div class="clear"></div>
<div class="linenb">1396</div><div class="codeline">an innately asymmetric notion of similarity.</div><div class="clear"></div>
<div class="linenb">1397</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1398</div><div class="codeline">\<span class="highlight-sh" title="A heading of level n should not be followed by a heading of level n+2 or more. [sh:secskip]">paragraph</span>{K-L Divergence} From a fuzzy set perspective, we measure similarity</div><div class="clear"></div>
<div class="linenb">1399</div><div class="codeline">as an overlap of features. For this purpose, we exploit the notion of fuzzy</div><div class="clear"></div>
<div class="linenb">1400</div><div class="codeline">information theory by comparing how close the probability distributions of the</div><div class="clear"></div>
<div class="linenb">1401</div><div class="codeline">similar words are using a standard measure, Kullback-Leibler (K-L) divergence.</div><div class="clear"></div>
<div class="linenb">1402</div><div class="codeline">K-L divergence is an asymmetric measure of similarity.</div><div class="clear"></div>
<div class="linenb">1403</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1404</div><div class="codeline">The K-L divergence of a distribution $P$ from another distribution $Q$ is</div><div class="clear"></div>
<div class="linenb">1405</div><div class="codeline">defined in terms of loss of compression. Given data $d$ which follows</div><div class="clear"></div>
<div class="linenb">1406</div><div class="codeline">distribution $P$, the extra bits need to store it under the false assumption</div><div class="clear"></div>
<div class="linenb">1407</div><div class="codeline">that the data $d$ follows distribution $Q$ is the K-L divergence between the</div><div class="clear"></div>
<div class="linenb">1408</div><div class="codeline">distributions $P$ and $Q$. In the fuzzy case, we can compute the KL divergence</div><div class="clear"></div>
<div class="linenb">1409</div><div class="codeline">as:</div><div class="clear"></div>
<div class="linenb">1410</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1411</div><div class="codeline"><span class="keyword2">\begin{equation*}</span></div><div class="clear"></div>
<div class="linenb">1412</div><div class="codeline">     \infdiv{S}{T} \equiv \infdiv[\bigg]{X^S_i}{X^T_i} =  \sum_i p^S_i \log \left( p^S_i / p^T_i \right)</div><div class="clear"></div>
<div class="linenb">1413</div><div class="codeline"><span class="keyword2">\end{equation*}</span></div><div class="clear"></div>
<div class="linenb">1414</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1415</div><div class="codeline"><span class="keyword2">\begin{table}</span>[]</div><div class="clear"></div>
<div class="linenb">1416</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">1417</div><div class="codeline">    <span class="keyword2">\begin{tabular}</span>{clr}</div><div class="clear"></div>
<div class="linenb">1418</div><div class="codeline">        \multirow{2}{*}{Example 1} &amp; $\infdiv{ganges}{delta}$ &amp; $6.3105$  \\</div><div class="clear"></div>
<div class="linenb">1419</div><div class="codeline">                                   &amp; $\infdiv{delta}{ganges}$ &amp; $6.3040$  \\</div><div class="clear"></div>
<div class="linenb">1420</div><div class="codeline">        \multirow{2}{*}{Example 2} &amp; $\infdiv{north \cap korea}{china}$ &amp; $1.02923$ \\</div><div class="clear"></div>
<div class="linenb">1421</div><div class="codeline">                                   &amp; $\infdiv{china}{north \cap korea}$ &amp; $10.60665$</div><div class="clear"></div>
<div class="linenb">1422</div><div class="codeline">    <span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">1423</div><div class="codeline">    <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Examples of KL-divergence as an asymmetric measure of similarity. Lower is closer. We see here that the evaluation of North Korea as a concept being closer to China than vice versa can be observed by the use of K-L Divergence on column-wise normalization.1</span>}</div><div class="clear"></div>
<div class="linenb">1424</div><div class="codeline">    <span class="keyword1">\label</span>{tab: k-l divergence}</div><div class="clear"></div>
<div class="linenb">1425</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">1426</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1427</div><div class="codeline">We see in <span class="highlight-sh" title="Use a capital letter when referring to a specific table: 'Table X' [sh:tabmag]">table \ref</span>{tab: k-l divergence} some qualitative examples of how K-L</div><div class="clear"></div>
<div class="linenb">1428</div><div class="codeline">divergence shows the relation between two words (or phrases when composed using</div><div class="clear"></div>
<div class="linenb">1429</div><div class="codeline">feature intersection as in the case of \texttt{north <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Korea, chorea, Korean, chores, chore, choreas, chored] (53799) [lt:en:MORFOLOGIK_RULE_EN_GB]">korea}</span>). We exemplify</div><div class="clear"></div>
<div class="linenb">1430</div><div class="codeline">\citet{nematzadeh2017evaluating}'s human annotator judgement of the distance</div><div class="clear"></div>
<div class="linenb">1431</div><div class="codeline">between China and North Korea, where human annotators considered “North Korea”</div><div class="clear"></div>
<div class="linenb">1432</div><div class="codeline">to be very similar to “China,” while the reverse relationship was rated as</div><div class="clear"></div>
<div class="linenb">1433</div><div class="codeline">significantly less strong <span class="highlight" title="Unpaired symbol: ')' seems to be missing (54069) [lt:en:EN_UNPAIRED_BRACKETS]">(</span>“China” is not very similar to <span class="highlight" title="There should be a space after a closing quote.. Suggestions: [” North] (54101) [lt:en:NO_SPACE_CLOSING_QUOTE]">”North</span> Korea<span class="highlight" title="Unpaired symbol: '“' seems to be missing (54113) [lt:en:EN_UNPAIRED_BRACKETS]">”</span>).</div><div class="clear"></div>
<div class="linenb">1434</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1435</div><div class="codeline"><span class="keyword1">\paragraph</span>{Cross Entropy} We also calculate the cross entropy between two</div><div class="clear"></div>
<div class="linenb">1436</div><div class="codeline">words, as it can be used to determine the entropy associated with the</div><div class="clear"></div>
<div class="linenb">1437</div><div class="codeline">similarity between two words. Ideally, by determining the <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (54308) [lt:en:EN_QUOTES]">"</span></span>spread<span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart closing quote here: '”'.. Suggestions: [”] (54315) [lt:en:EN_QUOTES]">"</span></span> of the</div><div class="clear"></div>
<div class="linenb">1438</div><div class="codeline">similarity of features between two words, we can determine the features that</div><div class="clear"></div>
<div class="linenb">1439</div><div class="codeline">allow two words to be similar, allowing a more interpretable notion of</div><div class="clear"></div>
<div class="linenb">1440</div><div class="codeline">feature-wise relation.</div><div class="clear"></div>
<div class="linenb">1441</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1442</div><div class="codeline">The cross-entropy of two distributions $P$ and $Q$ is a sum of the entropy of</div><div class="clear"></div>
<div class="linenb">1443</div><div class="codeline">$P$ and the K-L divergence between $P$ and $Q$. In this sense, in captures both</div><div class="clear"></div>
<div class="linenb">1444</div><div class="codeline">the <span class="keyword1">\emph</span>{uncertainty in $P$}, <span class="highlight" title="Probable usage error. Use 'and' after 'both'.. Suggestions: [and] (54666) [lt:en:BOTH_AS_WELL_AS]">as well as</span> the distance from $P$ to $Q$, to give</div><div class="clear"></div>
<div class="linenb">1445</div><div class="codeline">us a general sense of the information theoretic difference between the concepts</div><div class="clear"></div>
<div class="linenb">1446</div><div class="codeline">of $P$ and $Q$. We use a generalized version of cross-entropy to fuzzy sets</div><div class="clear"></div>
<div class="linenb">1447</div><div class="codeline">\citep{li2015fuzzy}, which is:</div><div class="clear"></div>
<div class="linenb">1448</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1449</div><div class="codeline"><span class="keyword2">\begin{equation*}</span></div><div class="clear"></div>
<div class="linenb">1450</div><div class="codeline">   H(S, T) \equiv \sum_i H(X^S_i) + \infdiv{X^S_i}{X^T_i}</div><div class="clear"></div>
<div class="linenb">1451</div><div class="codeline"><span class="keyword2">\end{equation*}</span></div><div class="clear"></div>
<div class="linenb">1452</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1453</div><div class="codeline">Feature representations which on comparison provide high cross entropy imply a</div><div class="clear"></div>
<div class="linenb">1454</div><div class="codeline">more distributed feature space. Therefore, provided the right words to compute</div><div class="clear"></div>
<div class="linenb">1455</div><div class="codeline">cross entropy, it could be possible to extract various features common (or</div><div class="clear"></div>
<div class="linenb">1456</div><div class="codeline">associated) with a large group of words, lending some insight into how a single</div><div class="clear"></div>
<div class="linenb">1457</div><div class="codeline">surface form (and its representation) can capture the distribution associated</div><div class="clear"></div>
<div class="linenb">1458</div><div class="codeline">with different senses. Here, we use cross-entropy as a measure of polysemy, and</div><div class="clear"></div>
<div class="linenb">1459</div><div class="codeline">isolate polysemous words based on context. We provide an example of capturing</div><div class="clear"></div>
<div class="linenb">1460</div><div class="codeline">polysemy using composition by feature intersection in <span class="highlight-sh" title="Use a capital letter when referring to a specific table: 'Table X' [sh:tabmag]">table \ref</span>{tab:</div><div class="clear"></div>
<div class="linenb">1461</div><div class="codeline">polysemy}.</div><div class="clear"></div>
<div class="linenb">1462</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1463</div><div class="codeline">We can see that the words which are most similar to \texttt{noble} are a</div><div class="clear"></div>
<div class="linenb">1464</div><div class="codeline">combination of words from many senses, which provides some perspective into its</div><div class="clear"></div>
<div class="linenb">1465</div><div class="codeline">distribution,<span class="highlight" title="Don't put a space before the full stop. Suggestions: [.] (55662) [lt:en:COMMA_PARENTHESIS_WHITESPACE]"> .</span> Indeed, it has an entropy value of $6.2765$\footnote{For</div><div class="clear"></div>
<div class="linenb">1466</div><div class="codeline">reference, the word \texttt{the} has an entropy of $6.2934$<span class="highlight" title="Two consecutive dots. Suggestions: [.] (55758) [lt:en:DOUBLE_PUNCTUATION]"></span>.}.</div><div class="clear"></div>
<div class="linenb">1467</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1468</div><div class="codeline"> <span class="comment">% {\tiny</span></div><div class="clear"></div>
<div class="linenb">1469</div><div class="codeline"> <span class="keyword2">\begin{table}</span>[]</div><div class="clear"></div>
<div class="linenb">1470</div><div class="codeline">     \centering</div><div class="clear"></div>
<div class="linenb">1471</div><div class="codeline">     <span class="keyword2">\begin{tabular}</span>{l l l l l}</div><div class="clear"></div>
<div class="linenb">1472</div><div class="codeline">         $\hat N$    &amp; $\hat M$  &amp; $\hat G$  &amp; $\hat N \cap \hat M$  &amp; $\hat N \cap \hat G$      \\</div><div class="clear"></div>
<div class="linenb">1473</div><div class="codeline">         nobility    &amp; metal     &amp; bad       &amp; fusible               &amp; good                      \\</div><div class="clear"></div>
<div class="linenb">1474</div><div class="codeline">         isotope     &amp; fusible   &amp; manners   &amp; unreactive            &amp; dharma                    \\</div><div class="clear"></div>
<div class="linenb">1475</div><div class="codeline">         fujwara     &amp; ductility &amp; happiness &amp; metalloids            &amp; morals                    \\</div><div class="clear"></div>
<div class="linenb">1476</div><div class="codeline">         feudal      &amp; with      &amp; evil      &amp; ductility             &amp; virtue                    \\</div><div class="clear"></div>
<div class="linenb">1477</div><div class="codeline">         clan        &amp; alnico    &amp; excellent &amp; heavy                 &amp; righteous             \\ \midrule</div><div class="clear"></div>
<div class="linenb">1478</div><div class="codeline">         $\vec N$    &amp; $\vec M$  &amp; $\vec G$  &amp; $\vec N + \vec M$     &amp; $\vec N + \vec G$         \\</div><div class="clear"></div>
<div class="linenb">1479</div><div class="codeline">         noblest     &amp; trivalent &amp; bad       &amp; fusible               &amp; gracious                  \\</div><div class="clear"></div>
<div class="linenb">1480</div><div class="codeline">         auctoritas  &amp; carbides  &amp; natured   &amp; metals                &amp; virtuous                  \\</div><div class="clear"></div>
<div class="linenb">1481</div><div class="codeline">         abies       &amp; metallic  &amp; humoured  &amp; sulfides              &amp; believeth                 \\</div><div class="clear"></div>
<div class="linenb">1482</div><div class="codeline">         eightfold   &amp; corrodes  &amp; selfless  &amp; finntroll             &amp; savages                   \\</div><div class="clear"></div>
<div class="linenb">1483</div><div class="codeline">         vojt        &amp; alloying  &amp; gracious  &amp; rhodium               &amp; hedonist</div><div class="clear"></div>
<div class="linenb">1484</div><div class="codeline">     <span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">1485</div><div class="codeline">     <span class="keyword1">\caption</span>{Polysemy of the word \texttt{noble}, in the context of the words \texttt{good} and \texttt{metal}. \texttt{noble} is represented by $N$, \texttt{metal} by $M$ and \texttt{good} by $G$. We also provide the word2vec analogues of the same.}</div><div class="clear"></div>
<div class="linenb">1486</div><div class="codeline">     <span class="keyword1">\label</span>{tab: polysemy}</div><div class="clear"></div>
<div class="linenb">1487</div><div class="codeline"> <span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">1488</div><div class="codeline"> <span class="comment">% }</span></div><div class="clear"></div>
<div class="linenb">1489</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1490</div><div class="codeline"><span class="keyword1">\subsection</span>{Constructing <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Analogy., Analogy!, Analogy?, Analogy:, Analogy,, Analogy;] (55776) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>Analogy}</div><div class="clear"></div>
<div class="linenb">1491</div><div class="codeline"><span class="keyword1">\label</span>{ssec: analogy math}</div><div class="clear"></div>
<div class="linenb">1492</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1493</div><div class="codeline">Finally, we construct the notion of analogy in our representation of a word as</div><div class="clear"></div>
<div class="linenb">1494</div><div class="codeline">a tuple of features. Word analogy is usually represented as a problem where</div><div class="clear"></div>
<div class="linenb">1495</div><div class="codeline">given a pairing $(a : b)$, and a prior $x$, we are asked to compute an unknown</div><div class="clear"></div>
<div class="linenb">1496</div><div class="codeline">word $y_?$ such that  $a:b::x:y_?$. In the vector space model, analogy is</div><div class="clear"></div>
<div class="linenb">1497</div><div class="codeline">computed based on vector distances. We find that this training mechanism does</div><div class="clear"></div>
<div class="linenb">1498</div><div class="codeline">not have a consistent interpretation beyond evaluation. This is because</div><div class="clear"></div>
<div class="linenb">1499</div><div class="codeline">normalization of vectors <span class="keyword1">\emph</span>{performed only during inference, not during</div><div class="clear"></div>
<div class="linenb">1500</div><div class="codeline">training}. Thus, computing analogy in terms of vector distances provides little</div><div class="clear"></div>
<div class="linenb">1501</div><div class="codeline">insight into the distribution of vectors or to the notion of the length of the</div><div class="clear"></div>
<div class="linenb">1502</div><div class="codeline">word vectors, which seems to be essential to analogy computation using vector</div><div class="clear"></div>
<div class="linenb">1503</div><div class="codeline">operations</div><div class="clear"></div>
<div class="linenb">1504</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1505</div><div class="codeline">In using a fuzzy set theoretic representation, vector projections are</div><div class="clear"></div>
<div class="linenb">1506</div><div class="codeline">inherently normalized, making them feature dense. This allows us to compute</div><div class="clear"></div>
<div class="linenb">1507</div><div class="codeline">analogies much better in lower dimension spaces. We consider analogy to be an</div><div class="clear"></div>
<div class="linenb">1508</div><div class="codeline">operation involving union and set difference. Word analogy is computed as</div><div class="clear"></div>
<div class="linenb">1509</div><div class="codeline">follows:</div><div class="clear"></div>
<div class="linenb">1510</div><div class="codeline"><span class="keyword2">\begin{equation*}</span></div><div class="clear"></div>
<div class="linenb">1511</div><div class="codeline"><span class="keyword2">\begin{split}</span></div><div class="clear"></div>
<div class="linenb">1512</div><div class="codeline">    &amp;a : b :: x : y_? \\</div><div class="clear"></div>
<div class="linenb">1513</div><div class="codeline">    &amp;y_? = b - a + x \implies y_? = (b + x) - a \\</div><div class="clear"></div>
<div class="linenb">1514</div><div class="codeline">    &amp;y = (b \sqcup x) \setminus a \quad \text{(Set-theoretic interpretation)}</div><div class="clear"></div>
<div class="linenb">1515</div><div class="codeline"><span class="keyword2">\end{split}</span></div><div class="clear"></div>
<div class="linenb">1516</div><div class="codeline"><span class="keyword2">\end{equation*}</span></div><div class="clear"></div>
<div class="linenb">1517</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1518</div><div class="codeline">Notice that this form of word analogy can be <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (56889) [lt:en:EN_QUOTES]">"</span></span>derived<span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart closing quote here: '”'.. Suggestions: [”] (56897) [lt:en:EN_QUOTES]">"</span></span> from the vector formula</div><div class="clear"></div>
<div class="linenb">1519</div><div class="codeline">by re-arrangement. We use non-disjoint set union so that the common features</div><div class="clear"></div>
<div class="linenb">1520</div><div class="codeline">are not eliminated, but the values are clipped at $(0,1]$ so that the fuzzy</div><div class="clear"></div>
<div class="linenb">1521</div><div class="codeline">representation is consistent. Analogical reasoning is based on the common</div><div class="clear"></div>
<div class="linenb">1522</div><div class="codeline">features between the word representations, and conflates multiple types of</div><div class="clear"></div>
<div class="linenb">1523</div><div class="codeline">relations such as synonymy, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [hypernym, hypernyms, hypernym y] (57247) [lt:en:MORFOLOGIK_RULE_EN_GB]">hypernymy</span> and causal relations</div><div class="clear"></div>
<div class="linenb">1524</div><div class="codeline">\citep{chen2017evaluating}. Using fuzzy set theoretic representations, we can</div><div class="clear"></div>
<div class="linenb">1525</div><div class="codeline">also provide a context for the analogy, effectively reconstructing analogous</div><div class="clear"></div>
<div class="linenb">1526</div><div class="codeline">reasoning to account for the type of relation from a lexical semantic</div><div class="clear"></div>
<div class="linenb">1527</div><div class="codeline">perspective.</div><div class="clear"></div>
<div class="linenb">1528</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1529</div><div class="codeline">Some examples of word analogy based are presented in <span class="highlight-sh" title="Use a capital letter when referring to a specific table: 'Table X' [sh:tabmag]">table \ref</span>{tab: analogy}.</div><div class="clear"></div>
<div class="linenb">1530</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1531</div><div class="codeline"><span class="keyword2">\begin{table}</span>[]</div><div class="clear"></div>
<div class="linenb">1532</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">1533</div><div class="codeline">    <span class="keyword2">\begin{tabular}</span>{ccc|c|c}</div><div class="clear"></div>
<div class="linenb">1534</div><div class="codeline">        \bf Word 1  &amp; \bf Word 2    &amp; \bf Word 3    &amp; \bf word2vec  &amp; \bf Our representation    \\ \hline</div><div class="clear"></div>
<div class="linenb">1535</div><div class="codeline">        bacteria    &amp; tuberculosis  &amp; virus         &amp; polio         &amp; hiv                       \\</div><div class="clear"></div>
<div class="linenb">1536</div><div class="codeline">        cold        &amp; freezing      &amp; hot           &amp; evaporates    &amp; boiling                   \\</div><div class="clear"></div>
<div class="linenb">1537</div><div class="codeline">        ds          &amp; nintendo      &amp; dreamcast     &amp; playstation   &amp; sega                      \\</div><div class="clear"></div>
<div class="linenb">1538</div><div class="codeline">        pool        &amp; billiards     &amp; karate        &amp; taekwondo     &amp; judo                      \\</div><div class="clear"></div>
<div class="linenb">1539</div><div class="codeline">    <span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">1540</div><div class="codeline">    <span class="keyword1">\caption</span>{Examples of analogy compared to the analogy in word2vec. We see here that the comparisons constructed by feature representations are similar to those given by the standard word vectors.}</div><div class="clear"></div>
<div class="linenb">1541</div><div class="codeline">    <span class="keyword1">\label</span>{tab: analogy}</div><div class="clear"></div>
<div class="linenb">1542</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">1543</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1544</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 7 words). You should consider merging it with another section or make it longer. [sh:seclen]">section</span>{Interesting Qualitative Observations}</div><div class="clear"></div>
<div class="linenb">1545</div><div class="codeline"><span class="keyword1">\label</span>{sec: observations}</div><div class="clear"></div>
<div class="linenb">1546</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1547</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 40 words). You should consider merging it with another section or make it longer. [sh:seclen]">section</span>{Experiments and Results}</div><div class="clear"></div>
<div class="linenb">1548</div><div class="codeline"><span class="keyword1">\label</span>{sec: results}</div><div class="clear"></div>
<div class="linenb">1549</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1550</div><div class="codeline">In this section, we present our experiments and their results in various</div><div class="clear"></div>
<div class="linenb">1551</div><div class="codeline">domains including similarity, analogy, function word detection, polysemy</div><div class="clear"></div>
<div class="linenb">1552</div><div class="codeline">detection, lexical entailment and compositionality. All the experiments have</div><div class="clear"></div>
<div class="linenb">1553</div><div class="codeline">been conducted on established datasets.</div><div class="clear"></div>
<div class="linenb">1554</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1555</div><div class="codeline"><span class="keyword1">\subsection</span>{Similarity and <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Analogy., Analogy!, Analogy?, Analogy:, Analogy,, Analogy;] (57902) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>Analogy}</div><div class="clear"></div>
<div class="linenb">1556</div><div class="codeline"><span class="keyword1">\label</span>{ssec: sim-anal}</div><div class="clear"></div>
<div class="linenb">1557</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1558</div><div class="codeline">Similarity and analogy are the most popular intrinsic evaluation mechanisms for</div><div class="clear"></div>
<div class="linenb">1559</div><div class="codeline">word representations \citep{mikolov2013efficient}. Therefore, to evaluate our</div><div class="clear"></div>
<div class="linenb">1560</div><div class="codeline">representations, the first tasks we show are similarity and analogy. For</div><div class="clear"></div>
<div class="linenb">1561</div><div class="codeline">similarity computations, we use the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Simplex] (58154) [lt:en:MORFOLOGIK_RULE_EN_GB]">SimLex</span> corpus \citep{hill2015simlex} for</div><div class="clear"></div>
<div class="linenb">1562</div><div class="codeline">training and testing at different dimensions For word analogy, we use the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Mr, MSN, CSR, MST, MSc, Ms, ESR, MSI, Mar, MSC, MSM, MSP, Mir, Mòr, Sr, Mfr, Mgr] (58250) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>MSR</div><div class="clear"></div>
<div class="linenb">1563</div><div class="codeline">Word Relatedness Test \citep{mikolov2013linguistic}. We compare it to the</div><div class="clear"></div>
<div class="linenb">1564</div><div class="codeline">vector representation of words for different dimensions.</div><div class="clear"></div>
<div class="linenb">1565</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1566</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Similarity}</div><div class="clear"></div>
<div class="linenb">1567</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1568</div><div class="codeline">Our scores our compared to the word2vec scores of similarity using the Spearman</div><div class="clear"></div>
<div class="linenb">1569</div><div class="codeline">rank correlation coefficient \citep{spearman1987proof}, which is a ratio of the</div><div class="clear"></div>
<div class="linenb">1570</div><div class="codeline">covariances and standard deviations of the inputs being compared.</div><div class="clear"></div>
<div class="linenb">1571</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1572</div><div class="codeline"><span class="keyword2">\begin{table}</span>[]</div><div class="clear"></div>
<div class="linenb">1573</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">1574</div><div class="codeline">    <span class="keyword2">\begin{tabular}</span>{c|c|cc}</div><div class="clear"></div>
<div class="linenb">1575</div><div class="codeline">        \multirow{2}{*}{\bf Dims.}   &amp; \multirow{2}{*}{\bf word2vec} &amp; \multicolumn{2}{c}{\bf Our Representation} \\ \cline{3-4}</div><div class="clear"></div>
<div class="linenb">1576</div><div class="codeline">                            &amp;                               &amp; K-L Divergence &amp; Cross-Entropy \\\hline</div><div class="clear"></div>
<div class="linenb">1577</div><div class="codeline">        20  &amp;   0.2478   &amp; 0.2690 &amp; \bf 0.2744    \\</div><div class="clear"></div>
<div class="linenb">1578</div><div class="codeline">        50  &amp;   0.2916   &amp; 0.2966 &amp; \bf 0.2981    \\</div><div class="clear"></div>
<div class="linenb">1579</div><div class="codeline">        100 &amp;   0.2960   &amp; 0.3124 &amp; \bf 0.3206    \\</div><div class="clear"></div>
<div class="linenb">1580</div><div class="codeline">        200 &amp;   0.3259   &amp; 0.3253 &amp; \bf 0.3298</div><div class="clear"></div>
<div class="linenb">1581</div><div class="codeline">    <span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">1582</div><div class="codeline">    <span class="keyword1">\caption</span>{Similarity scores on the SimLex-999 dataset \citep{hill2015simlex}, for various dimension sizes (Dims.). The scores are provided according to the Spearman Correlation to incorporate higher precision.}</div><div class="clear"></div>
<div class="linenb">1583</div><div class="codeline">    <span class="keyword1">\label</span>{tab: similarity scores}</div><div class="clear"></div>
<div class="linenb">1584</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">1585</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1586</div><div class="codeline">As shown in <span class="highlight-sh" title="Use a capital letter when referring to a specific table: 'Table X' [sh:tabmag]">table \ref</span>{tab: similarity scores}, using our representation,</div><div class="clear"></div>
<div class="linenb">1587</div><div class="codeline">similarity is <span class="keyword1">\textit</span>{slightly} better represented according to the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Simplex] (58684) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>SimLex</div><div class="clear"></div>
<div class="linenb">1588</div><div class="codeline">corpus. We show similarity on both the asymmetric measures of similarity for</div><div class="clear"></div>
<div class="linenb">1589</div><div class="codeline">our representation, K-L divergence <span class="highlight" title="Probable usage error. Use 'and' after 'both'.. Suggestions: [and] (58803) [lt:en:BOTH_AS_WELL_AS]">as well as</span> cross-entropy. We see that</div><div class="clear"></div>
<div class="linenb">1590</div><div class="codeline">cross-entropy performs better than K-L Divergence. While the similarity scores</div><div class="clear"></div>
<div class="linenb">1591</div><div class="codeline">are generally higher, we see a reduction in the degree of similarity beyond 100</div><div class="clear"></div>
<div class="linenb">1592</div><div class="codeline">dimension vectors (features).</div><div class="clear"></div>
<div class="linenb">1593</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1594</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Analogy}</div><div class="clear"></div>
<div class="linenb">1595</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1596</div><div class="codeline"><span class="keyword2">\begin{table}</span>[]</div><div class="clear"></div>
<div class="linenb">1597</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">1598</div><div class="codeline">    {\footnotesize</div><div class="clear"></div>
<div class="linenb">1599</div><div class="codeline">    <span class="keyword2">\begin{tabular}</span>{ll|rr|rr}</div><div class="clear"></div>
<div class="linenb">1600</div><div class="codeline">        \multicolumn{2}{l|}{\bf\multirow{2}{*}{Category}}&amp; \multicolumn{2}{c|}{\bf word2vec} &amp; \multicolumn{2}{c}{\bf Our representation}   \\ \cline{3-6}</div><div class="clear"></div>
<div class="linenb">1601</div><div class="codeline">        \multicolumn{2}{l|}{}                           &amp; 50        &amp; 100       &amp; 50        &amp; 100               \\\hline</div><div class="clear"></div>
<div class="linenb">1602</div><div class="codeline">        \multicolumn{2}{l|}{Capital Common Countries}   &amp; 21.94     &amp; 37.55     &amp; \bf 39.13 &amp; \bf 47.23         \\</div><div class="clear"></div>
<div class="linenb">1603</div><div class="codeline">        \multicolumn{2}{l|}{Capital World}              &amp; 13.02     &amp; 20.10     &amp; \bf 27.30 &amp; \bf 26.54         \\</div><div class="clear"></div>
<div class="linenb">1604</div><div class="codeline">        \multicolumn{2}{l|}{Currency}                   &amp; 12.24     &amp; 18.60     &amp; \bf 25.27 &amp; \bf 24.90         \\</div><div class="clear"></div>
<div class="linenb">1605</div><div class="codeline">        \multicolumn{2}{l|}{City-State}                 &amp; 10.38     &amp; 16.70     &amp; \bf 23.24 &amp; \bf 23.51         \\</div><div class="clear"></div>
<div class="linenb">1606</div><div class="codeline">        \multicolumn{2}{l|}{Family}                     &amp; 10.61     &amp; 17.34     &amp; \bf 23.67 &amp; \bf 23.88         \\ \hline</div><div class="clear"></div>
<div class="linenb">1607</div><div class="codeline">        \multirow{3}{*}{Adjective-Adverb}   &amp; Syntactic &amp; 4.74      &amp; 3.23      &amp; \bf 7.26  &amp; \bf 3.83          \\</div><div class="clear"></div>
<div class="linenb">1608</div><div class="codeline">                                            &amp; Semantic  &amp; 10.61     &amp; 17.34     &amp; \bf 23.67 &amp; \bf 23.88         \\</div><div class="clear"></div>
<div class="linenb">1609</div><div class="codeline">                                            &amp; Overall   &amp; 9.92      &amp; 15.68     &amp; \bf 21.73 &amp; \bf 21.52         \\ \hline</div><div class="clear"></div>
<div class="linenb">1610</div><div class="codeline">        \multirow{3}{*}{Opposite}           &amp; Syntactic &amp; 4.06      &amp; 3.66      &amp; \bf 7.61  &amp; \bf 4.92          \\</div><div class="clear"></div>
<div class="linenb">1611</div><div class="codeline">                                            &amp; Semantic  &amp; 10.61     &amp; 17.34     &amp; \bf 23.67 &amp; \bf 23.88         \\</div><div class="clear"></div>
<div class="linenb">1612</div><div class="codeline">                                            &amp; Overall   &amp; 9.36      &amp; 14.73     &amp; \bf 20.60 &amp; \bf 20.26         \\ \hline</div><div class="clear"></div>
<div class="linenb">1613</div><div class="codeline">        \multirow{3}{*}{Comparative}        &amp; Syntactic &amp; 8.86      &amp; 12.63     &amp; \bf 16.88 &amp; \bf 15.39         \\</div><div class="clear"></div>
<div class="linenb">1614</div><div class="codeline">                                            &amp; Semantic  &amp; 10.61     &amp; 17.34     &amp; \bf 23.67 &amp; \bf 23.88         \\</div><div class="clear"></div>
<div class="linenb">1615</div><div class="codeline">                                            &amp; Overall   &amp; 10.10     &amp; 15.96     &amp; \bf 21.67 &amp; \bf 21.39         \\ \hline</div><div class="clear"></div>
<div class="linenb">1616</div><div class="codeline">        \multirow{3}{*}{Superlative}        &amp; Syntactic &amp; 7.59      &amp; 11.30     &amp; \bf 14.32 &amp; \bf 13.36         \\</div><div class="clear"></div>
<div class="linenb">1617</div><div class="codeline">                                            &amp; Semantic  &amp; 10.61     &amp; 17.34     &amp; \bf 23.67 &amp; \bf 23.88         \\</div><div class="clear"></div>
<div class="linenb">1618</div><div class="codeline">                                            &amp; Overall   &amp; 9.54      &amp; 15.20     &amp; \bf 20.35 &amp; \bf 20.15         \\ \hline</div><div class="clear"></div>
<div class="linenb">1619</div><div class="codeline">        \multirow{3}{*}{Present-Participle} &amp; Syntactic &amp; 7.51      &amp; 10.96     &amp; \bf 14.31 &amp; \bf 13.14         \\</div><div class="clear"></div>
<div class="linenb">1620</div><div class="codeline">                                            &amp; Semantic  &amp; 10.61     &amp; 17.34     &amp; \bf 23.67 &amp; \bf 23.88         \\</div><div class="clear"></div>
<div class="linenb">1621</div><div class="codeline">                                            &amp; Overall   &amp; 9.34      &amp; 14.73     &amp; \bf 19.84 &amp; \bf 19.49         \\ \hline</div><div class="clear"></div>
<div class="linenb">1622</div><div class="codeline">        \multirow{3}{*}{Nationality}        &amp; Syntactic &amp; 12.51     &amp; 19.07     &amp; \bf 21.64 &amp; \bf 21.96          \\</div><div class="clear"></div>
<div class="linenb">1623</div><div class="codeline">                                            &amp; Semantic  &amp; 10.61     &amp; 17.34     &amp; \bf 23.67 &amp; \bf 23.88         \\</div><div class="clear"></div>
<div class="linenb">1624</div><div class="codeline">                                            &amp; Overall   &amp; 11.51     &amp; 18.16     &amp; \bf 22.71 &amp; \bf 22.97         \\ \hline</div><div class="clear"></div>
<div class="linenb">1625</div><div class="codeline">        \multirow{3}{*}{Past Tense}         &amp; Syntactic &amp; 11.65     &amp; 17.09     &amp; \bf 20.43 &amp; \bf 19.76         \\</div><div class="clear"></div>
<div class="linenb">1626</div><div class="codeline">                                            &amp; Semantic  &amp; 10.61     &amp; 17.34     &amp; \bf 23.67 &amp; \bf 23.88         \\</div><div class="clear"></div>
<div class="linenb">1627</div><div class="codeline">                                            &amp; Overall   &amp; 11.16     &amp; 17.21     &amp; \bf 21.96 &amp; \bf 27.72         \\ \hline</div><div class="clear"></div>
<div class="linenb">1628</div><div class="codeline">        \multirow{3}{*}{Plural}             &amp; Syntactic &amp; 11.76     &amp; 17.23     &amp; \bf 20.53 &amp; \bf 19.89         \\</div><div class="clear"></div>
<div class="linenb">1629</div><div class="codeline">                                            &amp; Semantic  &amp; 10.61     &amp; 17.34     &amp; \bf 23.67 &amp; \bf 23.88         \\</div><div class="clear"></div>
<div class="linenb">1630</div><div class="codeline">                                            &amp; Overall   &amp; 11.26     &amp; 17.28     &amp; \bf 21.90 &amp; \bf 21.64         \\ \hline</div><div class="clear"></div>
<div class="linenb">1631</div><div class="codeline">        \multirow{3}{*}{Plural Verbs}       &amp; Syntactic &amp; 11.36     &amp; 16.60     &amp; \bf 19.88 &amp; \bf 19.46         \\</div><div class="clear"></div>
<div class="linenb">1632</div><div class="codeline">                                            &amp; Semantic  &amp; 10.61     &amp; 17.34     &amp; \bf 23.67 &amp; \bf 23.88         \\</div><div class="clear"></div>
<div class="linenb">1633</div><div class="codeline">                                            &amp; Overall   &amp; 11.05     &amp; 16.91     &amp; \bf 21.46 &amp; \bf 21.30         \\ \hline</div><div class="clear"></div>
<div class="linenb">1634</div><div class="codeline">    <span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">1635</div><div class="codeline">    }</div><div class="clear"></div>
<div class="linenb">1636</div><div class="codeline">    <span class="keyword1">\caption</span>{Comparison of Analogies between word2vec and our representation for 50 and 100 dimensions (Dims.). For the first five, only overall accuracy is shown as overall accuracy is the same as semantic accuracy (as there is no syntactic accuracy measure). For all the others, we present, syntactic, semantic and overall accuracy as well. We see here that we outperform word2vec on every single metric.}</div><div class="clear"></div>
<div class="linenb">1637</div><div class="codeline">    <span class="keyword1">\label</span>{tab: analogy scores}</div><div class="clear"></div>
<div class="linenb">1638</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">1639</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1640</div><div class="codeline">For analogy, we see that our model outperforms word2vec at both 50 and 100</div><div class="clear"></div>
<div class="linenb">1641</div><div class="codeline">dimensions. We see that at lower dimension sizes, our normalized feature</div><div class="clear"></div>
<div class="linenb">1642</div><div class="codeline">representation captures significantly more syntactic and semantic information</div><div class="clear"></div>
<div class="linenb">1643</div><div class="codeline">than its vector counterpart. We conjecture that this can primarily be</div><div class="clear"></div>
<div class="linenb">1644</div><div class="codeline">attributed to the fact that constructing feature probabilities provides more</div><div class="clear"></div>
<div class="linenb">1645</div><div class="codeline">information about the common (and distinct) <span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart opening quote here: '“'.. Suggestions: [“] (59458) [lt:en:EN_QUOTES]">"</span></span>concepts<span class="highlight-sh" title="Use `` and '' instead of ''. [sh:d:008]"><span class="highlight" title="Use a smart closing quote here: '”'.. Suggestions: [”] (59467) [lt:en:EN_QUOTES]">"</span></span> which are shared between</div><div class="clear"></div>
<div class="linenb">1646</div><div class="codeline">two words.</div><div class="clear"></div>
<div class="linenb">1647</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1648</div><div class="codeline">Since feature representations are inherently fuzzy sets, lower dimension sizes</div><div class="clear"></div>
<div class="linenb">1649</div><div class="codeline">provide a more reliable probability distribution, which becomes more and more</div><div class="clear"></div>
<div class="linenb">1650</div><div class="codeline">sparse as the dimensionality of the vectors increases (<span class="highlight-sh" title="Use a backslash or comma after the second period; otherwise LaTeX will think it is a full stop ending a sentence. [sh:011]">i.e. </span>number of features</div><div class="clear"></div>
<div class="linenb">1651</div><div class="codeline">rise). Therefore, we notice that the increase in feature probabilities is a lot</div><div class="clear"></div>
<div class="linenb">1652</div><div class="codeline">more for 50 dimensions than it is for 100.</div><div class="clear"></div>
<div class="linenb">1653</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1654</div><div class="codeline"><span class="keyword1">\subsection</span>{Function Word <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Detection., Detection!, Detection?, Detection:, Detection,, Detection;] (59880) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>Detection}</div><div class="clear"></div>
<div class="linenb">1655</div><div class="codeline"><span class="keyword1">\label</span>{ssec: function}</div><div class="clear"></div>
<div class="linenb">1656</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1657</div><div class="codeline">As mentioned in <span class="highlight-sh" title="Use a capital letter when referring to a specific section: 'Section X' [sh:secmag]">section \ref</span>{ssec: entropy math}, we use entropy as a measure</div><div class="clear"></div>
<div class="linenb">1658</div><div class="codeline">of detecting function words for the standard GoogleNews-300 negative sampling</div><div class="clear"></div>
<div class="linenb">1659</div><div class="codeline">dataset\footnote{https://code.google.com/archive/p/word2vec/}. In order to</div><div class="clear"></div>
<div class="linenb">1660</div><div class="codeline">quantitatively evaluate the detection of function words, we choose the top $n$</div><div class="clear"></div>
<div class="linenb">1661</div><div class="codeline">words in our representation ordered by entropy with a frequency $\geq 100$, and</div><div class="clear"></div>
<div class="linenb">1662</div><div class="codeline">compare it to the top $n$ words ordered by frequency from word2vec; $n$ being</div><div class="clear"></div>
<div class="linenb">1663</div><div class="codeline">15, 30 and 50. We compare the number of function words in both in table</div><div class="clear"></div>
<div class="linenb">1664</div><div class="codeline">\ref{tab: function word eval}. The list of function words is derived from</div><div class="clear"></div>
<div class="linenb">1665</div><div class="codeline">\citet{nation2016making}.</div><div class="clear"></div>
<div class="linenb">1666</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1667</div><div class="codeline"><span class="keyword2">\begin{table}</span>[]</div><div class="clear"></div>
<div class="linenb">1668</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">1669</div><div class="codeline">    <span class="keyword2">\begin{tabular}</span>{c|cc}</div><div class="clear"></div>
<div class="linenb">1670</div><div class="codeline">        top $n$ words &amp; \bf word2vec &amp; \bf Our Representation  \\ \hline</div><div class="clear"></div>
<div class="linenb">1671</div><div class="codeline">        15  &amp; 10 &amp; \bf 15 \\</div><div class="clear"></div>
<div class="linenb">1672</div><div class="codeline">        30  &amp; 21 &amp; \bf 30 \\</div><div class="clear"></div>
<div class="linenb">1673</div><div class="codeline">        50  &amp; 39 &amp; \bf 47  \\</div><div class="clear"></div>
<div class="linenb">1674</div><div class="codeline">    <span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">1675</div><div class="codeline">    <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Function word detection using entropy (in our representation) and by frequency in word2vec. We see that we consistently detect more function words than word2vec, based on the 176 function word list released by \citet{nation2016making}. The metric is <span class="keyword1">\emph</span>{number of words}, <span class="highlight-sh" title="Use a backslash or comma after the second period; otherwise LaTeX will think it is a full stop ending a sentence. [sh:011]">i.e. </span>the number of words chosen by frequency for word2vec and entropy for our representation</span>}</div><div class="clear"></div>
<div class="linenb">1676</div><div class="codeline">    <span class="keyword1">\label</span>{tab: function word eval}</div><div class="clear"></div>
<div class="linenb">1677</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">1678</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1679</div><div class="codeline"><span class="keyword1">\subsection</span>{Compositionality}</div><div class="clear"></div>
<div class="linenb">1680</div><div class="codeline"><span class="keyword1">\label</span>{ssec: entailment}</div><div class="clear"></div>
<div class="linenb">1681</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1682</div><div class="codeline">Finally, we evaluate the compositionality of word embeddings.</div><div class="clear"></div>
<div class="linenb">1683</div><div class="codeline">\citet{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Mikolov2013distributed] (60487) [lt:en:UPPERCASE_SENTENCE_START]">mikolov2013distributed}</span> claims that word embeddings in vector spaces</div><div class="clear"></div>
<div class="linenb">1684</div><div class="codeline">possess additive compositionality, <span class="highlight-sh" title="Use a backslash or comma after the second period; otherwise LaTeX will think it is a full stop ending a sentence. [sh:011]">i.e. </span>by vector addition, semantic phrases</div><div class="clear"></div>
<div class="linenb">1685</div><div class="codeline">such as compounds can be well represented. We claim that our representation in</div><div class="clear"></div>
<div class="linenb">1686</div><div class="codeline">fact captures the semantics of phrases by performing a literal combination of</div><div class="clear"></div>
<div class="linenb">1687</div><div class="codeline">the features of the head and modifier word, therefore providing a more robust</div><div class="clear"></div>
<div class="linenb">1688</div><div class="codeline">representation of phrases.</div><div class="clear"></div>
<div class="linenb">1689</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1690</div><div class="codeline">We use the English nominal compound phrases from</div><div class="clear"></div>
<div class="linenb">1691</div><div class="codeline">\citet{ramisch-etal-2016-naked}. An initial set of experiments on nominal</div><div class="clear"></div>
<div class="linenb">1692</div><div class="codeline">compounds using word2vec have been done before</div><div class="clear"></div>
<div class="linenb">1693</div><div class="codeline">\citep{cordeiro-etal-2016-predicting}, where it was shown to be a fairly</div><div class="clear"></div>
<div class="linenb">1694</div><div class="codeline">difficult task for modern non-contextual word embeddings. In order to <span class="highlight" title="Do not mix variants of the same word ('analyse' and 'analyze') within a single text.. Suggestions: [analyze] (61166) [lt:en:EN_WORD_COHERENCY]"></span>analyse</div><div class="clear"></div>
<div class="linenb">1695</div><div class="codeline">nominal compounds, we adjust our similarity metric to account for asymmetry in</div><div class="clear"></div>
<div class="linenb">1696</div><div class="codeline">the similarity between the head-word and the modifier, and vice versa. We</div><div class="clear"></div>
<div class="linenb">1697</div><div class="codeline">report performance on two metrics, the Spearman correlation</div><div class="clear"></div>
<div class="linenb">1698</div><div class="codeline">\citep{spearman1987proof} and Pearson correlation \citep{pearson1920notes}.</div><div class="clear"></div>
<div class="linenb">1699</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1700</div><div class="codeline"><span class="keyword2">\begin{table}</span>[]</div><div class="clear"></div>
<div class="linenb">1701</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">1702</div><div class="codeline">    <span class="keyword2">\begin{tabular}</span>{c|c|cc}</div><div class="clear"></div>
<div class="linenb">1703</div><div class="codeline">        \bf Dims.               &amp; \bf Metric&amp; \bf word2vec  &amp; \bf Our Representation    \\ \hline</div><div class="clear"></div>
<div class="linenb">1704</div><div class="codeline">        \multirow{2}{*}{50}     &amp; Spearman  &amp; 0.3946    &amp; \bf 0.4117            \\</div><div class="clear"></div>
<div class="linenb">1705</div><div class="codeline">                                &amp; Pearson   &amp; 0.4058    &amp; \bf 0.4081            \\ \hline</div><div class="clear"></div>
<div class="linenb">1706</div><div class="codeline">        \multirow{2}{*}{100}    &amp; Spearman  &amp; 0.4646    &amp; \bf 0.4912            \\</div><div class="clear"></div>
<div class="linenb">1707</div><div class="codeline">                                &amp; Pearson   &amp; 0.4457    &amp; \bf 0.4803            \\ \hline</div><div class="clear"></div>
<div class="linenb">1708</div><div class="codeline">        \multirow{2}{*}{200}    &amp; Spearman  &amp; 0.4479    &amp; \bf 0.4549            \\</div><div class="clear"></div>
<div class="linenb">1709</div><div class="codeline">                                &amp; Pearson   &amp; \bf 0.4163&amp; 0.4091                \\</div><div class="clear"></div>
<div class="linenb">1710</div><div class="codeline">    <span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">1711</div><div class="codeline">    <span class="keyword1">\caption</span>{Results for compositionality of word embeddings for nominal compounds for various dimensions (Dims.). We see that almost across the board, we perform better, however, for the Pearson correlation metric, at 200 dimensions, we find that word2vec has a better representation of rank by frequency for nominal compounds.}</div><div class="clear"></div>
<div class="linenb">1712</div><div class="codeline">    <span class="keyword1">\label</span>{tab: compositionality}</div><div class="clear"></div>
<div class="linenb">1713</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">1714</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1715</div><div class="codeline">The results are shown in <span class="highlight-sh" title="Use a capital letter when referring to a specific table: 'Table X' [sh:tabmag]">table \ref</span>{tab: compositionality}. The difference in</div><div class="clear"></div>
<div class="linenb">1716</div><div class="codeline">scores for the Pearson and Spearman rank correlation show that word2vec at</div><div class="clear"></div>
<div class="linenb">1717</div><div class="codeline">higher dimensions better represents the rank of words (by frequency), but at</div><div class="clear"></div>
<div class="linenb">1718</div><div class="codeline">lower dimensions, the feature probability representation has a better analysis</div><div class="clear"></div>
<div class="linenb">1719</div><div class="codeline">of both rank by frequency, and its correlation with similarity of words with a</div><div class="clear"></div>
<div class="linenb">1720</div><div class="codeline">nominal compound. Despite this, we show a higher Spearman correlation</div><div class="clear"></div>
<div class="linenb">1721</div><div class="codeline">coefficient at 200 dimensions as well, as we capture non-linear relations.</div><div class="clear"></div>
<div class="linenb">1722</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1723</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1724</div><div class="codeline">\<span class="highlight-sh" title="This subsection is very short (about 139 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsection</span>{Dimensionality Analysis and Feature <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Representations., Representations!, Representations?, Representations:, Representations,, Representations;] (61967) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>Representations}</div><div class="clear"></div>
<div class="linenb">1725</div><div class="codeline"><span class="keyword1">\label</span>{ssec: analysis}</div><div class="clear"></div>
<div class="linenb">1726</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1727</div><div class="codeline">In this subsection, we provide some interpretation of the results above, and</div><div class="clear"></div>
<div class="linenb">1728</div><div class="codeline">examine the effect of scaling dimensions to the feature representation. As seen</div><div class="clear"></div>
<div class="linenb">1729</div><div class="codeline">here, the evaluation has been done on smaller dimension sizes of 50 and 100,</div><div class="clear"></div>
<div class="linenb">1730</div><div class="codeline">and we see that our representation can be used for a slightly larger range of</div><div class="clear"></div>
<div class="linenb">1731</div><div class="codeline">tasks from the perspective of intrinsic evaluations. However, the results of</div><div class="clear"></div>
<div class="linenb">1732</div><div class="codeline">quantitative analogy for higher dimensions have been observed to be lower for</div><div class="clear"></div>
<div class="linenb">1733</div><div class="codeline">fuzzy representations rather than the word2vec negative-sampling word vectors.</div><div class="clear"></div>
<div class="linenb">1734</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1735</div><div class="codeline">We see that the representation we propose does not scale well as dimensions</div><div class="clear"></div>
<div class="linenb">1736</div><div class="codeline">increase. This is because our representation relies on the distribution of</div><div class="clear"></div>
<div class="linenb">1737</div><div class="codeline">probability mass per feature (dimension) across all the words. Therefore,</div><div class="clear"></div>
<div class="linenb">1738</div><div class="codeline">increasing the dimensionality of the word vectors used makes the representation</div><div class="clear"></div>
<div class="linenb">1739</div><div class="codeline">that much more sparse.</div><div class="clear"></div>
<div class="linenb">1740</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1741</div><div class="codeline"><span class="keyword1">\section</span>{Conclusion} <span class="keyword1">\label</span>{sec: conclusion}</div><div class="clear"></div>
<div class="linenb">1742</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1743</div><div class="codeline">In this paper, we presented a reinterpretation of distributional semantics. We</div><div class="clear"></div>
<div class="linenb">1744</div><div class="codeline">performed a column-wise normalization on word vectors, such that each value in</div><div class="clear"></div>
<div class="linenb">1745</div><div class="codeline">this normalized representation represented the probability of the word</div><div class="clear"></div>
<div class="linenb">1746</div><div class="codeline">possessing a feature that corresponded to each dimension. This provides us a</div><div class="clear"></div>
<div class="linenb">1747</div><div class="codeline">representation of each word as a tuple of feature probabilities. We find that</div><div class="clear"></div>
<div class="linenb">1748</div><div class="codeline">this representation can be seen as a fuzzy set, with each probability being the</div><div class="clear"></div>
<div class="linenb">1749</div><div class="codeline">function of the projection of the original word vector on a dimension.</div><div class="clear"></div>
<div class="linenb">1750</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1751</div><div class="codeline">Considering word vectors as fuzzy sets allows us <span class="highlight" title="Please check whether 'to' is missing here (to allow to do something).. Suggestions: [to access] (63459) [lt:en:ALLOW_TO_DO]">access</span> to set operations such</div><div class="clear"></div>
<div class="linenb">1752</div><div class="codeline">as union, intersection and difference. In our modification, these operations</div><div class="clear"></div>
<div class="linenb">1753</div><div class="codeline">provide the product, disjoint sum and difference of the word representations,</div><div class="clear"></div>
<div class="linenb">1754</div><div class="codeline">feature wise. Using qualitative examples, we show that our representation</div><div class="clear"></div>
<div class="linenb">1755</div><div class="codeline">naturally captures an asymmetric notion of similarity using feature difference,</div><div class="clear"></div>
<div class="linenb">1756</div><div class="codeline">from which known asymmetric measures can be easily constructed, such as Cross</div><div class="clear"></div>
<div class="linenb">1757</div><div class="codeline">Entropy and K-L Divergence.</div><div class="clear"></div>
<div class="linenb">1758</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1759</div><div class="codeline">We qualitatively show how our model accounts for polysemy, while showing</div><div class="clear"></div>
<div class="linenb">1760</div><div class="codeline">quantitative proofs of our representation's performance at lower dimensions in</div><div class="clear"></div>
<div class="linenb">1761</div><div class="codeline">similarity, analogy, compositionality and function word detection. We</div><div class="clear"></div>
<div class="linenb">1762</div><div class="codeline">hypothesize that lower dimensions are more suited for our representation as</div><div class="clear"></div>
<div class="linenb">1763</div><div class="codeline">sparsity increases with higher dimensions, so the significance of feature</div><div class="clear"></div>
<div class="linenb">1764</div><div class="codeline">probabilities reduces. This sparsity causes a diffusion of the probabilities</div><div class="clear"></div>
<div class="linenb">1765</div><div class="codeline">across multiple features.</div><div class="clear"></div>
<div class="linenb">1766</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1767</div><div class="codeline">Through this work, we aim to provide some insights into interpreting word</div><div class="clear"></div>
<div class="linenb">1768</div><div class="codeline">representations by showing one possible perspective and explanation of the</div><div class="clear"></div>
<div class="linenb">1769</div><div class="codeline">lengths and projections of word embeddings in the vector space. These feature</div><div class="clear"></div>
<div class="linenb">1770</div><div class="codeline">representations can be adapted for basic neural models, allowing the use of</div><div class="clear"></div>
<div class="linenb">1771</div><div class="codeline">feature based representations at lower dimensions for downstream tasks.</div><div class="clear"></div>
<div class="linenb">1772</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1773</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1774</div><div class="codeline">\chapter{Geometry of Word <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Representations., Representations!, Representations?, Representations:, Representations,, Representations;] (64775) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>Representations}</div><div class="clear"></div>
<div class="linenb">1775</div><div class="codeline"><span class="keyword1">\label</span>{chapter:geometrization}</div><div class="clear"></div>
<div class="linenb">1776</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1777</div><div class="codeline">\epigraph{In the deeper dreams everything was likewise more distinct, and <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Tillman, Gillan, Gillian, Gilman, Hillman, Gill man] (64857) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>Gillman</div><div class="clear"></div>
<div class="linenb">1778</div><div class="codeline">felt that the twilight abysses around him were those of the fourth dimension.}{<span class="highlight" title="Add a space between sentences. Suggestions: [ H] (64942) [lt:en:SENTENCE_WHITESPACE]">H</span>. P. <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Love craft] (64948) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>Lovecraft}</div><div class="clear"></div>
<div class="linenb">1779</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1780</div><div class="codeline"><span class="comment"><span class="comment">% http://svcl.ucsd.edu/publications/journal/2016/ggr/supplementary_material.pdf</span></span></div><div class="clear"></div>
<div class="linenb">1781</div><div class="codeline"><span class="comment"><span class="comment">% https://www.cis.upenn.edu/~cis515/Stiefel-Grassmann-manifolds-Edelman.pdf</span></span></div><div class="clear"></div>
<div class="linenb">1782</div><div class="codeline"><span class="comment"><span class="comment">% https://www.manopt.org/reference/manopt/manifolds/grassmann/grassmannfactory.html#_sub7</span></span></div><div class="clear"></div>
<div class="linenb">1783</div><div class="codeline"><span class="comment"><span class="comment">% https://arxiv.org/pdf/1205.5935.pdf</span></span></div><div class="clear"></div>
<div class="linenb">1784</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1785</div><div class="codeline"><span class="comment"><span class="comment">% \textinit{E}mbedding words in vector spaces has become the norm for</span></span></div><div class="clear"></div>
<div class="linenb">1786</div><div class="codeline">Embedding words in vector spaces has become the norm for word representation.</div><div class="clear"></div>
<div class="linenb">1787</div><div class="codeline">The terms <span class="keyword1">\emph</span>{word vectors} and <span class="keyword1">\emph</span>{word embeddings} synonymous to one</div><div class="clear"></div>
<div class="linenb">1788</div><div class="codeline">another, due to the success of vector based models such as word2vec, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Glove, Love, Globe, Gloves, Grove, Clove, Gloved, Glover] (65168) [lt:en:MORFOLOGIK_RULE_EN_GB]">GloVe</span> and</div><div class="clear"></div>
<div class="linenb">1789</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Fastest, Fattest] (65178) [lt:en:MORFOLOGIK_RULE_EN_GB]">FastText</span>.  While esoteric literature has attempted to change the underlying</div><div class="clear"></div>
<div class="linenb">1790</div><div class="codeline">embedding space of distributional lexical semantic representations, the</div><div class="clear"></div>
<div class="linenb">1791</div><div class="codeline">resultant word embeddings are specific to a given task or linguistic property.</div><div class="clear"></div>
<div class="linenb">1792</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1793</div><div class="codeline">Even with the introduction of contextualized word representations, the</div><div class="clear"></div>
<div class="linenb">1794</div><div class="codeline">underlying structure of word representations has remained the same, mapping a</div><div class="clear"></div>
<div class="linenb">1795</div><div class="codeline">word to a single vector in a continuous vector space. <span class="highlight" title="If the text is a generality, 'of the' is not necessary. Do you mean 'some'?. Suggestions: [Some] (65609) [lt:en:SOME_OF_THE]">Some of the</span> known</div><div class="clear"></div>
<div class="linenb">1796</div><div class="codeline">challenges with this assumption of word to vector are based around</div><div class="clear"></div>
<div class="linenb">1797</div><div class="codeline">resolving polysemy and the treatment of function words, to which the classical</div><div class="clear"></div>
<div class="linenb">1798</div><div class="codeline">answer has been extracting and using contextual information.</div><div class="clear"></div>
<div class="linenb">1799</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1800</div><div class="codeline">We first survey why we use vectors as the object that is embedded. We focus</div><div class="clear"></div>
<div class="linenb">1801</div><div class="codeline">on the \texttt{word2vec} training and testing mechanism. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (65959) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]">We</span> will see that this process</div><div class="clear"></div>
<div class="linenb">1802</div><div class="codeline">uses many fundamentally different structures that is <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [possessed] (66042) [lt:en:MORFOLOGIK_RULE_EN_GB]">posessed</span> by real n-dimensional space $\R^n$.</div><div class="clear"></div>
<div class="linenb">1803</div><div class="codeline">We then disentangle these different structures for mathematical <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [cleanliness, cleanness] (66146) [lt:en:MORFOLOGIK_RULE_EN_GB]">cleaniness</span>. Once this is performed,</div><div class="clear"></div>
<div class="linenb">1804</div><div class="codeline">we isolate the mathematical structures that are present, allow us to introduce a</div><div class="clear"></div>
<div class="linenb">1805</div><div class="codeline">generalization based on embedding words into an arbitrary Lie group. We show how</div><div class="clear"></div>
<div class="linenb">1806</div><div class="codeline">specializing this to the case of $\R^n$ yields us back fuzzy set representations, and we</div><div class="clear"></div>
<div class="linenb">1807</div><div class="codeline">conjecture that this applied to richer spaces would yield embeddings with</div><div class="clear"></div>
<div class="linenb">1808</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [hitherto] (66502) [lt:en:MORFOLOGIK_RULE_EN_GB]">hithertho</span> unexplored properties.</div><div class="clear"></div>
<div class="linenb">1809</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1810</div><div class="codeline"><span class="keyword1">\section</span>{The blessing and curse of <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [X., X!, X?, X:, X,, X;] (66562) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>$\mathbb{R}^n$}</div><div class="clear"></div>
<div class="linenb">1811</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1812</div><div class="codeline">In this section, we recall the training regime of \texttt{word2vec},</div><div class="clear"></div>
<div class="linenb">1813</div><div class="codeline">and then disentangle the various structures of $\mathbb{R}^n$ that are</div><div class="clear"></div>
<div class="linenb">1814</div><div class="codeline">used during training and evaluation. The fundamental operations performed in</div><div class="clear"></div>
<div class="linenb">1815</div><div class="codeline">\<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (66761) [lt:en:MORFOLOGIK_RULE_EN_GB]">wtov</span> during training is to first pick a focus word, and then performing gradient descent</div><div class="clear"></div>
<div class="linenb">1816</div><div class="codeline">with all the words around the focus word to have dot product $+1$ (positive samples),</div><div class="clear"></div>
<div class="linenb">1817</div><div class="codeline">and performing gradient descent with random words in the corpus away from the focus word</div><div class="clear"></div>
<div class="linenb">1818</div><div class="codeline">to have dot product $0$ (negative samples). We see that to perform this step,</div><div class="clear"></div>
<div class="linenb">1819</div><div class="codeline">we need to know (1a) How to perform dot-products (a measure of similarity), and (1b)</div><div class="clear"></div>
<div class="linenb">1820</div><div class="codeline">How to perform gradient descent (a method of function <span class="highlight" title="In British English, for some nouns, both ~s and ~z spellings are possible. By default, the rule for Oxford spelling is on for nouns and thus suggests 'optimization'.. Suggestions: [optimization] (67237) [lt:en:OXFORD_SPELLING_NOUNS]">optimisation</span>).</div><div class="clear"></div>
<div class="linenb">1821</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1822</div><div class="codeline">Next, during evaluation, to check for <span class="keyword1">\emph</span>{similarity} between the two words,</div><div class="clear"></div>
<div class="linenb">1823</div><div class="codeline">we once again use the dot-product of the vectors representing the two words.</div><div class="clear"></div>
<div class="linenb">1824</div><div class="codeline"><span class="keyword1">\emph</span>{Analogy} is more complex;</div><div class="clear"></div>
<div class="linenb">1825</div><div class="codeline">Given two words representing a sense of analogy (\texttt{king<span class="highlight-sh" title="There should not be a space before a punctuation mark. If in your language, typographic rules require a space here, LaTeX takes care of inserting it without your intervention. [sh:d:005]"> :</span> man}), and a third</div><div class="clear"></div>
<div class="linenb">1826</div><div class="codeline">word representing the first half on an unknown analogy (\texttt{woman:?}), we</div><div class="clear"></div>
<div class="linenb">1827</div><div class="codeline">are to find the unknown word<span class="highlight-sh" title="There should not be a space before a punctuation mark. If in your language, typographic rules require a space here, LaTeX takes care of inserting it without your intervention. [sh:d:005]"> \texttt{?}</span> <span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Which] (67601) [lt:en:UPPERCASE_SENTENCE_START]">which</span> solves the analogical task</div><div class="clear"></div>
<div class="linenb">1828</div><div class="codeline">\texttt{king:man::woman:?}. Recall that this is computed as $? \equiv \texttt{man} - \texttt{king} + \texttt{woman}$.</div><div class="clear"></div>
<div class="linenb">1829</div><div class="codeline">The above equation relies on being able to perform (2) addition ($+$) and subtraction ($-$).</div><div class="clear"></div>
<div class="linenb">1830</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1831</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1832</div><div class="codeline">These are all different facets of $\R^n$. (1a) The <span class="keyword1">\emph</span>{inner product}</div><div class="clear"></div>
<div class="linenb">1833</div><div class="codeline">structure is used to compute the dot-product. (1b) The <span class="keyword1">\emph</span>{Riemannian} structure is used to perform</div><div class="clear"></div>
<div class="linenb">1834</div><div class="codeline">gradient descent, and (2) The <span class="keyword1">\emph</span>{group} structure of vectors under vector addition is used to compute</div><div class="clear"></div>
<div class="linenb">1835</div><div class="codeline">the addition and subtraction operations for analogy. With this disentanglement, we elaborate</div><div class="clear"></div>
<div class="linenb">1836</div><div class="codeline">on what these mathematical structures are, after which we write down the</div><div class="clear"></div>
<div class="linenb">1837</div><div class="codeline">general version of the algorithm which can still honestly be called the</div><div class="clear"></div>
<div class="linenb">1838</div><div class="codeline">\texttt{word2vec} algorithm. We describe the structures in \texttt{word2vec}</div><div class="clear"></div>
<div class="linenb">1839</div><div class="codeline">and their generalization is \autoref{fig:table-structures-word2vec-vs-ours}.</div><div class="clear"></div>
<div class="linenb">1840</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1841</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1842</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1843</div><div class="codeline"><span class="keyword1">\section</span>{Spaces for \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [WTO, tov, Ufton, w tov] (68411) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>wtov}</div><div class="clear"></div>
<div class="linenb">1844</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1845</div><div class="codeline">In light of the discussion above, we reformulate the informally discussed</div><div class="clear"></div>
<div class="linenb">1846</div><div class="codeline">notions into the language of <span class="keyword1">\emph</span>{Lie groups}, which are mathematical structures</div><div class="clear"></div>
<div class="linenb">1847</div><div class="codeline">that are equipped with addition, subtraction, and gradient descent operations.</div><div class="clear"></div>
<div class="linenb">1848</div><div class="codeline">The astute reader will notice that a dot product structure is missing. Fear not, for</div><div class="clear"></div>
<div class="linenb">1849</div><div class="codeline">every Lie group is associated with a corresponding <span class="keyword1">\emph</span>{Lie algebra}, which possesses</div><div class="clear"></div>
<div class="linenb">1850</div><div class="codeline">a dot-product structure, and a method to transport data back and forth from the Lie group</div><div class="clear"></div>
<div class="linenb">1851</div><div class="codeline">to the Lie algebra. The definition of a Lie Group is first presented, followed by</div><div class="clear"></div>
<div class="linenb">1852</div><div class="codeline">the definition of the Lie algebra and the exponential and logarithm maps. Later, the</div><div class="clear"></div>
<div class="linenb">1853</div><div class="codeline">formal definitions of a Riemannian manifold, along with the connection to Lie</div><div class="clear"></div>
<div class="linenb">1854</div><div class="codeline">Groups is presented.</div><div class="clear"></div>
<div class="linenb">1855</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1856</div><div class="codeline"><span class="keyword1">\subsection</span>{Matrix Lie <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [groups., groups!, groups?, groups:, groups,, groups;] (69178) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>groups}</div><div class="clear"></div>
<div class="linenb">1857</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1858</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">1859</div><div class="codeline"><span class="keyword1">\label</span>{<span class="highlight-sh" title="Figure fig:table-structures-word2vec-vs-ours is never referenced in the text [sh:figref]">f</span>ig:table-structures-word2vec-vs-ours}</div><div class="clear"></div>
<div class="linenb">1860</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{lll}</div><div class="clear"></div>
<div class="linenb">1861</div><div class="codeline">&amp; \texttt{word2vec} &amp; Ours \\</div><div class="clear"></div>
<div class="linenb">1862</div><div class="codeline">Space &amp; $\mathbb R^n$ &amp; Lie group $(G, \cdot)$ \\</div><div class="clear"></div>
<div class="linenb">1863</div><div class="codeline">Similarity \texttt{sim(a, b)}&amp;  Dot product on $\mathbb R^n$ &amp; Dot product in the Lie algebra $\mathfrak g$ \\</div><div class="clear"></div>
<div class="linenb">1864</div><div class="codeline">Analogy \texttt{a:b::c:?} &amp; Vector space structure on $\mathbb R^n$: $(b - a + c)$ &amp; Group operation $b\cdot a^{1}\cdot c$ \\</div><div class="clear"></div>
<div class="linenb">1865</div><div class="codeline">Optimisation &amp; Gradient descent &amp; Riemannian gradient descent</div><div class="clear"></div>
<div class="linenb">1866</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">1867</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Operations in \texttt{word2vec} and their generalization</span>}</div><div class="clear"></div>
<div class="linenb">1868</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">1869</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1870</div><div class="codeline">We first provide an accessible definition of Lie groups, sweeping</div><div class="clear"></div>
<div class="linenb">1871</div><div class="codeline">technicalities into the footnotes. We direct the interested reader to \cite{hall2015lie}.</div><div class="clear"></div>
<div class="linenb">1872</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1873</div><div class="codeline"><span class="keyword2">\begin{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Slogan] (69329) [lt:en:UPPERCASE_SENTENCE_START]"></span>slogan}</span></div><div class="clear"></div>
<div class="linenb">1874</div><div class="codeline">A Matrix Lie group is a space of <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [matrices] (69369) [lt:en:MORFOLOGIK_RULE_EN_GB]">matrcies</span> closed under multiplication and</div><div class="clear"></div>
<div class="linenb">1875</div><div class="codeline">matrix inverse.</div><div class="clear"></div>
<div class="linenb">1876</div><div class="codeline"><span class="keyword2">\end{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Slogan] (69426) [lt:en:UPPERCASE_SENTENCE_START]"></span>slogan}</span></div><div class="clear"></div>
<div class="linenb">1877</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1878</div><div class="codeline">Intuitively, the idea is that we wish to generalize from vectors, where adding</div><div class="clear"></div>
<div class="linenb">1879</div><div class="codeline">words is commutative (since $a + b = b + a$ for vectors), to the non-commutative</div><div class="clear"></div>
<div class="linenb">1880</div><div class="codeline">regime of <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [matrices] (69590) [lt:en:MORFOLOGIK_RULE_EN_GB]">matrcies</span> where $AB \neq BA$. Hence, we will replace the notion of analogy,</div><div class="clear"></div>
<div class="linenb">1881</div><div class="codeline">$b - a + c$ with matrix multiplication of the form $BA^{-1}C$.</div><div class="clear"></div>
<div class="linenb">1882</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1883</div><div class="codeline"><span class="keyword2">\begin{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Example] (69699) [lt:en:UPPERCASE_SENTENCE_START]"></span>example}</span></div><div class="clear"></div>
<div class="linenb">1884</div><div class="codeline">$\mathbb C^\times \equiv \{ z \in \mathbb C : |z| = 1 \}$, the collection of complex numbers with magnitude $1$</div><div class="clear"></div>
<div class="linenb">1885</div><div class="codeline">forms a Lie Group.</div><div class="clear"></div>
<div class="linenb">1886</div><div class="codeline"><span class="keyword2">\end{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Example] (69780) [lt:en:UPPERCASE_SENTENCE_START]"></span>example}</span></div><div class="clear"></div>
<div class="linenb">1887</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1888</div><div class="codeline"><span class="keyword2">\begin{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Example] (69789) [lt:en:UPPERCASE_SENTENCE_START]"></span>example}</span></div><div class="clear"></div>
<div class="linenb">1889</div><div class="codeline">$GL(n, \R)$ is the collection of all <span class="keyword1">\emph</span>{real}, invertible $n \times n$ matrices.</div><div class="clear"></div>
<div class="linenb">1890</div><div class="codeline"><span class="keyword2">\end{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Example] (69853) [lt:en:UPPERCASE_SENTENCE_START]"></span>example}</span></div><div class="clear"></div>
<div class="linenb">1891</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1892</div><div class="codeline"><span class="keyword2">\begin{<span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (69862) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]"></span>example}</span></div><div class="clear"></div>
<div class="linenb">1893</div><div class="codeline">$SO(n)$ is the collection of $n\times n$ real matrices with determinant $+1$</div><div class="clear"></div>
<div class="linenb">1894</div><div class="codeline"><span class="keyword2">\end{<span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [example., example!, example?, example:, example,, example;] (69928) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>example}</span></div><div class="clear"></div>
<div class="linenb">1895</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1896</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htb]</div><div class="clear"></div>
<div class="linenb">1897</div><div class="codeline"><span class="keyword1">\includegraphics</span>[width=0.8\textwidth]{./lie-group.pdf}</div><div class="clear"></div>
<div class="linenb">1898</div><div class="codeline"><span class="keyword1">\caption</span>{A depiction of how to imagine the Lie group $SO(3)$, the group of rotations of 3 dimensional space. The group's</div><div class="clear"></div>
<div class="linenb">1899</div><div class="codeline">elements are abstractly the gray circle. The identity rotation $I$ is denoted in pink. The tangent space at the identity $I$ is</div><div class="clear"></div>
<div class="linenb">1900</div><div class="codeline">denoted by blue; It consists of all skew symmetric matrices $S$ such that $S + S^T = 0$.  $s$ is one such skew-symmetric matrix,</div><div class="clear"></div>
<div class="linenb">1901</div><div class="codeline">which lives in the tangent space of the identity. Finally, the exponential map, which map from the lie algebra (the tangent space at the identity $I$)</div><div class="clear"></div>
<div class="linenb">1902</div><div class="codeline">to the lie group $G$ is shown as the light blue arc. The Lie group element $J \in SO(3) $ (in purple) is the exponential of the</div><div class="clear"></div>
<div class="linenb">1903</div><div class="codeline">Lie algebra element $s \in T_I(SO(3))$.}</div><div class="clear"></div>
<div class="linenb">1904</div><div class="codeline"><span class="highlight-sh" title="This figure is missing a label [sh:figref]">\</span>end{figure}</div><div class="clear"></div>
<div class="linenb">1905</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1906</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1907</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1908</div><div class="codeline"><span class="keyword1">\subsection</span>{Dot products on the Lie Group?}</div><div class="clear"></div>
<div class="linenb">1909</div><div class="codeline">We do not yet have a way to take dot-products of matrices. Naively, one might assume that given matrices</div><div class="clear"></div>
<div class="linenb">1910</div><div class="codeline">$M, N$, we could define $\langle M | N \rangle$, the dot product of $M$ and $N$ as</div><div class="clear"></div>
<div class="linenb">1911</div><div class="codeline">$\langle M | N \rangle \equiv \sum_{i, j} M[i, j] N[i, j]$. However, recall</div><div class="clear"></div>
<div class="linenb">1912</div><div class="codeline">that a dot-product must be defined on a vector space, since the dot-product must be <span class="keyword1">\emph</span>{bilinear}. It must</div><div class="clear"></div>
<div class="linenb">1913</div><div class="codeline">obey the axiom that $\langle \lambda M | N \rangle = \langle M | \lambda N \rangle = \lambda \langle M | N \rangle$</div><div class="clear"></div>
<div class="linenb">1914</div><div class="codeline">for any scalar $\lambda \in \R$. However, a Lie Group does <span class="keyword1">\emph</span>{not} come with a notion of scaling.</div><div class="clear"></div>
<div class="linenb">1915</div><div class="codeline">For example, the number $1 \in \mathbb C^\times$, but $2 \cdot 1 = 2 \not \in \mathbb C^\times$! More precisely,</div><div class="clear"></div>
<div class="linenb">1916</div><div class="codeline">we are saying that the Lie Group $G$ is not a vector space, and thus it does not make sense to impose a dot-product (inner product)</div><div class="clear"></div>
<div class="linenb">1917</div><div class="codeline">structure, since being a vector space pre-supposes the existence of a vector space structure on the Lie Group.</div><div class="clear"></div>
<div class="linenb">1918</div><div class="codeline">This is where the <span class="keyword1">\emph</span>{Lie Algebra} enters into the picture. It gives us a way to get <span class="keyword1">\emph</span>{vectors} from</div><div class="clear"></div>
<div class="linenb">1919</div><div class="codeline">Lie Group elements, such that we can take dot-products of these vectors.</div><div class="clear"></div>
<div class="linenb">1920</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1921</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1922</div><div class="codeline">\<span class="highlight-sh" title="This subsection is very short (about 119 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsection</span>{Matrix Lie Algebras}</div><div class="clear"></div>
<div class="linenb">1923</div><div class="codeline">A Matrix Lie Algebra is a way to convert group elements into vectors. Formally,</div><div class="clear"></div>
<div class="linenb">1924</div><div class="codeline">we perform this by taking a <span class="keyword1">\emph</span>{logarithm} of the group elements, where the</div><div class="clear"></div>
<div class="linenb">1925</div><div class="codeline">logarithm operation is defined by the <span class="keyword1">\emph</span>{matrix logarithm}.  It turns out to</div><div class="clear"></div>
<div class="linenb">1926</div><div class="codeline">be the case that the logarithm of a Lie Group is always a matrix vector space.</div><div class="clear"></div>
<div class="linenb">1927</div><div class="codeline">For example, going back to the example of</div><div class="clear"></div>
<div class="linenb">1928</div><div class="codeline">$\C^\times \equiv \{ z : |z| = 1 \}$,</div><div class="clear"></div>
<div class="linenb">1929</div><div class="codeline">recall that we can write all such number as $e^{i \theta}$. Thus, when we take</div><div class="clear"></div>
<div class="linenb">1930</div><div class="codeline">the logarithm, we get the set  $\{ i \theta : \theta \in \mathbb R \}$ which is</div><div class="clear"></div>
<div class="linenb">1931</div><div class="codeline">indeed a vector space, because it is closed under addition and scalar</div><div class="clear"></div>
<div class="linenb">1932</div><div class="codeline">multiplication.</div><div class="clear"></div>
<div class="linenb">1933</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1934</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1935</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 133 words). You should consider merging it with another section or make it longer. [sh:seclen]"><span class="highlight-sh" title="This section is very short (about 134 words). You should consider merging it with another section or make it longer. [sh:seclen]">section</span></span>{The generalized \texttt{word2vec} training}</div><div class="clear"></div>
<div class="linenb">1936</div><div class="codeline">We will now <span class="highlight" title="The verb 'imagining' is a stative verb and sometimes the progressive form is not correct. Try a simple form instead. (71419) [lt:en:PROGRESSIVE_VERBS]">be imagining</span> our words as <span class="keyword1">\emph</span>{elements of a lie group}. Recall that this means that</div><div class="clear"></div>
<div class="linenb">1937</div><div class="codeline">they are points in some <span class="keyword1">\emph</span>{subspace} of $\mathbb R^n$, where this subspace can be curved in shape.</div><div class="clear"></div>
<div class="linenb">1938</div><div class="codeline">Also, the elements are equipped with the notion of a logarithm; That is, they come equipped with a</div><div class="clear"></div>
<div class="linenb">1939</div><div class="codeline">function $\log : G \rightarrow \mathfrak g$, and $\exp: \mathfrak g \rightarrow G$,</div><div class="clear"></div>
<div class="linenb">1940</div><div class="codeline">where $\log$ maps from the lie group (a group) to its lie algebra (a vector space),</div><div class="clear"></div>
<div class="linenb">1941</div><div class="codeline">and vice versa for the $\exp$ map.</div><div class="clear"></div>
<div class="linenb">1942</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1943</div><div class="codeline"><span class="keyword1">\subsection</span>{Overview}</div><div class="clear"></div>
<div class="linenb">1944</div><div class="codeline">Following the discussion in the preceding section, we provide a compact</div><div class="clear"></div>
<div class="linenb">1945</div><div class="codeline">discussion of the \texttt{word2vec} training algorithm, indicating how to</div><div class="clear"></div>
<div class="linenb">1946</div><div class="codeline">substitute the original \texttt{word2vec} algorithm with its Lie Group</div><div class="clear"></div>
<div class="linenb">1947</div><div class="codeline">counterpart, as well as discussing potential linguistic ramifications of this</div><div class="clear"></div>
<div class="linenb">1948</div><div class="codeline">replacement.</div><div class="clear"></div>
<div class="linenb">1949</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1950</div><div class="codeline">\<span class="highlight-sh" title="This subsection is very short (about 80 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsection</span>{Training}</div><div class="clear"></div>
<div class="linenb">1951</div><div class="codeline">For the purposes of training, we need to describe how to perform the</div><div class="clear"></div>
<div class="linenb">1952</div><div class="codeline">dot-product to calculate the loss, as well as how to perform gradient descent</div><div class="clear"></div>
<div class="linenb">1953</div><div class="codeline">to improve the loss.</div><div class="clear"></div>
<div class="linenb">1954</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1955</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Dot Product}  To compute the dot product between two elements</div><div class="clear"></div>
<div class="linenb">1956</div><div class="codeline">$g, h \in G$, we first <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [logarithm ize] (72360) [lt:en:MORFOLOGIK_RULE_EN_GB]">logarithmize</span> them, and then take the dot product of</div><div class="clear"></div>
<div class="linenb">1957</div><div class="codeline">their logarithms, which lives in the Lie algebra.  Hence, we define the dot</div><div class="clear"></div>
<div class="linenb">1958</div><div class="codeline">product on the Lie group</div><div class="clear"></div>
<div class="linenb">1959</div><div class="codeline">$\langle \cdot , \cdot \rangle$ as $\langle g, h \rangle \equiv \log(g) \cdot \log(h)$.</div><div class="clear"></div>
<div class="linenb">1960</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1961</div><div class="codeline">\<span class="highlight-sh" title="This subsubsection is very short (about 106 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsubsection</span>{Gradients}</div><div class="clear"></div>
<div class="linenb">1962</div><div class="codeline">Next, to perform gradient descent, we need</div><div class="clear"></div>
<div class="linenb">1963</div><div class="codeline">a notion of a <span class="keyword1">\emph</span>{gradient} to decide in which direction to move, and a way to perform a gradient update.</div><div class="clear"></div>
<div class="linenb">1964</div><div class="codeline">How one performs the gradient update is explained in detail in \autoref{section:<span class="highlight-spelling" title="Possible spelling mistake found (72747) [lt:en:MORFOLOGIK_RULE_EN_GB]">optim-on-riem}</span>. Intuitively,</div><div class="clear"></div>
<div class="linenb">1965</div><div class="codeline">since all our manifolds are subspaces of $\mathbb R^n$, we first compute the gradient vector, then travel</div><div class="clear"></div>
<div class="linenb">1966</div><div class="codeline">along the gradient vector (which will take us out of the manifold), and finally ``retract back'' into the</div><div class="clear"></div>
<div class="linenb">1967</div><div class="codeline">manifold, which gives us a gradient step, starting from a point in the manifold, ending at a point in the manifold.</div><div class="clear"></div>
<div class="linenb">1968</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1969</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htb]</div><div class="clear"></div>
<div class="linenb">1970</div><div class="codeline"><span class="keyword1">\includegraphics</span>[width=0.5\textwidth]{./gradient-manifold.pdf}</div><div class="clear"></div>
<div class="linenb">1971</div><div class="codeline"><span class="keyword1">\caption</span>{gradient descent on a manifold.}</div><div class="clear"></div>
<div class="linenb">1972</div><div class="codeline"><span class="highlight-sh" title="This figure is missing a label [sh:figref]">\</span>end{figure}</div><div class="clear"></div>
<div class="linenb">1973</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1974</div><div class="codeline"><span class="comment"><span class="comment">% \todo{Differentiate sections into math basics, training, and evaluation.}</span></span></div><div class="clear"></div>
<div class="linenb">1975</div><div class="codeline">\<span class="highlight-sh" title="This subsection is very short (about 130 words). You should consider merging it with another section or make it longer. [sh:seclen]"><span class="highlight-sh" title="This subsection is very short (about 131 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsection</span></span>{Evaluation}</div><div class="clear"></div>
<div class="linenb">1976</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1977</div><div class="codeline">To perform evaluation, given the trained mapping from words to Lie Group</div><div class="clear"></div>
<div class="linenb">1978</div><div class="codeline">elements as inputs, we must be able to perform similarity and analogy to reach</div><div class="clear"></div>
<div class="linenb">1979</div><div class="codeline">the baseline of \texttt{word2vec}'s usefulness. We indicate other potential</div><div class="clear"></div>
<div class="linenb">1980</div><div class="codeline">uses of the richer structure <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [possessed] (73353) [lt:en:MORFOLOGIK_RULE_EN_GB]">posessed</span> by Lie Groups after describing the bare</div><div class="clear"></div>
<div class="linenb">1981</div><div class="codeline">minimum structure.</div><div class="clear"></div>
<div class="linenb">1982</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1983</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Similarity} We compute similarity between two words by computing</div><div class="clear"></div>
<div class="linenb">1984</div><div class="codeline">the dot product between the logarithm of the lie group elements which represent</div><div class="clear"></div>
<div class="linenb">1985</div><div class="codeline">the words. Given two word-matrices $h, h'$, we first map into their Lie Algebra</div><div class="clear"></div>
<div class="linenb">1986</div><div class="codeline">via $\log(h), \log(h')$. This is now the Lie Algebra, which is an inner product <span class="highlight" title="Use a comma before 'so' if it connects two independent clauses (unless they are closely connected and short).. Suggestions: [space, so] (73702) [lt:en:COMMA_COMPOUND_SENTENCE]">space so</span> we then</div><div class="clear"></div>
<div class="linenb">1987</div><div class="codeline">take the dot product $\log(h) \cdot \log(h')$. Linguistically, we are reducing a word</div><div class="clear"></div>
<div class="linenb">1988</div><div class="codeline">to its infinitesimal components, before comparing the words along these infinitesimal</div><div class="clear"></div>
<div class="linenb">1989</div><div class="codeline">senses of meaning.</div><div class="clear"></div>
<div class="linenb">1990</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1991</div><div class="codeline">\todo{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Plus, PCs, PLC, Pas, Ply, TLS, PMS, Pals, Pus, PS, PFS, PLO, PLP, POS, PPS, Pils, Ls, pHs, Pl, Plc, P ls, Pl s] (73888) [lt:en:MORFOLOGIK_RULE_EN_GB]">Pls</span> detail <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [CD, HD, SD, id, MD, 1D, 2D, 3D, 4D, D, Ed, ID, Nd, OD, RD, Rd, VD, X, XL, XP, Xi, Xu, ad, d, ed, pd, x, xi, xv, xx, yd, x D] (73899) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>xD}</div><div class="clear"></div>
<div class="linenb">1992</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1993</div><div class="codeline">\<span class="highlight-sh" title="This subsubsection is very short (about 47 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsubsection</span>{Analogy} To compute the analogy $a:b::c:?$, we generalize the vectorial</div><div class="clear"></div>
<div class="linenb">1994</div><div class="codeline">$b - a + c$  into $b \cdot a^{-1} \cdot c$. Linguistically, this provides the same</div><div class="clear"></div>
<div class="linenb">1995</div><div class="codeline">notion of analogy as \texttt{word2vec} does, since we are performing a similar operation</div><div class="clear"></div>
<div class="linenb">1996</div><div class="codeline">of cancelling the meaning of $a$ and adding the meaning of $c$ to a base word $b$.</div><div class="clear"></div>
<div class="linenb">1997</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">1998</div><div class="codeline">\<span class="highlight-sh" title="This subsection is very short (about 149 words). You should consider merging it with another section or make it longer. [sh:seclen]"><span class="highlight-sh" title="This subsection is very short (about 149 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsection</span></span>{Sense <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [difference., difference!, difference?, difference:, difference,, difference;] (74179) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>difference}</div><div class="clear"></div>
<div class="linenb">1999</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2000</div><div class="codeline">Recall that for an arbitrary Lie group, the group operation <span class="keyword1">\emph</span>{need not be</div><div class="clear"></div>
<div class="linenb">2001</div><div class="codeline">commutative}. This is in start contrast to the \texttt{word2vec} case, where <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [a, MA, ma, pa, ta, da, A, AA, BA, Ba, CA, Ca, Ga, IA, La, Na, Oa, QA, Qa, Ra, SA, Sa, Ta, WA, ba, ca, ea, fa, ha, ka, la, mA, na, ya, à] (74330) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>$a</div><div class="clear"></div>
<div class="linenb">2002</div><div class="codeline">+ b = b + <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [a, as, at, an, am, ah, A, AA, AC, AI, AK, AV, Ab, Ac, Ag, Al, At, ab, ad, ap, au, à] (74343) [lt:en:MORFOLOGIK_RULE_EN_GB]">a$</span> holds for all vectors. This non-commutativity allows one to define</div><div class="clear"></div>
<div class="linenb">2003</div><div class="codeline">the <span class="keyword1">\emph</span>{commutator} of two elements, $[a, b] \equiv aba^{-1}b^{-1}$, which</div><div class="clear"></div>
<div class="linenb">2004</div><div class="codeline">measures how much $a$ and $b$ fail to commute. If the commutator is the</div><div class="clear"></div>
<div class="linenb">2005</div><div class="codeline">identity element of the group, that is, if $[a, b] = 0$, then the two elements</div><div class="clear"></div>
<div class="linenb">2006</div><div class="codeline">commute, since $[a, b] = aba^{-1}b^{-1} = baa^{-1}b^{-1} = bb^{-1} = e$.  On</div><div class="clear"></div>
<div class="linenb">2007</div><div class="codeline">the other hand, if $a$ and $b$ do not commute, then the commutator $[a, b]$ is</div><div class="clear"></div>
<div class="linenb">2008</div><div class="codeline">a non-trivial element of the group. Linguistically speaking, the commutator of</div><div class="clear"></div>
<div class="linenb">2009</div><div class="codeline">two words $[v, w]$ gives us a new word which measures by how much the senses of</div><div class="clear"></div>
<div class="linenb">2010</div><div class="codeline">$v$ and $w$ fail to commute.</div><div class="clear"></div>
<div class="linenb">2011</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2012</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2013</div><div class="codeline">\todo{<span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [Elaboration] (74859) [lt:en:UPPERCASE_SENTENCE_START]"></span>elaboration}</div><div class="clear"></div>
<div class="linenb">2014</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2015</div><div class="codeline"><span class="keyword1">\section</span>{Formalism}</div><div class="clear"></div>
<div class="linenb">2016</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2017</div><div class="codeline">\<span class="highlight-sh" title="Avoid stacked headings, i.e. consecutive headings without text in between. [sh:stacked]">subsection</span>{Riemannian <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Manifold., Manifold!, Manifold?, Manifold:, Manifold,, Manifold;] (74894) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>Manifold}</div><div class="clear"></div>
<div class="linenb">2018</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2019</div><div class="codeline">A Riemannian manifold $M$ of dimension $k$ <span class="keyword1">\emph</span>{embedded} in a space of</div><div class="clear"></div>
<div class="linenb">2020</div><div class="codeline">dimension $n$ is, intuitively, a surface with $k$-degrees of freedom, which has</div><div class="clear"></div>
<div class="linenb">2021</div><div class="codeline">been embedded in $\R^n$.  For example, a circle has one degree of freedom, the angle $\theta$.</div><div class="clear"></div>
<div class="linenb">2022</div><div class="codeline">This can be embedded in 2D space $\mathbb R^2$ via the map $\theta \mapsto (\cos \theta, \sin \theta)$.</div><div class="clear"></div>
<div class="linenb">2023</div><div class="codeline">Similarly, the sphere has two <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [degree, degrees] (75205) [lt:en:MORFOLOGIK_RULE_EN_GB]">degres</span> of freedom, the azimuthal angle $\theta$ and the angle</div><div class="clear"></div>
<div class="linenb">2024</div><div class="codeline">at the azimuth $\phi$, and can be mapped into 3D via the map</div><div class="clear"></div>
<div class="linenb">2025</div><div class="codeline">$(\theta, \phi) \mapsto (\cos \theta \cos \phi, \cos \theta \sin \phi, \sin \theta)$.</div><div class="clear"></div>
<div class="linenb">2026</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2027</div><div class="codeline">Here, we assume that the reader is familiar with basic point-set topology \cite{munkres2014topology}.</div><div class="clear"></div>
<div class="linenb">2028</div><div class="codeline">Formally, the Riemannian manifold of dimension $k$ embedded in a space of dimension $N$</div><div class="clear"></div>
<div class="linenb">2029</div><div class="codeline">is a subset $M \subseteq \R^N$ such that for each $p \in M$,</div><div class="clear"></div>
<div class="linenb">2030</div><div class="codeline">there exists an open set $C \subseteq R^k$ (of parameters), and <span class="highlight" title="Maybe you need to remove one determiner so that only 'an' or 'an' is left.. Suggestions: [an] (75567) [lt:en:DT_DT]">a</span>n</div><div class="clear"></div>
<div class="linenb">2031</div><div class="codeline">an open neighbourhood $O \subseteq \mathbb R^n$ of $p$ (a local <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [parametrization] (75608) [lt:en:MORFOLOGIK_RULE_EN_GB]">parmetrization</span> of $M$ around $p$),</div><div class="clear"></div>
<div class="linenb">2032</div><div class="codeline">and an onto map $x: C \rightarrow O \cap M$ (of coordinates), such that (1) $x$ is differentiable,</div><div class="clear"></div>
<div class="linenb">2033</div><div class="codeline">(2) $x$ has a differentiable inverse, and (3) the <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Jacobian, Jacobean, Jacobin] (75758) [lt:en:MORFOLOGIK_RULE_EN_GB]">jacobian</span> of $x$ is one-to-one.</div><div class="clear"></div>
<div class="linenb">2034</div><div class="codeline">\footnote{We provide the extrinsic definition of a Riemannian manifold as a</div><div class="clear"></div>
<div class="linenb">2035</div><div class="codeline">subspace of $\mathbb R^n$.  A definition without reference to the embedding</div><div class="clear"></div>
<div class="linenb">2036</div><div class="codeline">space is an intrinsic definition, which is provided in standard texts, such as</div><div class="clear"></div>
<div class="linenb">2037</div><div class="codeline">Lee's introduction to smooth <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [manifolds., manifolds!, manifolds?, manifolds:, manifolds,, manifolds;] (76025) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>manifolds}</div><div class="clear"></div>
<div class="linenb">2038</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2039</div><div class="codeline">Intuitively, a Riemannian manifold allows us to assign <span class="highlight" title="Do not mix variants of the same word ('co-ordinate' and 'coordinate') within a single text.. Suggestions: [coordinate] (76091) [lt:en:EN_WORD_COHERENCY]">co-ordinates</span> at each</div><div class="clear"></div>
<div class="linenb">2040</div><div class="codeline">local region of the manifold which looks like $\R^N$. For example, the Earth in</div><div class="clear"></div>
<div class="linenb">2041</div><div class="codeline">total is curved, since it is a sphere. However, around each of us, it is</div><div class="clear"></div>
<div class="linenb">2042</div><div class="codeline">approximated by a plane, since the Earth appears flat around a small region.</div><div class="clear"></div>
<div class="linenb">2043</div><div class="codeline">Thus, we can continue to use the differential calculus that we know and love to</div><div class="clear"></div>
<div class="linenb">2044</div><div class="codeline">compute gradients on a Riemannian manifold, which we will use to perform gradient</div><div class="clear"></div>
<div class="linenb">2045</div><div class="codeline">descent on curved spaces.</div><div class="clear"></div>
<div class="linenb">2046</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2047</div><div class="codeline"><span class="keyword1">\subsection</span>{Tangent space}</div><div class="clear"></div>
<div class="linenb">2048</div><div class="codeline">On every manifold, at each point, we have a <span class="keyword1">\emph</span>{tangent space}, which</div><div class="clear"></div>
<div class="linenb">2049</div><div class="codeline">represents the space of possible directions we can move on the space at that</div><div class="clear"></div>
<div class="linenb">2050</div><div class="codeline">point. For example, at each point on a circle, we can define a velocity that is</div><div class="clear"></div>
<div class="linenb">2051</div><div class="codeline">tangential to the circle. See that this space that is tangential is <span class="keyword1">\emph</span>{one dimensional},</div><div class="clear"></div>
<div class="linenb">2052</div><div class="codeline">even though the circle is itself two-dimensional. The gradient of a function at a point is a</div><div class="clear"></div>
<div class="linenb">2053</div><div class="codeline">vector which lives in the tangent space a point.</div><div class="clear"></div>
<div class="linenb">2054</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2055</div><div class="codeline"><span class="keyword1">\subsection</span>{Lie groups}</div><div class="clear"></div>
<div class="linenb">2056</div><div class="codeline">A lie group is a Riemannian manifold $M$ which is also a group, whose group</div><div class="clear"></div>
<div class="linenb">2057</div><div class="codeline">structure is compatible with the manifold structure. This means that we have</div><div class="clear"></div>
<div class="linenb">2058</div><div class="codeline">an associative <span class="keyword1">\emph</span>{group operation} $*: M \times M \rightarrow M$, which comes with an</div><div class="clear"></div>
<div class="linenb">2059</div><div class="codeline">inverse $(\cdot)^{-1} : M \rightarrow M$, and an identity $e \in M$ such that the group operation $*$</div><div class="clear"></div>
<div class="linenb">2060</div><div class="codeline">and the inverse $(\cdot)^{-1}$ are continuous with respect to the inherited</div><div class="clear"></div>
<div class="linenb">2061</div><div class="codeline">subspace topology on $M$.</div><div class="clear"></div>
<div class="linenb">2062</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2063</div><div class="codeline">Intuitively, this gives us the operations (1) $v \cdot w \simeq v + w$ to add</div><div class="clear"></div>
<div class="linenb">2064</div><div class="codeline">vectors, (2)  $(v)^{-1} \simeq -v$ to invert a vector, and (3) $v \cdot w^{-1} \simeq v - w$</div><div class="clear"></div>
<div class="linenb">2065</div><div class="codeline">to subtract vectors. This allows us to generalize analogy to curved spaces, by using</div><div class="clear"></div>
<div class="linenb">2066</div><div class="codeline">lie group operations to perform analogy.</div><div class="clear"></div>
<div class="linenb">2067</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2068</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2069</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2070</div><div class="codeline"><span class="keyword1">\subsection</span>{Lie <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Algebras] (77589) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>Algberas}</div><div class="clear"></div>
<div class="linenb">2071</div><div class="codeline">The Lie algebra of a Lie group is the <span class="keyword1">\emph</span>{tangent space} of the Lie group</div><div class="clear"></div>
<div class="linenb">2072</div><div class="codeline"><span class="keyword1">\emph</span>{at} the identity element. Informally, the idea is that while the Lie group is a</div><div class="clear"></div>
<div class="linenb">2073</div><div class="codeline">``non-linear'' object, the tangent space represents tangents / ``<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [linearisation] (77811) [lt:en:MORFOLOGIK_RULE_EN_GB]">linearizations</span>'' of the group.</div><div class="clear"></div>
<div class="linenb">2074</div><div class="codeline">Moreover, in a group, given a tangent vector at the identity, we can <span class="keyword1">\emph</span>{exponentiate} this</div><div class="clear"></div>
<div class="linenb">2075</div><div class="codeline">tangent vector to get a Lie group element.</div><div class="clear"></div>
<div class="linenb">2076</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2077</div><div class="codeline">For example, we consider the Lie group of complex numbers of unit norm,</div><div class="clear"></div>
<div class="linenb">2078</div><div class="codeline"><span class="highlight" title="Replace by the typographical symbol.. Suggestions: [×, ·] (78045) [lt:en:MULTIPLICATION_SIGN]">$G \equiv \C^\times = \{ z \in \C : |z| = 1 \}$</span>. The Lie algebra corresponding to $G$, denoted</div><div class="clear"></div>
<div class="linenb">2079</div><div class="codeline">by $\mathfrak g$ are the real numbers $\mathfrak g = \mathbb R$. We can <span class="keyword1">\emph</span>{exponentiate}</div><div class="clear"></div>
<div class="linenb">2080</div><div class="codeline">a real number via the map $\exp : \mathfrak g \rightarrow G$, <span class="highlight" title="Replace by the typographical symbol.. Suggestions: [×, ·] (78170) [lt:en:MULTIPLICATION_SIGN]">$\exp(r) \equiv e^{i r}$</span>. Similarly,</div><div class="clear"></div>
<div class="linenb">2081</div><div class="codeline">we have a logarithm map $\log: G \rightarrow \mathfrak g$, which takes any</div><div class="clear"></div>
<div class="linenb">2082</div><div class="codeline">element $z \in \C^\times$, and produces a real number $\log(z) \equiv arg(z)$.</div><div class="clear"></div>
<div class="linenb">2083</div><div class="codeline">Notice that the space $\mathfrak g = \mathbb R$ is a real vector space, since it contains an</div><div class="clear"></div>
<div class="linenb">2084</div><div class="codeline">additive identity $0$, while the space $G = C^\times$ is not a real vector space, since it</div><div class="clear"></div>
<div class="linenb">2085</div><div class="codeline">is not closed under scaling by <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [real, deals, meals, reads, realm, realms, seals, reels, heals, rears, peals, reams, reaps, rials, teals, weals, Zeals, real s] (78444) [lt:en:MORFOLOGIK_RULE_EN_GB]">reals</span>.</div><div class="clear"></div>
<div class="linenb">2086</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2087</div><div class="codeline">For a more non-trivial example, we consider the space of all rotations in 3D. These are given</div><div class="clear"></div>
<div class="linenb">2088</div><div class="codeline">by the orthogonal matrices $SO(3) \equiv \{ O : O O ^T = I \}$. We will not derive the Lie algebra</div><div class="clear"></div>
<div class="linenb">2089</div><div class="codeline">space formally, which can be found <span class="highlight-sh" title="Do not use 'in [X]': the syntax of a sentence should not be changed by the removal of a citation. [sh:c:noin]">in \cite{</span>absil2009optimisation} \footnote{A derivation of the tangent space of $SO(n)$</div><div class="clear"></div>
<div class="linenb">2090</div><div class="codeline">performed by the author can be found at \url{https://math.stackexchange.com/questions/3389983/explicit-description-of-tangent-spaces-of-on}}.</div><div class="clear"></div>
<div class="linenb">2091</div><div class="codeline">Informally, the idea is that the Lie algebra represents a <span class="highlight-spelling" title="Possible spelling mistake found (78793) [lt:en:MORFOLOGIK_RULE_EN_GB]">logarithmization</span> of the tangent space. Thus,</div><div class="clear"></div>
<div class="linenb">2092</div><div class="codeline">we must compute $\log(SO(3)) = \{ \log(O): \log(O O^T) = \log(I) \}$. This leads to the calculation:</div><div class="clear"></div>
<div class="linenb">2093</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2094</div><div class="codeline"><span class="keyword2">\begin{align*}</span></div><div class="clear"></div>
<div class="linenb">2095</div><div class="codeline">&amp;\log(SO(3)) = \{ \log(O): \log(O O^T) = \log(I) \} \\</div><div class="clear"></div>
<div class="linenb">2096</div><div class="codeline">&amp;\log(SO(3)) = \{ \log(O): \log(O) + \log(O^T) = \log(I) \} \\</div><div class="clear"></div>
<div class="linenb">2097</div><div class="codeline">&amp;\log(SO(3)) = \{ \log(O): \log(O) + \log(O)^T = \log(I) \} \\</div><div class="clear"></div>
<div class="linenb">2098</div><div class="codeline">&amp;\log(SO(3)) = \{ \log(O): \log(O) + \log(O)^T = 0 \} \\</div><div class="clear"></div>
<div class="linenb">2099</div><div class="codeline">&amp;\skewsym = \{ Z: Z + Z^T = 0 \} \\</div><div class="clear"></div>
<div class="linenb">2100</div><div class="codeline"><span class="keyword2">\end{align*}</span></div><div class="clear"></div>
<div class="linenb">2101</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2102</div><div class="codeline">Thus, the tangent space of $SO(3)$ is the space $\skewsym$ of skew-symmetric matrices. Notice that skew symmetric</div><div class="clear"></div>
<div class="linenb">2103</div><div class="codeline">matrices form a vector space, since the sum of two skew symmetric matrices is skew-symmetric, and skew-symmetric</div><div class="clear"></div>
<div class="linenb">2104</div><div class="codeline">matrices are closed under scaling by the real numbers. On the other hand, $SO(3)$ is not a vector space; For example,</div><div class="clear"></div>
<div class="linenb">2105</div><div class="codeline">the element $I \in SO(3)$ as $I I^T = I$. On the other hand, consider $J \equiv 2I$. We have</div><div class="clear"></div>
<div class="linenb">2106</div><div class="codeline">$J J^T = 4I \neq I$. Thus $SO(3)$ is not closed under scaling by <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [real, deals, meals, reads, realm, realms, seals, reels, heals, rears, peals, reams, reaps, rials, teals, weals, Zeals, real s] (79314) [lt:en:MORFOLOGIK_RULE_EN_GB]">reals</span>, and is thus not a vector space. Hence,</div><div class="clear"></div>
<div class="linenb">2107</div><div class="codeline">we see that even in this case, the Lie group is not a vector space, while the Lie algebra is a vector space.</div><div class="clear"></div>
<div class="linenb">2108</div><div class="codeline">Philosophically, skew-symmetric <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [matrices] (79501) [lt:en:MORFOLOGIK_RULE_EN_GB]">matrcies</span> correspond to angular momenta, which are indeed the ``velocities''</div><div class="clear"></div>
<div class="linenb">2109</div><div class="codeline">of a rotation.</div><div class="clear"></div>
<div class="linenb">2110</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2111</div><div class="codeline">\todo{For each section, also add linguistic corollaries. This will make it a bit</div><div class="clear"></div>
<div class="linenb">2112</div><div class="codeline">  easier to digest the transition from dense <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [match, path, mate, myth, oath, bath, maths, hath, mat, mats, moth, Mach, Meath, mash, lath, matt, Bath, Kath, Mata, Rath, Wath, ath, mah, maty, meth, m ath, mat h] (79713) [lt:en:MORFOLOGIK_RULE_EN_GB]">math</span> topic to dense <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [match, path, mate, myth, oath, bath, maths, hath, mat, mats, moth, Mach, Meath, mash, lath, matt, Bath, Kath, Mata, Rath, Wath, ath, mah, maty, meth, m ath, mat h] (79733) [lt:en:MORFOLOGIK_RULE_EN_GB]">math</span> <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [topic., topic!, topic?, topic:, topic,, topic;] (79738) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>topic}</div><div class="clear"></div>
<div class="linenb">2113</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2114</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2115</div><div class="codeline"><span class="keyword1">\subsection</span>{<span class="highlight" title="In British English, for some nouns, both ~s and ~z spellings are possible. By default, the rule for Oxford spelling is on for nouns and thus suggests 'Optimization'.. Suggestions: [Optimization] (79746) [lt:en:OXFORD_SPELLING_NOUNS]">Optimisation</span> on Riemannian Manifolds}</div><div class="clear"></div>
<div class="linenb">2116</div><div class="codeline"><span class="keyword1">\label</span>{section:optim-on-riem}.</div><div class="clear"></div>
<div class="linenb">2117</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2118</div><div class="codeline"><span class="comment"><span class="comment">% \todo{introduce the need: ML algorithms and all that. @Alok: can you do this? I'm not sure what I ought to write...}</span></span></div><div class="clear"></div>
<div class="linenb">2119</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2120</div><div class="codeline">The eventual goal of the \texttt{word2vec} training regime is to <span class="highlight" title="In British English, for some verbs, both ~s and ~z spellings are possible. By default, the rule for Oxford spelling is on for verbs and thus suggests 'minimize'.. Suggestions: [minimize] (79843) [lt:en:OXFORD_SPELLING_ISE_VERBS]">minimise</span> the loss function which attempts</div><div class="clear"></div>
<div class="linenb">2121</div><div class="codeline">to align word vectors of words <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [occurring, occur ing] (79916) [lt:en:MORFOLOGIK_RULE_EN_GB]">occuring</span> in similar contexts, as per the distribution hypothesis. Classical \texttt{word2vec}</div><div class="clear"></div>
<div class="linenb">2122</div><div class="codeline">uses gradient descent to <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [mi mise] (80026) [lt:en:MORFOLOGIK_RULE_EN_GB]">mimise</span> this loss function, as it is computationally cheap, and has good theoretical</div><div class="clear"></div>
<div class="linenb">2123</div><div class="codeline">guarantees of being able to find local minima. Hence, we propose to use <span class="keyword1">\emph</span>{Riemannian gradient descent}, an analogue</div><div class="clear"></div>
<div class="linenb">2124</div><div class="codeline">of gradient descent which enables the minimization of a loss function</div><div class="clear"></div>
<div class="linenb">2125</div><div class="codeline">for arbitrary Riemannian manifolds, and in particular, for loss functions over Lie Groups.</div><div class="clear"></div>
<div class="linenb">2126</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2127</div><div class="codeline">We now consider manifold <span class="highlight" title="In British English, for some nouns, both ~s and ~z spellings are possible. By default, the rule for Oxford spelling is on for nouns and thus suggests 'optimization'.. Suggestions: [optimization] (80410) [lt:en:OXFORD_SPELLING_NOUNS]">optimisation</span> techniques on embedded <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Riemannian] (80446) [lt:en:MORFOLOGIK_RULE_EN_GB]">riemannian</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [manifolds] (80457) [lt:en:MORFOLOGIK_RULE_EN_GB]">manfiolds</span> $M$,</div><div class="clear"></div>
<div class="linenb">2128</div><div class="codeline">equipped with the metric $g: (p: M) \rightarrow T_p M  \times T_p M \rightarrow \mathbb R$.</div><div class="clear"></div>
<div class="linenb">2129</div><div class="codeline">The metric at a point $g(p)$ provides an inner product structure on the point $T_pM$</div><div class="clear"></div>
<div class="linenb">2130</div><div class="codeline">for <span class="highlight" title="Use 'an' instead of 'a' if the following word starts with a vowel sound, e.g. 'an article', 'an hour'. Suggestions: [an] (80577) [lt:en:EN_A_VS_AN]">a</span> <span class="highlight" title="Replace by the typographical symbol.. Suggestions: [×, ·] (80579) [lt:en:MULTIPLICATION_SIGN]">$p \in M$</span>.</div><div class="clear"></div>
<div class="linenb">2131</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2132</div><div class="codeline"><span class="highlight" title="“where” at the beginning of a sentence usually requires a 2nd clause. Maybe a comma, question or exclamation mark is missing, or the sentence is incomplete and should be joined with the following sentence. (80583) [lt:en:SENTENCE_FRAGMENT]">where</span> we are <span class="highlight" title="Do not mix variants of the same word ('optimise' and 'optimize') within a single text.. Suggestions: [optimize] (80596) [lt:en:EN_WORD_COHERENCY]">optimising</span> a cost function $c: M \rightarrow \mathbb R$.</div><div class="clear"></div>
<div class="linenb">2133</div><div class="codeline">We presume that we have a diffeomorphism $E: M \rightarrow \mathbb R^n$ (Embedding) which</div><div class="clear"></div>
<div class="linenb">2134</div><div class="codeline">preserves the metric structure. We will elucidate this notion of preserving</div><div class="clear"></div>
<div class="linenb">2135</div><div class="codeline">the metric structure once we formally define the mapping between tangent spaces.</div><div class="clear"></div>
<div class="linenb">2136</div><div class="codeline">This allows us to treat $M$ as a subspace of $\mathbb R^n$.</div><div class="clear"></div>
<div class="linenb">2137</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2138</div><div class="codeline">For any object $X$</div><div class="clear"></div>
<div class="linenb">2139</div><div class="codeline">defined with respect to the manifold, we define a new object $\overline X$, which</div><div class="clear"></div>
<div class="linenb">2140</div><div class="codeline">is the embedded version of $X$ in $\mathbb R^n$.</div><div class="clear"></div>
<div class="linenb">2141</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2142</div><div class="codeline">We define $\overline M \subset \mathbb R^n; \overline M \equiv image(E)$.</div><div class="clear"></div>
<div class="linenb">2143</div><div class="codeline">We define $\overline c: \overline M \subseteq \mathbb R^n \rightarrow \mathbb R; \overline c \equiv c \circ E^{-1}$</div><div class="clear"></div>
<div class="linenb">2144</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2145</div><div class="codeline">We then <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [need, needs, needy, needn, need h] (81048) [lt:en:MORFOLOGIK_RULE_EN_GB]">needh</span> two operators, that allows us to project onto the tangent space</div><div class="clear"></div>
<div class="linenb">2146</div><div class="codeline">and the normal space. The tangent space at a point $x_0 \in M$, <span class="highlight" title="Replace by the typographical symbol.. Suggestions: [×, ·] (81172) [lt:en:MULTIPLICATION_SIGN]">$\overline{T_{x_0} M} \equiv span(\partial_i E |_{E(x_0)})$</span>.</div><div class="clear"></div>
<div class="linenb">2147</div><div class="codeline">We get an induced mapping of tangent spaces $dE: T_{x_0} M$ and $T_{x_0} \overline M$.</div><div class="clear"></div>
<div class="linenb">2148</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2149</div><div class="codeline"><span class="highlight" title="This sentence does not start with an uppercase letter. Suggestions: [We] (81229) [lt:en:UPPERCASE_SENTENCE_START]">we</span> consider the gradient</div><div class="clear"></div>
<div class="linenb">2150</div><div class="codeline">$\overline \grad c : (p: \overline M) \rightarrow \overline{T_p M}; \overline \grad c \equiv dE \overline dc$</div><div class="clear"></div>
<div class="linenb">2151</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2152</div><div class="codeline">The normal space,</div><div class="clear"></div>
<div class="linenb">2153</div><div class="codeline">$\overline{N_{x_0} M}$ is the orthogonal complement of the tangent space, defined</div><div class="clear"></div>
<div class="linenb">2154</div><div class="codeline">as $\overline{N_{x_0} M} \equiv \left\{ v \in \mathbb R^n \mid \langle v | \overline{T_{x_0} M} \rangle = 0 \right\}$.</div><div class="clear"></div>
<div class="linenb">2155</div><div class="codeline">It is often very easy to derive the projection onto the normal space, from</div><div class="clear"></div>
<div class="linenb">2156</div><div class="codeline">whose orthogonal complement we derive the projection of the tangent space.</div><div class="clear"></div>
<div class="linenb">2157</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2158</div><div class="codeline">The final piece that we require is a retraction $R: \mathbb R^n \rightarrow \overline M \subseteq \mathbb R^n$. This allows</div><div class="clear"></div>
<div class="linenb">2159</div><div class="codeline">us to project elements of the ambient space that are not on the manifold. <span class="highlight" title="Three successive sentences begin with the same word. Consider rewording the sentence or use a thesaurus to find a synonym. (81630) [lt:en:ENGLISH_WORD_REPEAT_BEGINNING_RULE]"></span>The</div><div class="clear"></div>
<div class="linenb">2160</div><div class="codeline">retraction must obey the property $R(p \in \overline M) = p$.</div><div class="clear"></div>
<div class="linenb">2161</div><div class="codeline"><span class="comment"><span class="comment">% (TODO: is this correct? Do we need $R(\overline M) = \overline M$ or is this pointwise?)</span></span></div><div class="clear"></div>
<div class="linenb">2162</div><div class="codeline"><span class="comment"><span class="comment">% (what are the other conditions on the retraction? smoothness?)</span></span></div><div class="clear"></div>
<div class="linenb">2163</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2164</div><div class="codeline">Given all of this machinery, the algorithm is indeed quite simple.</div><div class="clear"></div>
<div class="linenb">2165</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2166</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">2167</div><div class="codeline">	<span class="keyword1">\item</span> $x \in \overline M \subseteq \mathbb R^n$ is the current point on the manifold as an element of $\mathbb R^n$</div><div class="clear"></div>
<div class="linenb">2168</div><div class="codeline">	<span class="keyword1">\item</span> Compute $g = \grad c(x) \in T_x \mathbb R^n$ is the gradient with respect to $\mathbb R^n$.</div><div class="clear"></div>
<div class="linenb">2169</div><div class="codeline">	<span class="keyword1">\item</span> $\overline g = P_{T_x} g \in T_x M$ is the projection of the gradient with respect to $\mathbb R^n$ onto the</div><div class="clear"></div>
<div class="linenb">2170</div><div class="codeline">	tangent space of the manifold.</div><div class="clear"></div>
<div class="linenb">2171</div><div class="codeline">	<span class="keyword1">\item</span> $x_{mid}\in \mathbb R^n \equiv x + \eta \overline g$, a motion along the tangent vector, giving a point in</div><div class="clear"></div>
<div class="linenb">2172</div><div class="codeline">	$\mathbb R^n$.</div><div class="clear"></div>
<div class="linenb">2173</div><div class="codeline">	<span class="keyword1">\item</span> $\overline x_{next}: \overline M \equiv R(x_{mid})$, the retraction of the motion along the tangent vector,</div><div class="clear"></div>
<div class="linenb">2174</div><div class="codeline">	giving a point on the manifold $\overline M$.</div><div class="clear"></div>
<div class="linenb">2175</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">2176</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2177</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2178</div><div class="codeline">We point out that this algorithm, when specialized to $\mathbb R^n$ as a Lie</div><div class="clear"></div>
<div class="linenb">2179</div><div class="codeline">group recovers the fuzzy set representation, where we perform similarity and</div><div class="clear"></div>
<div class="linenb">2180</div><div class="codeline">analogy on the <span class="keyword1">\emph</span>{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [logarithmic] (82257) [lt:en:MORFOLOGIK_RULE_EN_GB]">logarithmized</span> inputs}, which we interpreted as treating</div><div class="clear"></div>
<div class="linenb">2181</div><div class="codeline">\texttt{word2vec} vectors as fuzzy sets. We leave the experimentation on more</div><div class="clear"></div>
<div class="linenb">2182</div><div class="codeline">exotic manifolds as open for future work.</div><div class="clear"></div>
<div class="linenb">2183</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2184</div><div class="codeline"><span class="comment"><span class="comment">%--------------------------------------------------------</span></span></div><div class="clear"></div>
<div class="linenb">2185</div><div class="codeline"><span class="comment"><span class="comment">%%% Optional appendix</span></span></div><div class="clear"></div>
<div class="linenb">2186</div><div class="codeline"><span class="comment"><span class="comment">%\appendix</span></span></div><div class="clear"></div>
<div class="linenb">2187</div><div class="codeline"><span class="comment"><span class="comment">%\chapter{}</span></span></div><div class="clear"></div>
<div class="linenb">2188</div><div class="codeline"><span class="comment"><span class="comment">%<span class="keyword1">\label</span>{}</span></span></div><div class="clear"></div>
<div class="linenb">2189</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2190</div><div class="codeline">\chapter{Conclusion and Future <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Work., Work!, Work?, Work:, Work,, Work;] (82447) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>Work}</div><div class="clear"></div>
<div class="linenb">2191</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2192</div><div class="codeline">\epigraph{A good proof is one that makes us<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> wiser.}{<span class="highlight" title="Add a space between sentences. Suggestions: [ Yuri] (82493) [lt:en:SENTENCE_WHITESPACE]">Yu</span>ri</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Main, Mann, Mani, Marin, Mania, Manic, Man in, Mani n] (82498) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>Manin}</div><div class="clear"></div>
<div class="linenb">2193</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2194</div><div class="codeline">In this thesis, we focus on <span class="keyword1">\emph</span>{empirical study} to provide</div><div class="clear"></div>
<div class="linenb">2195</div><div class="codeline"><span class="keyword1">\emph</span>{mathematical} formalisms for word embeddings. Towards this goal, we</div><div class="clear"></div>
<div class="linenb">2196</div><div class="codeline">provide two directions of research: One based on the linguistic theory of</div><div class="clear"></div>
<div class="linenb">2197</div><div class="codeline">Montague semantics, which we link to the formal theory of abstract</div><div class="clear"></div>
<div class="linenb">2198</div><div class="codeline">interpretation, from which we produce fuzzy set representations. These fuzzy</div><div class="clear"></div>
<div class="linenb">2199</div><div class="codeline">embeddings are extracted from standard word embeddings, and provide access to</div><div class="clear"></div>
<div class="linenb">2200</div><div class="codeline">set theoretic and probabilistic operations on word embeddings. This exhibits</div><div class="clear"></div>
<div class="linenb">2201</div><div class="codeline">our conjecture that word embeddings are in fact capturing <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Montague] (83058) [lt:en:MORFOLOGIK_RULE_EN_GB]">montagueian</span> based</div><div class="clear"></div>
<div class="linenb">2202</div><div class="codeline">semantics. The second prong of our research is purely mathematical, where we</div><div class="clear"></div>
<div class="linenb">2203</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake. 'analyze' is American English.. Suggestions: [analyse] (83153) [lt:en:MORFOLOGIK_RULE_EN_GB]">analyze</span> the conflation of various ideas in classical word embeddings, and</div><div class="clear"></div>
<div class="linenb">2204</div><div class="codeline">dis-entangle these ideas to provide a framework for generating word embeddings</div><div class="clear"></div>
<div class="linenb">2205</div><div class="codeline">over Lie groups.  We see that our generalization provides a cleaner framework</div><div class="clear"></div>
<div class="linenb">2206</div><div class="codeline">to <span class="keyword1">\emph</span>{think} about word embeddings, where we provide separate mathematical</div><div class="clear"></div>
<div class="linenb">2207</div><div class="codeline">objects that captures notions of similarity, analogy, meaning distance, and</div><div class="clear"></div>
<div class="linenb">2208</div><div class="codeline">meaning interpolation.  Our hope is that this framework also bakes in inductive</div><div class="clear"></div>
<div class="linenb">2209</div><div class="codeline">biases into our machine learning to better learn complex representations for larger</div><div class="clear"></div>
<div class="linenb">2210</div><div class="codeline">language units such as phrases and sentences.</div><div class="clear"></div>
<div class="linenb">2211</div><div class="codeline">For the future, we envision lines of research which</div><div class="clear"></div>
<div class="linenb">2212</div><div class="codeline">exploits other geometric structures <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [possessed] (83829) [lt:en:MORFOLOGIK_RULE_EN_GB]">posessed</span> by the manifold, including notions</div><div class="clear"></div>
<div class="linenb">2213</div><div class="codeline">of <span class="keyword1">\emph</span>{parallel transport}, which provide a notion of interpolation of word</div><div class="clear"></div>
<div class="linenb">2214</div><div class="codeline">meaning. Furthermore, we wish to adapt results from PAC learning --- in</div><div class="clear"></div>
<div class="linenb">2215</div><div class="codeline">particular the contrastive losses \cite{arora2019theoretical} to our</div><div class="clear"></div>
<div class="linenb">2216</div><div class="codeline">generalized setting of Lie groups.  In closing, I hope this thesis has given</div><div class="clear"></div>
<div class="linenb">2217</div><div class="codeline">you, the reader, a glimpse into pretty mathematical abstractions, reified by</div><div class="clear"></div>
<div class="linenb">2218</div><div class="codeline">the humble \texttt{word2vec}.</div><div class="clear"></div>
<div class="linenb">2219</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2220</div><div class="codeline"><span class="comment"><span class="comment">%--------------------------------------------------------</span></span></div><div class="clear"></div>
<div class="linenb">2221</div><div class="codeline"><span class="comment"><span class="comment">% Recommended 'Related Publication'</span></span></div><div class="clear"></div>
<div class="linenb">2222</div><div class="codeline">\chapter*{Related <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [Publications., Publications!, Publications?, Publications:, Publications,, Publications;] (84245) [lt:en:PUNCTUATION_PARAGRAPH_END]"></span>Publications}</div><div class="clear"></div>
<div class="linenb">2223</div><div class="codeline"><span class="keyword1">\label</span>{ch:relatedPubs}</div><div class="clear"></div>
<div class="linenb">2224</div><div class="codeline"><span class="comment"><span class="comment">% \input{relatedPapers.tex}</span></span></div><div class="clear"></div>
<div class="linenb">2225</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2226</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2227</div><div class="codeline">Word Embeddings as Tuples of Feature Probabilities: <span class="keyword1">\textbf</span>{<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Siddhartha] (84313) [lt:en:MORFOLOGIK_RULE_EN_GB]">Siddharth</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [That, What, Beat, Boat, Hat, Bat, Chat, Baht, Brat, Phat, Ghat, Shat, B hat] (84323) [lt:en:MORFOLOGIK_RULE_EN_GB]">Bhat}</span>,</div><div class="clear"></div>
<div class="linenb">2228</div><div class="codeline"><span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Amok, Aloe] (84329) [lt:en:MORFOLOGIK_RULE_EN_GB]">Alok</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Death, Debate, Debach, Denbeath] (84334) [lt:en:MORFOLOGIK_RULE_EN_GB]">Debnath</span>, <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Moujik, Soulie] (84343) [lt:en:MORFOLOGIK_RULE_EN_GB]">Souvik</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Bakeries, Bannered, Banshee, Bantered, Bargee, Bintree, Ganerew, Banterer] (84350) [lt:en:MORFOLOGIK_RULE_EN_GB]">Banerjee</span>, Manish <span class="highlight-spelling" title="Possible spelling mistake found (84367) [lt:en:MORFOLOGIK_RULE_EN_GB]">Shrivastava</span> <span class="highlight" title="Consider using an m-dash if you do not want to join two words.. Suggestions: [—] (84379) [lt:en:DASH_RULE]">-</span> Proceedings of the 5th</div><div class="clear"></div>
<div class="linenb">2229</div><div class="codeline">Workshop on Representation Learning for <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Nap, Nip, Alp, LP, Np, PLP, N LP] (84444) [lt:en:MORFOLOGIK_RULE_EN_GB]">NLP</span>, 2020</div><div class="clear"></div>
<div class="linenb">2230</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2231</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2232</div><div class="codeline"><span class="comment"><span class="comment">%--------------------------------------------------------</span></span></div><div class="clear"></div>
<div class="linenb">2233</div><div class="codeline">\nocite{*}</div><div class="clear"></div>
<div class="linenb">2234</div><div class="codeline">\bibliographystyle{latex8}</div><div class="clear"></div>
<div class="linenb">2235</div><div class="codeline"><span class="comment"><span class="comment">%\bibliography{References,Introduction/References} % To include one or more reference.bib files</span></span></div><div class="clear"></div>
<div class="linenb">2236</div><div class="codeline"><span class="comment"><span class="comment">% \bibliography{references}</span></span></div><div class="clear"></div>
<div class="linenb">2237</div><div class="codeline">\bibliography{references}</div><div class="clear"></div>
<div class="linenb">2238</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">2239</div><div class="codeline"><span class="keyword2">\end{document}</span></div><div class="clear"></div>
</div>
<h2 class="filename">titlePage.tex</h2>

<p>Found 20 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;1</div><div class="codeline">\thispagestyle{empty}</div><div class="clear"></div>
<div class="linenb">&nbsp;2</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;3</div><div class="codeline">\vspace*{1.5cm}</div><div class="clear"></div>
<div class="linenb">&nbsp;4</div><div class="codeline">{\Large \bf Mathematical Structures for Word Embeddings}</div><div class="clear"></div>
<div class="linenb">&nbsp;5</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;6</div><div class="codeline">\vspace*{3.75cm}</div><div class="clear"></div>
<div class="linenb">&nbsp;7</div><div class="codeline">{\large Thesis submitted in partial <span class="highlight-spelling" title="Possible spelling mistake. 'fulfillment' is American English.. Suggestions: [fulfilment] (83) [lt:en:MORFOLOGIK_RULE_EN_GB]">fulfillment<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]"></span>\\</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;8</div><div class="codeline">{\large  of the requirements for the degree of <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\\</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;9</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">10</div><div class="codeline">\vspace*{1cm}</div><div class="clear"></div>
<div class="linenb">11</div><div class="codeline">{\it {\large Master of Science in Computer Science and Engineering by Research} <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">12</div><div class="codeline"><span class="comment"><span class="comment">% {\large in\\}</span></span></div><div class="clear"></div>
<div class="linenb">13</div><div class="codeline"><span class="comment"><span class="comment">% {\large COURSE \\}}</span></span></div><div class="clear"></div>
<div class="linenb">14</div><div class="codeline">}</div><div class="clear"></div>
<div class="linenb">15</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">16</div><div class="codeline">\vspace*{1cm}</div><div class="clear"></div>
<div class="linenb">17</div><div class="codeline">{\large by}</div><div class="clear"></div>
<div class="linenb">18</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">19</div><div class="codeline">\vspace*{5mm}</div><div class="clear"></div>
<div class="linenb">20</div><div class="codeline">{\large <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Siddhartha] (222) [lt:en:MORFOLOGIK_RULE_EN_GB]">Siddharth</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [That, What, Beat, Boat, Hat, Bat, Chat, Baht, Brat, Phat, Ghat, Shat, B hat] (232) [lt:en:MORFOLOGIK_RULE_EN_GB]">Bhat<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]"></span>\\</span>}</div><div class="clear"></div>
<div class="linenb">21</div><div class="codeline">{\large 20161105 <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">22</div><div class="codeline">{\small \<span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [to, at, it, St, ft, GT, Lt, TNT, TV, ta, ITT, TTL, pt, tat, tot, rt, tut, OTT, At, ET, Mt, NT, OT, Rt, T, TW, Ta, Tb, Tc, Te, Th, Ti, Tm, Ty, UT, VT, kt, qt, st, t, tit, tu, wt, t t, tr] (251) [lt:en:MORFOLOGIK_RULE_EN_GB]">tt<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"></span> <span class="highlight" title="Please add a punctuation mark at the end of paragraph. Suggestions: [siddharth.bhat@research.iiit.ac.in., siddharth.bhat@research.iiit.ac.in!, siddharth.bhat@research.iiit.ac.in?, siddharth.bhat@research.iiit.ac.in:, siddharth.bhat@research.iiit.ac.in,, siddharth.bhat@research.iiit.ac.in;] (254) [lt:en:PUNCTUATION_PARAGRAPH_END]">siddharth.bh</span>at@research.iiit.ac.in</span> }}</div><div class="clear"></div>
<div class="linenb">23</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">24</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">25</div><div class="codeline">\vspace*{4.0cm}</div><div class="clear"></div>
<div class="linenb">26</div><div class="codeline">{\psfig{figure=figures/iiit.eps<span class="highlight-sh" title="There should be a space after a comma. [sh:d:001]"><span class="highlight" title="Put a space after the comma. Suggestions: [, width] (316) [lt:en:COMMA_PARENTHESIS_WHITESPACE]">,w</span>idth</span>=<span class="highlight" title="Insert a space between the numerical value and the unit symbol '14 mm'. Suggestions: [14 mm] (323) [lt:en:UNIT_SPACE]">14mm}<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]"></span>\\</span>}</div><div class="clear"></div>
<div class="linenb">27</div><div class="codeline"><span class="comment"><span class="comment">% {\large CSTAR: Center for Security, Theory, and Algorithms Research \\}</span></span></div><div class="clear"></div>
<div class="linenb">28</div><div class="codeline">{\large International Institute of Information Technology<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\\</span>}</div><div class="clear"></div>
<div class="linenb">29</div><div class="codeline">{\large (Deemed to be University) <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\\</span>}</div><div class="clear"></div>
<div class="linenb">30</div><div class="codeline">{\large Hyderabad <span class="highlight" title="Consider using an m-dash if you do not want to join two words.. Suggestions: [—] (421) [lt:en:DASH_RULE]">-</span> 500 032, INDIA<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\\</span>}</div><div class="clear"></div>
<div class="linenb">31</div><div class="codeline">{\large April 2021 <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\\</span>}</div><div class="clear"></div>
<div class="linenb">32</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
</div>
<h2 class="filename">certificate.tex</h2>

<p>Found 7 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;1</div><div class="codeline"><span class="highlight-sh" title="If you are writing a research paper, do not force page breaks. [sh:nonp]"></span>\newpage</div><div class="clear"></div>
<div class="linenb">&nbsp;2</div><div class="codeline">\thispagestyle{empty}</div><div class="clear"></div>
<div class="linenb">&nbsp;3</div><div class="codeline">\vspace*{1.5cm}</div><div class="clear"></div>
<div class="linenb">&nbsp;4</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;5</div><div class="codeline">{\Large International Institute of Information Technology<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\\</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;6</div><div class="codeline">{\Large Hyderabad, India<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\\</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;7</div><div class="codeline">\vspace*{3cm}</div><div class="clear"></div>
<div class="linenb">&nbsp;8</div><div class="codeline">{\Large \bf CERTIFICATE<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\\</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;9</div><div class="codeline">\vspace*{1cm}</div><div class="clear"></div>
<div class="linenb">10</div><div class="codeline">\noindent</div><div class="clear"></div>
<div class="linenb">11</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">12</div><div class="codeline">It is certified that the work contained in this thesis, titled ``Mathematical Structures for Word Embeddings'' by <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [Siddhartha] (211) [lt:en:MORFOLOGIK_RULE_EN_GB]">Siddharth</span> <span class="highlight-spelling" title="Possible spelling mistake found. Suggestions: [That, What, Beat, Boat, Hat, Bat, Chat, Baht, Brat, Phat, Ghat, Shat, B hat] (221) [lt:en:MORFOLOGIK_RULE_EN_GB]">Bhat</span>, has been carried out under</div><div class="clear"></div>
<div class="linenb">13</div><div class="codeline">my supervision and is not submitted elsewhere for a degree.</div><div class="clear"></div>
<div class="linenb">14</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">15</div><div class="codeline">\vspace*{3cm}</div><div class="clear"></div>
<div class="linenb">16</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{cc}</div><div class="clear"></div>
<div class="linenb">17</div><div class="codeline">\underline{\makebox[1in]{}} &amp; \hspace*{5cm} \underline{\makebox[2.5in]{}} \\</div><div class="clear"></div>
<div class="linenb">18</div><div class="codeline">Date &amp; \hspace*{5cm} Adviser: Prof. Kannan Srinathan</div><div class="clear"></div>
<div class="linenb">19</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">20</div><div class="codeline">\<span class="highlight-spelling" title="Possible spelling mistake found (317) [lt:en:MORFOLOGIK_RULE_EN_GB]"></span>oneandhalfspace</div><div class="clear"></div>
</div>
<hr/>
Output produced by TeXtidote v0.8.2, &copy; 2018-2020 Sylvain Hall&eacute; - All rights reserved.<br/>
See the <a href="https://sylvainhalle.github.io/textidote">TeXtidote website</a> for more information.
</body>
</html>
