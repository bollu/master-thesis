@inproceedings{cousot1992comparing,
  title={Comparing the Galois connection and widening/narrowing approaches to abstract interpretation},
  author={Cousot, Patrick and Cousot, Radhia},
  booktitle={International Symposium on Programming Language Implementation and Logic Programming},
  pages={269--295},
  year={1992},
  organization={Springer}
}

@article{cousot1996abstract,
  title={Abstract interpretation},
  author={Cousot, Patrick},
  journal={ACM Computing Surveys (CSUR)},
  volume={28},
  number={2},
  pages={324--328},
  year={1996},
  publisher={ACM New York, NY, USA}
}
@article{landauer1998introduction,
  title={An introduction to latent semantic analysis},
  author={Landauer, Thomas K and Foltz, Peter W and Laham, Darrell},
  journal={Discourse processes},
  volume={25},
  number={2-3},
  pages={259--284},
  year={1998},
  publisher={Taylor \& Francis}
}
@article{tversky1977features,
  abstract = {Questions the metric and dimensional assumptions that underlie the geometric representation of similarity on both theoretical and empirical grounds. A new set-theoretical approach to similarity is developed in which objects are represented as collections of features and similarity is described as a feature-matching process. Specifically, a set of qualitative assumptions is shown to imply the contrast model, which expresses the similarity between objects as a linear combination of the measures of their common and distinctive features. Several predictions of the contrast model are tested in studies of similarity with both semantic and perceptual stimuli. The model is used to uncover, analyze, and explain a variety of empirical phenomena such as the role of common and distinctive features, the relations between judgments of similarity and difference, the presence of asymmetric similarities, and the effects of context on judgments of similarity. The contrast model generalizes standard representations of similarity data in terms of clusters and trees. It is also used to analyze the relations of prototypicality and family resemblance. (39 ref) (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  added-at = {2014-02-04T10:50:37.000+0100},
  address = {US},
  author = {Tversky, Amos},
  biburl = {https://www.bibsonomy.org/bibtex/26213352d60fe7cf406596d8f1db71f8a/jaeschke},
  doi = {10.1037/0033-295X.84.4.327},
  interhash = {03a061a2e7ecca2b5e8d900655596144},
  intrahash = {6213352d60fe7cf406596d8f1db71f8a},
  issn = {19391471},
  journal = {Psychological Review},
  keywords = {psychology similarity toread},
  number = 4,
  pages = {327--352},
  publisher = {American Psychological Association},
  refid = {1978-09287-001},
  timestamp = {2014-07-28T15:57:31.000+0200},
  title = {Features of similarity},
  volume = 84,
  year = 1977
}


@misc{goldberg2014word2vec,
  abstract = {The word2vec software of Tomas Mikolov and colleagues
(https://code.google.com/p/word2vec/ ) has gained a lot of traction lately, and
provides state-of-the-art word embeddings. The learning models behind the
software are described in two research papers. We found the description of the
models in these papers to be somewhat cryptic and hard to follow. While the
motivations and presentation may be obvious to the neural-networks
language-modeling crowd, we had to struggle quite a bit to figure out the
rationale behind the equations.
  This note is an attempt to explain equation (4) (negative sampling) in
"Distributed Representations of Words and Phrases and their Compositionality"
by Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado and Jeffrey Dean.},
  added-at = {2016-05-31T15:34:46.000+0200},
  author = {Goldberg, Yoav and Levy, Omer},
  biburl = {https://www.bibsonomy.org/bibtex/2d03ee2d89572258e9951a2058b333312/albinzehe},
  description = {[1402.3722] word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method},
  interhash = {529718927f289e07d24eb4b9b4d4e207},
  intrahash = {d03ee2d89572258e9951a2058b333312},
  keywords = {ma-zehe thema:word_embeddings word2vec wordembeddings},
  note = {cite arxiv:1402.3722},
  timestamp = {2016-10-24T11:33:25.000+0200},
  title = {word2vec Explained: deriving Mikolov et al.'s negative-sampling
  word-embedding method},
  url = {http://arxiv.org/abs/1402.3722},
  year = 2014
}

@inproceedings{pennington-etal-2014-glove,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D14-1162",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543",
}
@article{mikolov2013efficient,
  added-at = {2015-11-09T17:49:31.000+0100},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  biburl = {https://www.bibsonomy.org/bibtex/24a3db34a5744ad8a2704d42f0ef00905/scheuerpflug},
  interhash = {e92df552b17e9f952226a893b84ad739},
  intrahash = {4a3db34a5744ad8a2704d42f0ef00905},
  journal = {arXiv preprint arXiv:1301.3781},
  keywords = {language modelling skipgram thema:deepwalk},
  timestamp = {2015-11-09T17:49:31.000+0100},
  title = {Efficient estimation of word representations in vector space},
  year = 2013
}

@misc{firth1957synopsis,
  title={A Synopsis of Linguistic Theory 1930--55},
  author={Firth, John R},
  year={1957},
  publisher={Oxford: Basil Blackwell}
}

@article{arora2019theoretical,
  title={A theoretical analysis of contrastive unsupervised representation learning},
  author={Arora, Sanjeev and Khandeparkar, Hrishikesh and Khodak, Mikhail and Plevrakis, Orestis and Saunshi, Nikunj},
  journal={arXiv preprint arXiv:1902.09229},
  year={2019}
}
@book{absil2009optimization,
  title={Optimization algorithms on matrix manifolds},
  author={Absil, P-A and Mahony, Robert and Sepulchre, Rodolphe},
  year={2009},
  publisher={Princeton University Press}
}
@misc{munkres2014topology,
  title={Topology},
  author={Munkres, James},
  year={2014},
  publisher={Pearson Education}
}
